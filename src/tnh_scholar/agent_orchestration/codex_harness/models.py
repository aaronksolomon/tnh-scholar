"""Domain models for the Codex harness."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path

from pydantic import BaseModel, Field
from pydantic_settings import BaseSettings, SettingsConfigDict


@dataclass(frozen=True)
class CodexDefaults:
    """Default values for harness settings and parameters."""

    runs_root: Path = Path(".tnh-codex/runs")
    model: str = "gpt-5.2-codex"
    timeout_seconds: int = 900
    max_output_tokens: int = 2000
    temperature: float | None = None
    max_tool_rounds: int = 12
    default_system_prompt: str = (
        "Use the provided tools to inspect the repo. Use repo-relative paths. "
        "Return ONLY JSON with keys: patch (string or null), rationale (string), "
        "risk_flags (list of strings), open_questions (list of strings), "
        "status (complete|partial|blocked). No extra keys."
    )


class CodexRunStatus(str, Enum):
    completed = "completed"
    blocked = "blocked"
    failed = "failed"


class CodexOutputStatus(str, Enum):
    complete = "complete"
    partial = "partial"
    blocked = "blocked"


class CodexSettings(BaseSettings):
    """Environment-driven settings for the Codex harness."""

    model_config = SettingsConfigDict(extra="ignore")

    runs_root: Path = Field(default_factory=lambda: CodexDefaults().runs_root)
    model: str = Field(default_factory=lambda: CodexDefaults().model)
    openai_api_key: str | None = None

    @classmethod
    def from_env(cls) -> "CodexSettings":
        """Create settings from environment."""
        return cls()


class CodexRunConfig(BaseModel):
    """Construction-time configuration for the harness."""

    runs_root: Path
    model: str


class CodexRunParams(BaseModel):
    """Per-run parameters for the harness."""

    task: str
    system_prompt: str | None = None
    apply_patch: bool = True
    run_tests_command: str | None = None
    timeout_seconds: int = Field(default_factory=lambda: CodexDefaults().timeout_seconds)
    max_output_tokens: int = Field(default_factory=lambda: CodexDefaults().max_output_tokens)
    temperature: float | None = Field(default_factory=lambda: CodexDefaults().temperature)
    max_tool_rounds: int = Field(default_factory=lambda: CodexDefaults().max_tool_rounds)


class CodexMessage(BaseModel):
    """Message entry for a Codex request."""

    role: str
    content: str


class CodexRequest(BaseModel):
    """Codex request payload for the Responses API."""

    model: str
    messages: list[CodexMessage]
    max_output_tokens: int
    temperature: float | None
    max_tool_rounds: int


class CodexStructuredOutput(BaseModel):
    """Structured output expected from Codex."""

    patch: str | None = None
    rationale: str
    risk_flags: list[str] = Field(default_factory=list)
    open_questions: list[str] = Field(default_factory=list)
    status: CodexOutputStatus


class CodexResponseText(BaseModel):
    """Raw response text captured from the API."""

    text: str
    raw_payload: str


class CodexRunArtifacts(BaseModel):
    """Paths to files generated by a run."""

    run_metadata: Path
    request_json: Path
    response_json: Path
    response_text: Path
    output_json: Path
    patch_diff: Path
    stdout_log: Path
    stderr_log: Path


class PatchApplyResult(BaseModel):
    """Result of applying a patch."""

    applied: bool
    stdout: str
    stderr: str


class TestRunResult(BaseModel):
    """Result of running a test command."""

    exit_code: int
    stdout: str
    stderr: str


class CodexRunMetadata(BaseModel):
    """Metadata for a Codex harness run."""

    run_id: str
    started_at: datetime
    ended_at: datetime
    model: str
    status: CodexRunStatus
    output_status: CodexOutputStatus | None = None
    artifacts: CodexRunArtifacts
    patch_applied: bool = False
    test_exit_code: int | None = None
    error_message: str | None = None
