{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from data_processing.gpt_processing import (\n",
    "    generate_messages, \n",
    "    set_model_settings,\n",
    "    run_immediate_chat_process,\n",
    "    get_last_batch_response,\n",
    ")\n",
    "\n",
    "from data_processing.gpt_processing.pdf_journal_process import (\n",
    "    batch_section, batch_translate, validate_and_save_metadata, save_sectioning_data, save_translation_data\n",
    ")\n",
    "\n",
    "%aimport time\n",
    "%aimport json\n",
    "%aimport datetime\n",
    "%aimport logging\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from math import floor\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "project_dir = Path(\"/Users/phapman/Desktop/tnh-scholar/\")\n",
    "data_dir = project_dir / \"data_processing\"\n",
    "journal_dir = data_dir / \"processed_journal_data\"\n",
    "journal_name = \"phat-giao-viet-nam-1956-02\"\n",
    "working_dir = journal_dir / journal_name\n",
    "input_xml = working_dir / f\"TEST_full_cleaned_{journal_name}.xml\"\n",
    "translation_xml_path = working_dir / f\"translation_{journal_name}.xml\"\n",
    "section_batch_jsonl = working_dir / \"processing_batch_files\" /\"section_batch.jsonl\"\n",
    "translate_batch_jsonl = working_dir / \"processing_batch_files\" / \"translation_batch.jsonl\"\n",
    "section_metadata_out = working_dir / \"section_metadata.json\"\n",
    "raw_json_metadata_path = working_dir / \"raw_metadata_response.txt\"\n",
    "logfile = data_dir / \"gpt_processing\" / \"processing_info.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MAX_TOKEN_LIMIT = 20000\n",
    "MAX_BATCH_RETRIES = 20  # Number of retries\n",
    "BATCH_RETRY_DELAY = 5  # seconds to wait before retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the logger\n",
    "def setup_logger(log_file_path):\n",
    "    \"\"\"\n",
    "    Configures the logger to write to a log file and the console.\n",
    "    \"\"\"\n",
    "    # Remove existing handlers\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",  # Include logger name\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()  # Optional: to log to the console as well\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Suppress DEBUG/INFO logs for specific noisy modules\n",
    "    modules_to_suppress = [\"httpx\", \"httpcore\", \"urllib3\", \"openai\"]\n",
    "    for module in modules_to_suppress:\n",
    "        logger = logging.getLogger(module)\n",
    "        logger.setLevel(logging.WARNING)  # Suppress DEBUG and INFO logs\n",
    "\n",
    "    \n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings_section = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,\n",
    "        \"temperature\": 0.25\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_section = \"\"\"You are a highly skilled assistant processing a Vietnamese Buddhist journal scanned from OCR. \n",
    "Use the title: \"Journal of Vietnamese Buddhism.\"\n",
    "You will be determining the journal sections by page number. You will also generate metadata for the full text and each section. \n",
    "You will return this metadata in JSON format.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the text and divide it into sections based on logical breaks, such as headings, topic changes, or clear shifts in content.\n",
    "2. Ensure every page is part of  a section, even if that section is titled \"blank page\" or \"title page,\" for example.\n",
    "3. For each section, provide:\n",
    "   - The original title in Vietnamese (`section_title_vi`).\n",
    "   - The translated title in English (`section_title_en`).\n",
    "   - The author's name if it is available (`section_author`). \n",
    "   - A one-paragraph summary of the section in English (`section_summary`).\n",
    "   - A list of keywords for the section that are related to its content, these can be proper names, specific concepts, or contextual information.\n",
    "   - The section's start and end page numbers (`start_page` and `end_page`).\n",
    "   - Use \"null\" for any data that is not available (such as author name) for the section.\n",
    "\n",
    "4. Return the output as a JSON object with the following schema:\n",
    "{\n",
    "    \"journal_summary\": \"A one-page summary of the whole journal in English.\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"title_vi\": \"Original title in Vietnamese\",\n",
    "            \"title_en\": \"Translated title in English\",\n",
    "            \"author\": \"Name of the author of the section\",\n",
    "            \"summary\": \"One-paragraph summary of the section in English\",\n",
    "            \"keywords\": \"A list of keywords for the section\",\n",
    "            \"start_page\":  X,\n",
    "            \"end_page\":  Y\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "5.  Ensure the JSON is well-formed and adheres strictly to the provided schema.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings_translate = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,  # a default value, updated per batch\n",
    "        \"temperature\": 0.75\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_translate = \"\"\"You are the world's foremost translator of Zen Master Thich Nhat Hanh's Vietnamese writing into English, following the language style of the plumvillage.org website.\n",
    "The text is based on an OCR scan of a journal you edited from 1956-1958. Use the title: \"Journal of Vietnamese Buddhism\" for the journal when it is referenced.\n",
    "You will be translating a single section of the journal and will be provided with the section title in English. \n",
    "You want advanced students of Thay to understand the text in its larger historical context, in the context of Vietnamese Buddhism, and in the context of your own life.\n",
    "Translate for the most meaningful, typical, and eloquent English interpretation that is simple, yet poetic. Translate literally, don't add any content. \n",
    "Notes on the text can be added in the <notes>.\n",
    "Make corrections in the text only where necessary (for example if words are missing) to create logical flow. Note all corrections in the <translation-notes>. \n",
    "Do not change <pagebreak> tag postioning. Each translated page must match its original page source as pages will be studied side by side with the original Vietnamese.\n",
    "Infer paragraphs and text structure from the text layout.\n",
    "Add XML tags for clarity, using only the following tags: \n",
    "\n",
    "   <section> for major sections.\n",
    "   <subsection> for subsections.\n",
    "   <title> for main titles of sections and subsections. \n",
    "   <subtitle> for subtitles of sections and subsections. \n",
    "   <heading> for headings that do not mark titles or subtitles\n",
    "   <p> for paragraphs.\n",
    "   <br/> for linebreaks that add meaning such as in poems or other structures.\n",
    "   <TOC> for tables of contents\n",
    "   <author> for authors of sections or subsections\n",
    "   <ol> <ul> <li> for lists\n",
    "   <i> for italics. \n",
    "   <b> for bold.\n",
    "   <notes>\n",
    "   <translation-notes>\n",
    "\n",
    "You may use <notes> at the end of the section for notes on historical, cultural, spiritual, or other interesting elements of the text.\n",
    "You may add <translation-notes> at the end of the section as a commentary to summarize your translation choices. \n",
    "For <translation-notes>, you may include information on Sino-Vietnamese, complex, unusual, poetic, or other interesting terms, and significant corrections to the text. \n",
    "In the <translation-notes> include the original Vietnamese terms for reference.\n",
    "\n",
    "IMPORTANT: All titles, XML sections, text, and terms should be translated. Do not however, translate names of people; leave names in Vietnamese with diacritics.\n",
    "IMPORTANT: Return pure XML with no formatting marks such as xml or ```.\n",
    "IMPORTANT: The returned XML should begin and end with <section> tags.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/translation_phat-giao-viet-nam-1956-02.xml')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_xml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 20:53:22,666 - journal_process - INFO - Starting sectioning batch for phat-giao-viet-nam-1956-02 with file:\n",
      "\t/Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "2024-12-02 20:53:22,669 - gpt_interface - INFO - Creating JSONL batch file with \u001b[91m5000\u001b[0m requested tokens:\n",
      "\t/Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/processing_batch_files/section_batch.jsonl\n",
      "2024-12-02 20:53:22,669 - gpt_interface - DEBUG - Batch request details: Method=POST, URL=/v1/chat/completions\n",
      "2024-12-02 20:53:22,670 - gpt_interface - DEBUG - Batch parameters:\n",
      "    model: gpt-4o\n",
      "    max_tokens: 5000\n",
      "    temperature: 0.25\n",
      "    response_format: {'type': 'json_object'}\n",
      "2024-12-02 20:53:22,671 - gpt_interface - INFO - JSONL file created at: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/processing_batch_files/section_batch.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 20:53:24,368 - gpt_interface - INFO - Batch Initiated with description: 12-02-2024 20:53:22 PST | section_batch.jsonl | Batch for sectioning journal: phat-giao-viet-nam-1956-02 | input file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "2024-12-02 20:53:24,370 - gpt_interface - INFO - batch info: batch_674e8ec436e4819099d93114fd43489b, 1733201604, file-5T9FgVfB653kEGn3HbY82C \n",
      "2024-12-02 20:53:24,371 - gpt_interface - INFO - Batch started successfully on attempt 1.\n",
      "2024-12-02 20:53:24,373 - gpt_interface - INFO - Polling batch status for batch ID batch_674e8ec436e4819099d93114fd43489b ...\n",
      "2024-12-02 20:53:34,659 - gpt_interface - DEBUG - Batch ID batch_674e8ec436e4819099d93114fd43489b status: failed\n",
      "2024-12-02 20:53:34,661 - gpt_interface - ERROR - Batch processing for ID batch_674e8ec436e4819099d93114fd43489b failed.\n",
      "2024-12-02 20:53:34,662 - gpt_interface - ERROR - Attempt 1 failed. Retrying batch process in 5 seconds...\n",
      "2024-12-02 20:53:40,899 - gpt_interface - INFO - Batch Initiated with description: 12-02-2024 20:53:39 PST | section_batch.jsonl | Batch for sectioning journal: phat-giao-viet-nam-1956-02 | input file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "2024-12-02 20:53:40,902 - gpt_interface - INFO - batch info: batch_674e8ed48f2481909cec0342a11d4b36, 1733201620, file-2YK26Ks9cBPcB2Wa3uLn3S \n",
      "2024-12-02 20:53:40,902 - gpt_interface - INFO - Batch started successfully on attempt 2.\n",
      "2024-12-02 20:53:40,903 - gpt_interface - INFO - Polling batch status for batch ID batch_674e8ed48f2481909cec0342a11d4b36 ...\n",
      "2024-12-02 20:53:51,494 - gpt_interface - DEBUG - Batch ID batch_674e8ed48f2481909cec0342a11d4b36 status: failed\n",
      "2024-12-02 20:53:51,496 - gpt_interface - ERROR - Batch processing for ID batch_674e8ed48f2481909cec0342a11d4b36 failed.\n",
      "2024-12-02 20:53:51,497 - gpt_interface - ERROR - Attempt 2 failed. Retrying batch process in 5 seconds...\n",
      "2024-12-02 20:53:57,939 - gpt_interface - INFO - Batch Initiated with description: 12-02-2024 20:53:56 PST | section_batch.jsonl | Batch for sectioning journal: phat-giao-viet-nam-1956-02 | input file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "2024-12-02 20:53:57,940 - gpt_interface - INFO - batch info: batch_674e8ee5d3948190a5ec5a3232289d43, 1733201637, file-GpERhop82HfVCmysyBa2Nj \n",
      "2024-12-02 20:53:57,941 - gpt_interface - INFO - Batch started successfully on attempt 3.\n",
      "2024-12-02 20:53:57,941 - gpt_interface - INFO - Polling batch status for batch ID batch_674e8ee5d3948190a5ec5a3232289d43 ...\n",
      "2024-12-02 20:54:08,143 - gpt_interface - DEBUG - Batch ID batch_674e8ee5d3948190a5ec5a3232289d43 status: failed\n",
      "2024-12-02 20:54:08,144 - gpt_interface - ERROR - Batch processing for ID batch_674e8ee5d3948190a5ec5a3232289d43 failed.\n",
      "2024-12-02 20:54:08,145 - gpt_interface - ERROR - Attempt 3 failed. Retrying batch process in 5 seconds...\n",
      "2024-12-02 20:54:14,281 - gpt_interface - INFO - Batch Initiated with description: 12-02-2024 20:54:13 PST | section_batch.jsonl | Batch for sectioning journal: phat-giao-viet-nam-1956-02 | input file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "2024-12-02 20:54:14,283 - gpt_interface - INFO - batch info: batch_674e8ef628d48190bfcaec89f8dedb1a, 1733201654, file-45QHFbikQbPssTpvLpQoHg \n",
      "2024-12-02 20:54:14,284 - gpt_interface - INFO - Batch started successfully on attempt 4.\n",
      "2024-12-02 20:54:14,286 - gpt_interface - INFO - Polling batch status for batch ID batch_674e8ef628d48190bfcaec89f8dedb1a ...\n",
      "2024-12-02 20:54:24,765 - gpt_interface - DEBUG - Batch ID batch_674e8ef628d48190bfcaec89f8dedb1a status: in_progress\n",
      "2024-12-02 20:54:24,768 - gpt_interface - INFO - Batch status: in_progress. Retrying in 10 seconds...\n",
      "2024-12-02 20:54:38,057 - gpt_interface - DEBUG - Batch ID batch_674e8ef628d48190bfcaec89f8dedb1a status: completed\n",
      "2024-12-02 20:54:38,060 - gpt_interface - INFO - Batch processing for ID batch_674e8ef628d48190bfcaec89f8dedb1a completed successfully.\n",
      "2024-12-02 20:54:38,766 - gpt_interface - INFO - Batch completed successfully after 4 attempts.\n",
      "2024-12-02 20:54:38,768 - journal_process - INFO - Successfully batch sectioned journal 'phat-giao-viet-nam-1956-02' with input file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml.\n",
      "2024-12-02 20:54:38,774 - journal_process - INFO - Parsed and validated metadata successfully written to /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/section_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Sectioning\n",
    "set_model_settings(model_settings_section)\n",
    "metadata_serial_json = batch_section(input_xml, section_batch_jsonl, system_message_section, journal_name)\n",
    "metadata_path = save_sectioning_data(section_metadata_out, raw_json_metadata_path, metadata_serial_json, journal_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 20:58:02,870 - journal_process - INFO - Starting translation batch for journal 'phat-giao-viet-nam-1956-02':\n",
      "\twith file: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/TEST_full_cleaned_phat-giao-viet-nam-1956-02.xml\n",
      "\tmetadata: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/section_metadata.json\n",
      "2024-12-02 20:58:02,871 - journal_process - DEBUG - page groups found: [(1, 1), (2, 2), (3, 3), (4, 6)]\n",
      "2024-12-02 20:58:02,872 - journal_process - DEBUG - section_contents[0]:\n",
      "PHẬT-GIÁO\n",
      "VIỆT-NAM\n",
      "NGUYỆT-SAN\n",
      "SỐ 2 RA NGÀY 15 THÁNG 9 BÍNH-THÂN\n",
      "THƯỜNG HỘI PHẬT-GIÁO VIỆT-NAM XUẤT-BẢN\n",
      "<pagebreak page='1' />\n",
      "2024-12-02 20:58:02,873 - journal_process - DEBUG - section 0: Journal of Vietnamese Buddhism added for batch processing.\n",
      "2024-12-02 20:58:02,874 - journal_process - DEBUG - section 1: Table of Contents Issue 2 added for batch processing.\n",
      "2024-12-02 20:58:02,875 - journal_process - DEBUG - section 2: blank page added for batch processing.\n",
      "2024-12-02 20:58:02,888 - journal_process - DEBUG - section 3: The Direction of Culture added for batch processing.\n",
      "2024-12-02 20:58:02,890 - gpt_interface - INFO - Creating JSONL batch file with \u001b[91m6383\u001b[0m requested tokens:\n",
      "\t/Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/processing_batch_files/translation_batch.jsonl\n",
      "2024-12-02 20:58:02,890 - gpt_interface - DEBUG - Batch request details: Method=POST, URL=/v1/chat/completions\n",
      "2024-12-02 20:58:02,891 - gpt_interface - DEBUG - Batch parameters:\n",
      "    model: gpt-4o\n",
      "    max_tokens: 1102\n",
      "    temperature: 0.75\n",
      "2024-12-02 20:58:02,892 - gpt_interface - INFO - JSONL file created at: /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-02/processing_batch_files/translation_batch.jsonl\n",
      "2024-12-02 20:58:04,318 - gpt_interface - INFO - Batch Initiated with description: 12-02-2024 20:58:02 PST | translation_batch.jsonl | Batch for translating journal 'phat-giao-viet-nam-1956-02'\n",
      "2024-12-02 20:58:04,319 - gpt_interface - INFO - batch info: batch_674e8fdbf524819091d7ba9634045727, 1733201884, file-TEMbahEsosCLKDUjP2XwMT \n",
      "2024-12-02 20:58:04,319 - gpt_interface - INFO - Batch started successfully on attempt 1.\n",
      "2024-12-02 20:58:04,320 - gpt_interface - INFO - Polling batch status for batch ID batch_674e8fdbf524819091d7ba9634045727 ...\n",
      "2024-12-02 20:58:14,619 - gpt_interface - DEBUG - Batch ID batch_674e8fdbf524819091d7ba9634045727 status: in_progress\n",
      "2024-12-02 20:58:14,619 - gpt_interface - INFO - Batch status: in_progress. Retrying in 10 seconds...\n",
      "2024-12-02 20:58:28,007 - gpt_interface - DEBUG - Batch ID batch_674e8fdbf524819091d7ba9634045727 status: completed\n",
      "2024-12-02 20:58:28,008 - gpt_interface - INFO - Batch processing for ID batch_674e8fdbf524819091d7ba9634045727 completed successfully.\n",
      "2024-12-02 20:58:28,897 - gpt_interface - INFO - Batch completed successfully after 1 attempts.\n",
      "2024-12-02 20:58:28,898 - journal_process - INFO - Successfully translated section batch.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Translating\n",
    "set_model_settings(model_settings_translate)\n",
    "if metadata_path:\n",
    "    translation_data = batch_translate(input_xml, translate_batch_jsonl, metadata_path, system_message_translate, journal_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<section>\\n    <title>Journal of Vietnamese Buddhism</title>\\n    <p>\\n        BUDDHISM<br/>\\n        IN VIETNAM<br/>\\n        MONTHLY JOURNAL<br/>\\n        ISSUE 2 RELEASED ON 15TH OF SEPTEMBER, YEAR OF THE MONKEY<br/>\\n        PUBLISHED BY THE VIETNAMESE BUDDHIST ASSOCIATION<br/>\\n    </p>\\n    <pagebreak page='1' />\\n</section>\",\n",
       " '<section>\\n    <title>Table of Contents</title>\\n    <TOC>\\n        <p>Buddhism in Vietnam</p>\\n        <p>Contents Number 2</p>\\n        <p>Full Moon of the Ninth Month in the Year of the Monkey (Bính Thân)</p>\\n        <ul>\\n            <li>The Direction of Culture</li>\\n            <li>Affirming the Value of the Human Being</li>\\n            <li>What Factors Determined the Success of Nguyễn-Công Trứ</li>\\n            <li>Buddhist Literature</li>\\n            <li>The Spring of the Path</li>\\n            <li>Visits to Buddhist Lands</li>\\n            <li>Buddhism and Science</li>\\n            <li>The Bridge of Sympathy</li>\\n            <li>Buddhist Ideology</li>\\n            <li>Escaping the Golden Prison</li>\\n            <li>Folk Songs</li>\\n        </ul>\\n        <p>Authors:</p>\\n        <ul>\\n            <li>P. G. V. N</li>\\n            <li>Dã Thảo</li>\\n            <li>Minh Hạnh</li>\\n            <li>Thầy Thạc-Đức</li>\\n            <li>Thanh-Ti</li>\\n            <li>Thầy Thiện Hòa</li>\\n            <li>Viên-Đình</li>\\n            <li>Thiều Chi Hoa</li>\\n            <li>Thầy Trí-Quang</li>\\n            <li>Võ Đình Cường</li>\\n            <li>Tâm Kiến</li>\\n        </ul>\\n    </TOC>\\n    <pagebreak page=\\'2\\' />\\n    <notes>\\n    The text references the Bính Thân year, which corresponds to the lunar calendar year of 1956 in the Gregorian calendar. Nguyễn-Công Trứ was a notable Vietnamese poet and official. This table of contents reflects a broad array of topics, showing the journal\\'s dedication to merging traditional Buddhist scholarship with contemporary issues, such as science and culture. The authors listed are key figures in Vietnamese Buddhism and literature of that time.\\n    </notes>\\n    <translation-notes>\\n    The term \"Mục Lục\" was translated to \"Table of Contents.\" \"RẰM THÁNG 9 BÍNH THÂN\" was interpreted as \"Full Moon of the Ninth Month in the Year of the Monkey (Bính Thân)\" to provide context regarding the traditional lunar calendar. \"Thoát Ngục Vàng\" was translated as \"Escaping the Golden Prison,\" where \"Ngục Vàng\" metaphorically refers to a prison of wealth or materialism. The authors\\' names were kept in their original form as requested.\\n    </translation-notes>\\n</section>',\n",
       " \"<section>\\n<title>Blank Page</title>\\n<pagebreak page='3' />\\n</section>\",\n",
       " '<section>\\n    <title>The Direction of Culture</title>\\n    <p>Since ancient times, humanity has been in a struggle. Due to karma from time immemorial, humans possess a physical body that exists within a universe, amidst a human society, and alongside countless other sentient beings. With life comes the necessity to preserve life, either through awareness or instinct.</p>\\n    <p>Heat, cold, wind, rain, hunger, cold, wild beasts, disasters... these are all challenges that humans must overcome to survive. Nature is an adversary, but it is also a friend. When weak, nature threatens; when clever, nature serves. Humans, with their hands and minds, have harnessed nature, exploited it, and compelled it to provide for the needs of life.</p>\\n    <pagebreak page=\\'4\\' />\\n    <p>From the form of an economy based on gathering to one of animal husbandry and cultivation, humans have truly advanced. However, from the beginning, the object of struggle was not only nature and wild beasts. Humans have eaten humans just as wild beasts have eaten humans, so people from ancient times have sought ways to deal with their own kind. Groups of five, seven people banded together, using collective strength to protect one another. Tribes were formed, and as a result, the struggle against nature became more effective.</p>\\n    <p>The tribal system marked a step forward in humanity\\'s struggle for survival. These human societies had their own laws, customs, rituals, entertainments, and survival methods. They had culture.</p>\\n    <p>From the tribal organization, humans gradually moved toward national organization. During this period, the mind expanded, and the sense of kinship grew rapidly. The phenomenon of cannibalism no longer occurred frequently: humans now directed all mental and physical efforts toward exploiting nature.</p>\\n    <p>But the more exploited, the more nature provided raw materials and food. Simultaneously, technology advanced: the quality of extraction and production increased at an unexpected rate. The economic issue suddenly became significant. Conflicts arose between nations and between classes. Wars erupted fiercely. Science and technology turned to serve war, producing bombs, ammunition, and weapons. While struggling with nature, humans turned weapons against one another.</p>\\n    <p>People died, blood spilled, flesh fell. In the past, with limited production means and crude tools, humanity did not perish as much as now. All the greed and anger of humans have been awakened; humans have used countless insidious and evil schemes to confront each other.</p>\\n    <p>Killing fellow humans? It doesn\\'t matter, as long as it serves the class, satisfies personal desires. People kill under the guise of ideals: killing to eradicate disease, to create peace. To counter killing, naturally, the opponent also resorts to killing...</p>\\n    <p>In the past, when a black savage ate a white person, we called it barbaric. Today, a nation with weapons that can kill more people is called civilized. In truth, it is an unparalleled barbarity and brutality.</p>\\n    <p>Previously, the direction of culture was to struggle with nature. Now, the direction of culture is to struggle with fellow humans.</p>\\n    <pagebreak page=\\'5\\' />\\n    <p>In a vast and fierce arena of struggle, using killing to prevent killing is a futile endeavor. The law of cause and effect never errs: sow the wind, reap the storm; plant corn, get corn; plant beans, get beans, and cause killing, bear the consequence of killing.</p>\\n    <p>Humans must realize this crucial point and acknowledge that culture has lost its way. People need to see that greed and anger have caused chaos in the world and must turn inward to initiate a great internal cleansing. We must realize that within ourselves lie elements of wisdom and compassion, as well as elements of ignorance and desire.</p>\\n    <p>Ignorant desires have obscured compassion and wisdom: humans must struggle to eliminate them, to nurture wisdom and compassion. With wisdom and compassion, humans can achieve happiness, and only then can they unite deeply to create a beautiful and shared life.</p>\\n    <p>In the past, culture shifted from the struggle with nature to the struggle with fellow humans. The direction of the new culture of humanity must be to struggle with personal desires.</p>\\n    <author>P. G.</author>\\n    <author>V. N.</author>\\n    <pagebreak page=\\'6\\' />\\n</section>\\n\\n<notes>\\n    The text highlights the evolution of human struggle from nature to internal desires, emphasizing the need to cultivate wisdom and compassion. It reflects the Buddhist perspective on the importance of inner transformation for societal harmony.\\n</notes>\\n\\n<translation-notes>\\n    Original Vietnamese terms: \\n    - \"nghiệp cảm\" (karma), \\n    - \"sắc thân\" (physical body), \\n    - \"hữu tình\" (sentient beings), \\n    - \"trí tuệ\" (wisdom),\\n    - \"tình thương\" (compassion),\\n    - \"si mê\" (ignorance), \\n    - \"dục vọng\" (desire).\\n    The authors \"P. G.\" and \"V. N.\" are not identified in the text but may be contributors or pseudonyms.\\n</translation-notes>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_translation_data() missing 1 required positional argument: 'journal_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_translation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.xml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_translation_data() missing 1 required positional argument: 'journal_name'"
     ]
    }
   ],
   "source": [
    "save_translation_data(Path(\"test.xml\"), translation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 21:15:49,819 - INFO - HTTP Request: GET https://api.openai.com/v1/batches?limit=30 \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:50,287 - INFO - HTTP Request: GET https://api.openai.com/v1/batches?limit=30&after=batch_6748f738f6948190b4b987ac65cf2a1d \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:50,778 - INFO - HTTP Request: GET https://api.openai.com/v1/batches?limit=30&after=batch_6736d4d981f48190beda7f734d6a75d9 \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:50,976 - INFO - HTTP Request: GET https://api.openai.com/v1/batches?limit=30&after=batch_672b85772df8819085957fa62c4e3020 \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:51,265 - INFO - HTTP Request: GET https://api.openai.com/v1/batches?limit=30&after=batch_672b091c02088190b0d4e5d9275ec258 \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:51,588 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_6749361435788190a9391a6839d845aa \"HTTP/1.1 200 OK\"\n",
      "2024-11-28 21:15:52,007 - INFO - HTTP Request: GET https://api.openai.com/v1/files/file-9F8Ku2oW6NHdWfZp4DbBxH/content \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = get_last_batch_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"journal_summary\": \"This Vietnamese journal explores the deep-rooted connection between Buddhism and Vietnamese culture, tracing its historical influence and emphasizing the importance of maintaining Buddhist values in modern society. It also discusses the proper path for Vietnamese Buddhists, emphasizing the need for clear understanding and awareness in navigating life's challenges.\",\n",
      "    \"sections\": [\n",
      "        {\n",
      "            \"section_title_vi\": \"PHẬT GIÁO VIỆT NAM NGUYỆT SAN SỐ 1\",\n",
      "            \"section_title_en\": \"Vietnamese Buddhism Monthly Issue 1\",\n",
      "            \"section_author\": null,\n",
      "            \"section_summary\": \"This is the title page of the journal, indicating the publication as the first issue of the Vietnamese Buddhism Monthly, released on the 15th of August in the year of the Monkey.\",\n",
      "            \"section_keywords\": [\"Vietnamese Buddhism\", \"Monthly Issue\", \"Publication Date\"],\n",
      "            \"start_page\": 1,\n",
      "            \"end_page\": 1\n",
      "        },\n",
      "        {\n",
      "            \"section_title_vi\": \"PHẬT-GIÁO VIỆT - NAM\",\n",
      "            \"section_title_en\": \"Vietnamese Buddhism\",\n",
      "            \"section_author\": null,\n",
      "            \"section_summary\": \"This section discusses the historical and cultural integration of Buddhism into Vietnamese society over fifteen centuries. It highlights Buddhism's role in shaping Vietnamese national identity and culture, emphasizing its adaptability and deep connection with Vietnamese values and traditions.\",\n",
      "            \"section_keywords\": [\"Buddhism\", \"Vietnamese Culture\", \"History\", \"National Identity\"],\n",
      "            \"start_page\": 2,\n",
      "            \"end_page\": 4\n",
      "        },\n",
      "        {\n",
      "            \"section_title_vi\": \"HƯỚNG ĐI CỦA NGƯỜI PHẬT TỬ VIỆT NAM\",\n",
      "            \"section_title_en\": \"The Path for Vietnamese Buddhists\",\n",
      "            \"section_author\": null,\n",
      "            \"section_summary\": \"This section outlines the proper path for Vietnamese Buddhists, stressing the importance of having a clear understanding and awareness in life. It warns against blind faith and emphasizes the need for correct perception and wisdom to avoid life's pitfalls and achieve true understanding.\",\n",
      "            \"section_keywords\": [\"Buddhist Path\", \"Awareness\", \"Correct Perception\", \"Wisdom\"],\n",
      "            \"start_page\": 5,\n",
      "            \"end_page\": 5\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data successfully written to /Users/phapman/Desktop/tnh-scholar/data_processing/processed_journal_data/phat-giao-viet-nam-1956-01/section_metadata.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_and_save_metadata(section_metadata_out, result[0], journal_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_sectioning(input_xml_path, output_json_path, raw_output_path, journal_name, max_retries=MAX_BATCH_RETRIES, retry_delay=BATCH_RETRY_DELAY):\n",
    "#     \"\"\"\n",
    "#     Splits the journal content into sections using GPT, with retries for both starting and completing the batch.\n",
    "#     \"\"\"\n",
    "#     journal_pages = get_text_from_file(input_xml_path)\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"{text}\"\n",
    "#     messages = generate_messages(system_message_section, user_message_wrapper, [journal_pages])\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, section_batch_jsonl, json_mode=True)\n",
    "\n",
    "#     for attempt in range(max_retries):\n",
    "#         try:\n",
    "#             # Try to start the batch\n",
    "#             batch = start_batch(jsonl_file, description=f\"Batch for sectioning journal: {journal_name} | input file: {input_xml_path}\")\n",
    "#             batch_id = batch.id\n",
    "#             if not batch_id:\n",
    "#                 raise RuntimeError(\"Batch started but no ID was returned.\")\n",
    "\n",
    "#             print(f\"Batch for sectioning started successfully on attempt {attempt + 1}. ID: {batch_id}\")\n",
    "\n",
    "#             # Poll for batch completion\n",
    "#             json_results = poll_batch_for_response(batch_id)\n",
    "#             if json_results:\n",
    "#                 break # exit retry loop\n",
    "#             else:\n",
    "#                 raise RuntimeError(\"Unknown error in polling for batch response.\", exc_info=True)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Attempt {attempt + 1} failed: {e}. Retrying batch process in {retry_delay} seconds...\")\n",
    "#             time.sleep(retry_delay)\n",
    "#     else:\n",
    "#         logger.error(\"Failed to complete batch sectioning after maximum retries.\")\n",
    "#         raise RuntimeError(\"Error: Failed to complete batch sectioning after maximum retries.\")\n",
    "\n",
    "#     # save raw result\n",
    "#     try:\n",
    "#         write_text_to_file(raw_output_path, json_results, force=True)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"failed to write raw response file: {raw_output_path}\")\n",
    "#         raise\n",
    "\n",
    "#     # If successful, try to validate and save metadata and exit loop\n",
    "#     try:\n",
    "#         valid = validate_and_save_metadata(output_json_path, json_results, journal_schema)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error occurred while validating and saving metadata for journal {journal_name}: '{output_json_path}' (batch ID: {batch_id}).\", exc_info=True)\n",
    "#         raise\n",
    "    \n",
    "#     if valid:\n",
    "#         logger.info(f\"Successfully processed {journal_name}: {input_xml_path} with batch: {batch_id} and saved metadata to {output_json_path} \")\n",
    "#         return output_json_path\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Sectioning\n",
    "# def batch_sectioning(input_xml_path, output_xml_path):\n",
    "#     \"\"\"\n",
    "#     Splits the journal content into sections using the GPT model.\n",
    "#     Saves the sectioned content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the input XML\n",
    "#     journal_pages = load_xml(input_xml_path)\n",
    "#     pages_content = [page.text for page in journal_pages]\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"Divide this content into sections:\\n{text}\"\n",
    "#     messages = generate_messages(system_message_section, user_message_wrapper, pages_content)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, section_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for sectioning journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for sectioning.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for sectioning started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_status(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve sectioning batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save sectioned content back to XML\n",
    "#     for i, section_content in enumerate(results):\n",
    "#         journal_pages[i].text = section_content  # Replace original content with sectioned content\n",
    "\n",
    "#     save_xml(journal_pages, output_xml_path)\n",
    "#     print(f\"Sectioned journal saved to {output_xml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from gpt_processing.gpt_interface import (\n",
    "#     set_api_client, \n",
    "#     generate_messages, \n",
    "#     create_jsonl_file_for_batch, \n",
    "#     start_batch, \n",
    "#     get_batch_response\n",
    "# )\n",
    "# from data_processing.xml_processing import (\n",
    "#     load_xml, \n",
    "#     save_xml, \n",
    "#     extract_sections_from_xml\n",
    "# )\n",
    "\n",
    "# # Initialize OpenAI client\n",
    "# set_api_client()\n",
    "\n",
    "# # File paths\n",
    "# INPUT_XML = \"input_journal.xml\"\n",
    "# SECTIONED_XML = \"sectioned_journal.xml\"\n",
    "# TRANSLATED_XML = \"translated_journal.xml\"\n",
    "# BATCH_SECTION_JSONL = \"section_batch.jsonl\"\n",
    "# BATCH_TRANSLATE_JSONL = \"translate_batch.jsonl\"\n",
    "\n",
    "# # System messages\n",
    "# SYSTEM_MESSAGE_SECTION = \"\"\"\n",
    "# You are a helpful assistant. Divide the text into meaningful sections and add XML tags:\n",
    "# <section> for major sections, <subsection> for subsections, <title> for titles, and <p> for paragraphs.\n",
    "# \"\"\"\n",
    "# SYSTEM_MESSAGE_TRANSLATE = \"\"\"\n",
    "# You are Thich Nhat Hanh translating from Vietnamese to English. Provide meaningful translations with appropriate XML tags:\n",
    "# <section>, <subsection>, <title>, <p>.\n",
    "# \"\"\"\n",
    "\n",
    "# # Step 1: Sectioning\n",
    "# def batch_sectioning(input_xml, output_xml):\n",
    "#     # Load the input XML and extract pages or chunks\n",
    "#     journal_pages = load_xml(input_xml)\n",
    "#     pages_content = [page.text for page in journal_pages]  # Assuming .text contains the text of each page\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"Divide this content into sections:\\n{text}\"\n",
    "#     messages = generate_messages(SYSTEM_MESSAGE_SECTION, user_message_wrapper, pages_content)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, BATCH_SECTION_JSONL)\n",
    "\n",
    "#     # Start batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for sectioning journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for sectioning.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for sectioning started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion and retrieve results\n",
    "#     results = get_batch_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve sectioning batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save the sectioned content back to XML\n",
    "#     for i, section_content in enumerate(results):\n",
    "#         journal_pages[i].text = section_content  # Replace original content with sectioned content\n",
    "\n",
    "#     save_xml(journal_pages, output_xml)\n",
    "#     print(f\"Sectioned journal saved to {output_xml}\")\n",
    "\n",
    "# # Step 2: Translation\n",
    "# def batch_translation(input_xml, output_xml):\n",
    "#     # Load the sectioned XML and extract sections or chunks for translation\n",
    "#     sections = extract_sections_from_xml(input_xml)\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(SYSTEM_MESSAGE_TRANSLATE, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, BATCH_TRANSLATE_JSONL)\n",
    "\n",
    "#     # Start batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion and retrieve results\n",
    "#     results = get_batch_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save the translated content back to XML\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         sections[i].text = translated_content  # Replace original content with translated content\n",
    "\n",
    "#     save_xml(sections, output_xml)\n",
    "#     print(f\"Translated journal saved to {output_xml}\")\n",
    "\n",
    "# # Main process\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Step 1: Sectioning\n",
    "#     print(\"Starting batch sectioning...\")\n",
    "#     batch_sectioning(INPUT_XML, SECTIONED_XML)\n",
    "\n",
    "#     # Step 2: Translation\n",
    "#     print(\"Starting batch translation...\")\n",
    "#     batch_translation(SECTIONED_XML, TRANSLATED_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function schema for function calling\n",
    "# function_schemas = [\n",
    "#     {\n",
    "#         \"name\": \"save_processed_metadata\",\n",
    "#         \"description\": \"Save metadata for a processed vietnamese journal, including sections and summaries, that will later be translated\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"journal_summary\": {\"type\": \"string\", \"description\": \"A one-page summary of the journal in English.\"},\n",
    "#                 \"sections\": {\n",
    "#                     \"type\": \"array\",\n",
    "#                     \"items\": {\n",
    "#                         \"type\": \"object\",\n",
    "#                         \"properties\": {\n",
    "#                             \"section_title_vi\": {\"type\": \"string\", \"description\": \"The original title of the section in Vietnamese.\"},\n",
    "#                             \"section_title_en\": {\"type\": \"string\", \"description\": \"The translated title of the section in English.\"},\n",
    "#                             \"section_summary\": {\"type\": \"string\", \"description\": \"A one paragraph summary of the section in English.\"},\n",
    "#                             \"page_range\": {\n",
    "#                                 \"type\": \"array\",\n",
    "#                                 \"items\": {\"type\": \"integer\"},\n",
    "#                                 \"minItems\": 2,\n",
    "#                                 \"maxItems\": 2,\n",
    "#                                 \"description\": \"The start and end page numbers of the section.\"\n",
    "#                             }\n",
    "#                         },\n",
    "#                         \"required\": [\"section_title_en\", \"section_title_vi\", \"section_summary\", \"page_range\"]\n",
    "#                     }\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"journal_summary\", \"sections\"]\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Translation\n",
    "# def batch_translate(input_xml_path, metadata_path):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the sectioned XML\n",
    "#     section_metadata = #load json data from metadata_path and deserialize\n",
    "\n",
    "#     # use the function split_xml_to_pages to get sections for translation:\n",
    "#     sections = split_xml_pages(...)\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # convert the blocks below to a series of nested try blocks with multiple attempts as in batch_section():\n",
    "#     # add appropriate logging to match batch_section():\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_for_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save translated content back to XML\n",
    "#     translated_sections = []\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         translated_sections.append(translated_content)  # Replace original content with translated content\n",
    "\n",
    "#     save_pages_to_xml(translated_sections, translated_xml)\n",
    "#     print(f\"Translated journal saved to {translated_xml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old system message\n",
    "\n",
    "# system_message_section = \"\"\"\n",
    "# You are a highly skilled assistant processing a Vietnamese journal scanned from OCR. \n",
    "# You will be determining the journal sections by page number. You will also generate summaries for the full text and each section. \n",
    "# You will return this metadata in JSON format.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Analyze the text and divide it into sections based on logical breaks, such as headings, topic changes, or clear shifts in content.\n",
    "# 2. Ensure every page is part of  a section, even if that section is titled \"blank page\" or \"title page,\" for example.\n",
    "# 3. For each section, provide:\n",
    "#    - The original title in Vietnamese (`section_title_vi`).\n",
    "#    - The translated title in English (`section_title_en`).\n",
    "#    - The author's name if it is available (`section_author`). \n",
    "#    - A one-paragraph summary of the section in English (`section_summary`).\n",
    "#    - A list of keywords for the section that are related to its content, these can be proper names, specific concepts, or contextual information.\n",
    "#    - The section's start and end page numbers (`start_page` and `end_page`).\n",
    "#    - Use \"null\" for any data that is not available (such as author name) for the section.\n",
    "\n",
    "# 4. Return the output as a JSON object with the following schema:\n",
    "# {\n",
    "#     \"journal_summary\": \"A one-page summary of the whole journal in English.\",\n",
    "#     \"sections\": [\n",
    "#         {\n",
    "#             \"section_title_vi\": \"Original title in Vietnamese\",\n",
    "#             \"section_title_en\": \"Translated title in English\",\n",
    "#             \"section_author\": \"Name of the author of the section\",\n",
    "#             \"section_summary\": \"One-paragraph summary of the section in English\",\n",
    "#             \"section_keywords\": \"A list of keywords for the section\",\n",
    "#             \"start_page\":  X,\n",
    "#             \"end_page\":  Y\n",
    "#         },\n",
    "#         ...\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# 5.  Ensure the JSON is well-formed and adheres strictly to the provided schema.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Translation\n",
    "# def batch_translate(input_xml_path, output_xml_path):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the sectioned XML\n",
    "#     section_metadata = \n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_status(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save translated content back to XML\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         sections[i].text = translated_content  # Replace original content with translated content\n",
    "\n",
    "#     save_pages_to_xml(sections, output_xml_path)\n",
    "#     print(f\"Translated journal saved to {output_xml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Translation\n",
    "# def batch_translate(input_xml_path, metadata_path, journal_name, xml_output_path, max_retries=MAX_BATCH_RETRIES, retry_delay=BATCH_RETRY_DELAY):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "\n",
    "#     Args:\n",
    "#         input_xml_path (str): Path to the input XML file.\n",
    "#         metadata_path (str): Path to the metadata JSON file.\n",
    "#         max_retries (int): Maximum number of retries for batch operations.\n",
    "#         retry_delay (int): Delay in seconds between retries.\n",
    "\n",
    "#     Returns:\n",
    "#         bool: True if the process succeeds, False otherwise.\n",
    "#     \"\"\"\n",
    "#     logger.info(\n",
    "#         f\"starting translation batch {journal_name}...\",\n",
    "#         extra={\n",
    "#             \"input_xml\": input_xml_path,\n",
    "#             \"metadata_path\": metadata_path,\n",
    "#             \"journal_name\": journal_name\n",
    "#         }\n",
    "#     )\n",
    "#     try: # data initialization:\n",
    "#         # get metadata\n",
    "#         section_metadata = deserialize_json(metadata_path)\n",
    "#         section_title = section_metadata.section_title_en\n",
    "\n",
    "#         # Extract page groups and split XML content\n",
    "#         page_groups = extract_page_groups_from_metadata(section_metadata)\n",
    "#         xml_content = get_text_from_file(input_xml_path)\n",
    "#         sections = split_xml_pages(xml_content, page_groups)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         # Log the error with full traceback\n",
    "#         logger.error(\n",
    "#             \"Could not initialize data for translation batching {journal_name}\", exc_info=True)\n",
    "#         raise  # Re-raise the exception to escalate\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section with title {section_title}:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "    \n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "#     if not jsonl_file:\n",
    "#         logger.error(\n",
    "#             \"Failed to create JSONL file for translation batch.\",\n",
    "#             exc_info=True  # Logs the exception traceback if one exists\n",
    "#         )\n",
    "#         raise RuntimeError(\"Failed to create JSONL file for translation batch.\")\n",
    "    \n",
    "#     for attempt in range(max_retries): # batching logic requires multiple retries due to issues with API:\n",
    "#         try:\n",
    "#             # Start the batch\n",
    "#             batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#             batch_id = batch.get(\"id\")\n",
    "#             if not batch_id:\n",
    "#                 raise RuntimeError(\"Batch started but no ID was returned.\")\n",
    "            \n",
    "#             print(f\"Batch for translation started successfully on attempt {attempt + 1}. ID: {batch_id}\")\n",
    "\n",
    "#             # Poll for batch completion\n",
    "#             print(\"Polling for batch completion...\")\n",
    "#             results = poll_batch_for_response(batch_id)\n",
    "\n",
    "#             if results:\n",
    "#                 break # exit the retry loop\n",
    "#             else:\n",
    "#                 raise RuntimeError(\"Unknown error. No results from batch polling.\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(\n",
    "#                 f\"Attempt {attempt + 1} failed during translation for journal '{input_xml_path}'. Retrying in {retry_delay} seconds...\",\n",
    "#                 exc_info=True\n",
    "#             )\n",
    "#             time.sleep(retry_delay)\n",
    "#     else:\n",
    "#         logger.error(f\"Failed to complete translation after {max_retries} retries for journal '{input_xml_path}'.\")\n",
    "#         raise RuntimeError(\"Unable to run translate batch.\")\n",
    "        \n",
    "#     # Save translated content back to XML\n",
    "#     try: \n",
    "#         print(\"Saving translated content back to XML...\")\n",
    "#         translated_sections = []\n",
    "#         for i, translated_content in enumerate(results):\n",
    "#             translated_sections.append(translated_content)\n",
    "\n",
    "#         save_pages_to_xml(translated_sections, xml_output_path, overwrite=True)\n",
    "#         print(f\"Translated journal saved to {xml_output_path}\")\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(\"Failed to save translation data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 17:17:12,289 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AYjv0xkI0XcjvFgsIoqkv6onw62F9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The immediate future of AI is poised to be characterized by several key trends and developments:\\n\\n1. **Continued Advancements in Machine Learning**: Expect ongoing improvements in algorithms, leading to more efficient, robust, and interpretable AI systems. Techniques like transfer learning, reinforcement learning, and unsupervised learning will gain prominence, making AI systems more adaptable and capable of complex tasks with less data.\\n\\n2. **Explainability and Transparency**: With increased AI integration in critical decision-making processes, there will be heightened demand for models that provide clear explanations of their outputs. This aligns with growing regulatory pressures and the need for trustworthiness in AI systems.\\n\\n3. **Ethical AI and Governance**: The focus will intensify on creating frameworks for ethical AI, addressing issues like bias, privacy, and accountability. Companies and governments will work towards establishing clearer policies and standards for AI deployment.\\n\\n4. **Edge AI**: The shift toward edge computing involves deploying AI technologies directly on devices (\"on the edge\") instead of relying solely on centralized cloud systems. This approach reduces latency, improves privacy, and can be more cost-effective, driving broader IoT and real-time analytics applications.\\n\\n5. **Democratization of AI**: Tools and platforms that make AI more accessible to non-experts are advancing, lowering the barriers to entry in AI development and implementation. This democratization will enable more businesses to leverage AI, fueling innovation across industries.\\n\\n6. **Specialized AI Applications**: AI will continue to make inroads into specialized applications such as healthcare (driving diagnostics and personalized medicine), finance (automating trading and fraud detection), and autonomous systems (from vehicles to drones).\\n\\n7. **Hybrid AI Models**: Combining various AI approaches, such as integrating symbolic reasoning with neural networks, will gain traction. These hybrid models aim to leverage the strengths of different methodologies, paving the way for more versatile and powerful AI systems.\\n\\n8. **Collaboration between AI and Human Experts**: Rather than replacing human roles, AI systems will increasingly be designed to augment human capabilities, assisting experts in making more informed decisions, and streamlining workflows.\\n\\n9. **Sustainability**: There will be a stronger emphasis on reducing the environmental impact of AI, particularly in relation to energy-intensive training processes. Research into more sustainable AI practices will expand, focusing on efficiency and resource conservation.\\n\\n10. **Increased Focus on Continuous Learning**: AI systems capable of continuous learning will be developed, enabling systems to adapt and evolve as new data and scenarios arise, rather than relying solely on traditional retraining cycles.\\n\\nAs these trends evolve, the field of AI will continue to redefine itself, opening up new possibilities and challenges. Building systems that are not only powerful but also ethical and sustainable will be crucial in shaping the trajectory of AI\\'s immediate future.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732843026, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_7f6be3efb0', usage=CompletionUsage(completion_tokens=563, prompt_tokens=40, total_tokens=603, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "set_api_client()\n",
    "msgs = generate_messages(\"you are assisting a software engineering/researcher looking to develop new AI platforms and processes.\", lambda x: x, [\"why is AI suddenly successful?\", \"What is the (immediate) future of AI?\"])\n",
    "run_immediate_chat_process(msgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model_settings = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 3000,\n",
    "        \"context_limit\": 20000,  # Total context limit for the model\n",
    "        \"temperature\": 1.3\n",
    "    }}\n",
    "\n",
    "set_model_settings(model_settings)\n",
    "batch_id = run_single_oa_batch([\"what is the square root of 2?\", \"why is the sky blue?\"], \"you are are explaining complex ideas to a 9 year old child.\")\n",
    "\n",
    "poll_batch_for_response(batch_id, 10)\n",
    "\n",
    "msgs = generate_messages(\"you are assisting a software engineering/researcher looking to develop new AI platforms and processes.\", lambda x: x, [\"why is AI suddenly successful?\", \"What is the (immediate) future of AI?\"])\n",
    "run_immediate_chat_process(msgs[1])\n",
    "\n",
    "get_last_batch_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
