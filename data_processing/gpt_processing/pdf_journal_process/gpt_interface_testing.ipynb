{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the logger\n",
    "def setup_logger(log_file_path):\n",
    "    \"\"\"\n",
    "    Configures the logger to write to a log file and the console.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()  # Optional: to log to the console as well\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from data_processing.gpt_processing import (\n",
    "    set_api_client, \n",
    "    generate_messages, \n",
    "    create_jsonl_file_for_batch, \n",
    "    start_batch, \n",
    "    get_batch_response,\n",
    "    get_completed_batches,\n",
    "    set_model_settings,\n",
    "    get_batch_status,\n",
    "    get_active_batches,\n",
    "    get_all_batch_info,\n",
    "    token_count,\n",
    "    run_immediate_chat_process,\n",
    "    run_single_batch,\n",
    "    get_last_batch_response,\n",
    "    delete_old_files\n",
    ")\n",
    "\n",
    "from data_processing.xml_processing import ( \n",
    "    save_pages_to_xml,\n",
    "    split_xml_pages\n",
    ")\n",
    "\n",
    "from data_processing.text_processing import (\n",
    "    get_text_from_file,\n",
    "    write_text_to_file\n",
    ")\n",
    "from pathlib import Path\n",
    "%aimport time\n",
    "%aimport json\n",
    "%aimport datetime\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(\"tmp.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 10:10:51,999 - INFO - Open AI API client successfully set: <openai.OpenAI object at 0x11847d7d0>\n"
     ]
    }
   ],
   "source": [
    "# Set up API client\n",
    "client = set_api_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,\n",
    "        \"context_limit\": 20000,  # Total context limit for the model\n",
    "        \"temperature\": 0.25\n",
    "    },\n",
    "    \"gpt-3.5-turbo\": {\n",
    "        \"max_tokens\": 4096,  # Set conservatively to avoid errors\n",
    "        \"context_limit\": 16384  # Same as gpt-4o\n",
    "        }\n",
    "    }\n",
    "\n",
    "set_model_settings(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "project_dir = Path(\"/Users/phapman/Desktop/tnh-scholar/\")\n",
    "data_dir = project_dir / \"data_processing\"\n",
    "journal_dir = data_dir / \"processed_journal_data\"\n",
    "journal_name = \"phat-giao-viet-nam-1956-01\"\n",
    "working_dir = journal_dir / journal_name\n",
    "input_xml = working_dir / f\"TEST2_full_cleaned_{journal_name}.xml\"\n",
    "translated_xml = journal_dir / f\"translation_{journal_name}.xml\"\n",
    "section_batch_jsonl = working_dir / \"section_batch.jsonl\"\n",
    "translate_batch_jsonl = working_dir / \"translation_batch.jsonl\"\n",
    "section_metadata = working_dir / \"section_metadata.json\"\n",
    "logfile = data_dir / \"gpt_processing\" / \"processing_info.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 10:10:54,647 - INFO - HTTP Request: GET https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:55,039 - INFO - HTTP Request: DELETE https://api.openai.com/v1/files/file-TP94fRELZTYEv7EC65xRby \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:55,041 - INFO - Deleted file: file-TP94fRELZTYEv7EC65xRby (created on 2024-11-30 10:07:58)\n",
      "2024-11-30 10:10:55,444 - INFO - HTTP Request: DELETE https://api.openai.com/v1/files/file-MNXZLzdmXmLpwsGJdoSuNb \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:55,446 - INFO - Deleted file: file-MNXZLzdmXmLpwsGJdoSuNb (created on 2024-11-30 10:07:41)\n",
      "2024-11-30 10:10:55,901 - INFO - HTTP Request: DELETE https://api.openai.com/v1/files/file-JcnBXipepk8N6Zf7KwEnk2 \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:55,904 - INFO - Deleted file: file-JcnBXipepk8N6Zf7KwEnk2 (created on 2024-11-30 09:34:57)\n",
      "2024-11-30 10:10:56,088 - INFO - HTTP Request: DELETE https://api.openai.com/v1/files/file-CYHLaAKtgGkDrkrhQLJLE2 \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:56,092 - INFO - Deleted file: file-CYHLaAKtgGkDrkrhQLJLE2 (created on 2024-11-30 09:34:41)\n",
      "2024-11-30 10:10:56,268 - INFO - HTTP Request: DELETE https://api.openai.com/v1/files/file-SNTJ9HbhDXgFijE7aKeFDK \"HTTP/1.1 200 OK\"\n",
      "2024-11-30 10:10:56,273 - INFO - Deleted file: file-SNTJ9HbhDXgFijE7aKeFDK (created on 2024-11-30 09:34:24)\n"
     ]
    }
   ],
   "source": [
    "delete_old_files(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
