{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_nltk_data():\n",
    "    \"\"\"Ensure NLTK punkt tokenizer is available.\"\"\"\n",
    "    try:\n",
    "        # Try to find the resource\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        # If not found, try downloading\n",
    "        try:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            # Verify download\n",
    "            nltk.data.find('tokenizers/punkt')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to download required NLTK data. \"\n",
    "                \"Please run 'python -m nltk.downloader punkt' \"\n",
    "                f\"to install manually. Error: {e}\"\n",
    "            ) from e\n",
    "\n",
    "# Call this before sentence tokenization\n",
    "ensure_nltk_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic NLTK sentence splitting test\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Test on a simple string\n",
    "text = \"This is sentence one. This is sentence two! Is this sentence three? Yes it is.\"\n",
    "\n",
    "# Try tokenizing\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Tokenized sentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample Vietnamese text\n",
    "text = \"\"\"\n",
    "Thầy thường dạy chúng ta phải biết lắng nghe. Lắng nghe là một nghệ thuật. \n",
    "Khi lắng nghe với tâm từ bi, ta có thể hiểu được nỗi khổ của người khác. \n",
    "Ta phải tập ngồi yên và thở. Hơi thở là cây cầu nối liền thân và tâm.\n",
    "\"\"\"\n",
    "\n",
    "# Test Spacy\n",
    "nlp_vi = spacy.load(\"xx_sent_ud_sm\")  # Universal dependencies model\n",
    "start = time.time()\n",
    "doc = nlp_vi(text)\n",
    "spacy_sents = list(doc.sents)\n",
    "spacy_time = time.time() - start\n",
    "\n",
    "# Test NLTK\n",
    "start = time.time()\n",
    "nltk_sents = sent_tokenize(text, language='vietnamese')\n",
    "nltk_time = time.time() - start\n",
    "\n",
    "print(\"Spacy sentences:\", len(spacy_sents))\n",
    "for sent in spacy_sents:\n",
    "    print(f\"- {sent}\")\n",
    "    \n",
    "print(\"\\nNLTK sentences:\", len(nltk_sents))\n",
    "for sent in nltk_sents:\n",
    "    print(f\"- {sent}\")\n",
    "\n",
    "print(f\"\\nTiming - Spacy: {spacy_time:.3f}s, NLTK: {nltk_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
