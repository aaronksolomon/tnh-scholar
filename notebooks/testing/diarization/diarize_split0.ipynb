{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tnh_scholar.cli_tools.audio_transcribe.diarize_poc3 import (\n",
    "    extract_audio_segments,\n",
    "    load_diarization_result,\n",
    "    merge_speaker_segments,\n",
    "    plt,\n",
    "    process_diarization,\n",
    "    transform_srt,\n",
    "    visualize_merged_timeline,\n",
    "    visualize_results,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_dir = Path.home() / \"Desktop/transcription_wouter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file_path = working_dir \\\n",
    "#     / \"audio_transcriptions\"  \\\n",
    "#     / \"Sr. Abbess Interview Thay's Hut (for transcription).mp3\"\n",
    "# if not audio_file_path.exists:\n",
    "#     raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file_path = working_dir \\\n",
    "#     / \"audio_transcriptions\"  \\\n",
    "#     / \"Sr. Abbess Interview Thay's Hut (for transcription)_segments\" \\\n",
    "#     / \"raw_diarization_results.json\"\n",
    "# if not data_file_path.exists:\n",
    "#     raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path.home() / \"Desktop/trans_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = working_dir \\\n",
    "    / \"audio_transcriptions\"  \\\n",
    "    / \"neil_degrasse_tyson_s_5_m_PFHVYKrNpNk.mp3\"\n",
    "if not audio_file_path.exists:\n",
    "    raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = working_dir \\\n",
    "    / \"audio_transcriptions\"  \\\n",
    "    / \"neil_degrasse_tyson_s_5_m_PFHVYKrNpNk_segments\" \\\n",
    "    / \"raw_diarization_results.json\"\n",
    "if not data_file_path.exists:\n",
    "    raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_export_path = working_dir \\\n",
    "    / \"audio_transcriptions\"  \\\n",
    "    / \"neil_degrasse_tyson_s_5_m_PFHVYKrNpNk_segments\" \\\n",
    "    / \"export_test\"\n",
    "if not data_file_path.exists:\n",
    "    raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the processing\n",
    "segments = load_diarization_result(file_path=data_file_path)\n",
    "speaker_blocks = merge_speaker_segments(segments)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nProcessed speaker blocks:\")\n",
    "for speaker, blocks in speaker_blocks.items():\n",
    "    total_duration = sum(end - start for start, end in blocks)\n",
    "    print(f\"{speaker}: {len(blocks)} blocks, {total_duration:.3f}s total\")\n",
    "    for i, (start, end) in enumerate(blocks):\n",
    "        print(f\"  Block {i+1}: {start:.3f}s - {end:.3f}s ({end-start:.3f}s)\")\n",
    "\n",
    "# Create visualization\n",
    "fig = visualize_results(segments, speaker_blocks)\n",
    "plt.show()  # This will display in the notebook\n",
    "\n",
    "# Merged visualization\n",
    "fig2 = visualize_merged_timeline(speaker_blocks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_blocks = extract_audio_segments(audio_file_path, speaker_blocks, output_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_blocks['SPEAKER_02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_blocks['SPEAKER_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_blocks['SPEAKER_02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_dir = working_dir \\\n",
    "    / \"audio_transcriptions\"  \\\n",
    "    / \"neil_degrasse_tyson_s_5_m_PFHVYKrNpNk_segments\" \\\n",
    "    / \"export_test\" \\\n",
    "    / \"audio_transcriptions\" \\\n",
    "    / \"SPEAKER_02\" \n",
    "\n",
    "srt_path = srt_dir / \"test_neil.srt\"\n",
    "srt_conv = srt_dir / \"conv_neil.srt\"\n",
    "\n",
    "if not srt_path.exists():\n",
    "    raise FileNotFoundError(\"Audio file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_srt(srt_path, mapped_blocks['SPEAKER_02'], srt_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "177\n",
    "00:08:24,980 --> 00:08:26,740\n",
    "So we have to figure that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs_start = 8*60+24.980\n",
    "secs_end = 8*60+26.74\n",
    "secs_start, secs_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_start = secs_start * 1000\n",
    "ms_end = secs_end * 1000\n",
    "ms_start, ms_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "504980 - 503260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "937265 + 1720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have the required function in diarize_poc3.py to extract speaker blocks and export them to a single file as desired for my new diarization pipeline. \n",
    "\n",
    "The next step in the PoC development process is to take an SRT based on a single speaker transcription (+ the time spacing used between blocks) and entry by entry in the SRT, map the time in this SRT back to the original audio file. I've already done some of this by hand for testing.\n",
    "\n",
    "I too a particular line from the speaker SRT file:\n",
    "\n",
    "177\n",
    "00:08:24,980 --> 00:08:26,740\n",
    "So we have to figure that out.\n",
    "\n",
    "converted the start and end times to ms: 504980, 506740\n",
    "\n",
    "now I can look at the mapped speaker blocks and searching through the export positions I find a series of blocks:\n",
    "\n",
    "... (913145, 924845, 490560), (937265, 974385, 503260), (987725, 1007325, 541380)]\n",
    "\n",
    "as 504980 > 503260 and 506740 < 541380,\n",
    "\n",
    "we find that this segment belongs to the original interval (937265, 974385) and that the original time point 937265 maps to the time point 503260 in the speaker file, so the delta of the particular entry is (504980 -  503260) is 1720, so the entry should occur at start time 937265 + 1720 = 938985 in ms. \n",
    "\n",
    "If this is the right logic, we have found a way to speaker SRT time entries to original file entries. Please give this as a module to, transform a Speaker SRT to Original SRT given the SRT file (as Path) and a Speaker mapped blocks object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "938985 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "938 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "938 - (15 *60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15:38.985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_blocks['SPEAKER_03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
