{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from v2_cleaning_scripts import process_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../books/transformation_and_healing-thich_nhat_hanh.txt', 'r') as f:\n",
    "    book_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load a pretrained model, e.g., for sentence and chapter recognition\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def process_book(book_text):\n",
    "    \"\"\"\n",
    "    Process text to extract chapters and paragraphs using spaCy NLP model.\n",
    "    \n",
    "    Args:\n",
    "        book_text (str): Raw text of the book.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of (chapter_title, chapter_content) tuples.\n",
    "    \"\"\"\n",
    "    doc = nlp(book_text)\n",
    "    chapters = []\n",
    "    chapter_title = \"\"\n",
    "    chapter_content = []\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        if \"chapter\" in sent.text.lower():\n",
    "            # Store previous chapter if any\n",
    "            if chapter_title:\n",
    "                chapters.append((chapter_title, \" \".join(chapter_content)))\n",
    "            chapter_title = sent.text.strip()\n",
    "            chapter_content = []\n",
    "        else:\n",
    "            chapter_content.append(sent.text.strip())\n",
    "    \n",
    "    if chapter_title:\n",
    "        chapters.append((chapter_title, \" \".join(chapter_content)))\n",
    "    \n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(book_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sents[:200]:\n",
    "    print(f\">>{s}<<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entlist = list(doc.ents)\n",
    "for ent in entlist[:200]:\n",
    "    print(f\">>{ent.text}, {ent.label_}<<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_chapters = process_book(book_text)\n",
    "for title, content in processed_chapters:\n",
    "    print(f\"{title}: {content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from v2_cleaning_scripts import classify_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # Check if MPS is available for GPU computations on macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier\n",
    "sample_text = \"EXERCISES FOR OBSERVING THE BODY\"\n",
    "if classify_heading(sample_text):\n",
    "    print(f\"'{sample_text}' is classified as a heading.\")\n",
    "else:\n",
    "    print(f\"'{sample_text}' is classified as body text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Check if MPS is available and set the device accordingly\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Load the pre-trained BERT model for classification\n",
    "classifier = pipeline('zero-shot-classification', model=\"facebook/bart-large-mnli\", device=0 if device == \"mps\" else -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example classification\n",
    "text = \"Mindfulness is the practice of being fully aware of the present moment.\"\n",
    "candidate_labels = [\"mind\", \"presence\", \"direct\", \"awareness\", \"sentence\", \"paragraph\"]\n",
    "\n",
    "# Perform classification\n",
    "result = classifier(text, candidate_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_heading(text):\n",
    "    \"\"\"\n",
    "    Classifies text as heading or not using a Hugging Face model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to classify.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the text is classified as a heading, otherwise False.\n",
    "    \"\"\"\n",
    "    # Define candidate labels for zero-shot classification\n",
    "    candidate_labels = [\"label\", \"paragraph\"]\n",
    "\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result['labels'][0] == \"heading\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_heading(\"EXERCISES FOR OBSERVING THE BODY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_lines(text, classifier):\n",
    "    \"\"\"\n",
    "    Iterate through each line of the input text and classify it as a heading or not.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full text to process line by line.\n",
    "        classifier (pipeline): Hugging Face classifier pipeline.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples with (line, classification).\n",
    "\n",
    "    # Example usage\n",
    "        sample_text = \n",
    "        \n",
    "            EXERCISES FOR OBSERVING THE BODY\n",
    "\n",
    "            The First Establishment of Mindfulness is the body, which includes the breath, the positions of the body,\n",
    "\n",
    "    result = classify_text_lines(sample_text, classifier)\n",
    "    for line, classification in result:\n",
    "    print(f\"Line: {line}\\nClassification: {classification}\\n\")\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    classified_lines = []\n",
    "    for line in text.splitlines():\n",
    "        if line.strip():  # Skip empty lines\n",
    "            result = classifier(line, [\"heading\", \"paragraph\"])\n",
    "            classification = \"heading\" if result['labels'][0] == \"heading\" else \"non-heading\"\n",
    "            classified_lines.append((line, classification))\n",
    "    \n",
    "    return classified_lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classify_text_lines(book_text, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", device=0)\n",
    "result = ner(\"EXERCISES FOR OBSERVING THE BODY\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner(\"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner(\"Thich Nhat Hanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner(\"Mindfulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
