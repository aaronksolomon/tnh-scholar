{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport bs4, ebooklib, spacy, html.parser\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from ebooklib import epub\n",
    "\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_parse_tag import extract_tags_by_attributes, get_all_tag_names, get_all_attribute_values \n",
    "from clean_parse_tag import remove_all_tags_with_attribute, remove_tags_with_attribute, remove_attributes, remove_empty_tags, unwrap_redundant_tags\n",
    "from clean_parse_tag import remove_tag_whitespace, normalize_newlines, clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_parse_tag import set_working_directory, get_text_from_file, write_text_to_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH_book_path = \"../books/private_books/Transformation_and_Healing-Thich_Nhat_Hanh.epub\"\n",
    "LiA_book_path = \"../books/private_books/Love_in_Action-Thich_Nhat_Hanh.epub\"\n",
    "TH_epub_book = epub.read_epub(TH_book_path)\n",
    "LiA_epub_book = epub.read_epub(LiA_book_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = [BeautifulSoup(item.get_body_content(), 'html.parser') for item in TH_epub_book.get_items_of_media_type('application/xhtml+xml')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[18].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups[18].find_all('br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_tag_names(soups[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = set()\n",
    "for i, soup in enumerate(soups):\n",
    "    tags = get_all_tag_names(soup)\n",
    "    for tag in tags:\n",
    "        tagset.add(tag)\n",
    "print(tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, soup in enumerate(soups):\n",
    "    print(i, soup.find_all('sup'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tag_dict(soup_list):\n",
    "    tag_dict = {tag: {} for tag in tagset}\n",
    "    for soup in soup_list:\n",
    "        for tag in tagset:\n",
    "            attr_dict = get_all_attribute_values(soup, tag)\n",
    "            for attr, value_set in attr_dict.items():\n",
    "                if attr in tag_dict[tag]:\n",
    "                    tag_dict[tag][attr].update(value_set)\n",
    "                else:\n",
    "                    tag_dict[tag][attr] = value_set\n",
    "    return tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tag_dict(soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[1].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[18].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, \"style\", r\"margin*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[1].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, \"class\", r\"calibre*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, \"id\", r\"filepos.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, 'class', 'mbp_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, 'id', \"calibre_pb*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_attributes(soup, 'href', \"index_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "    remove_empty_tags(soup, ['p', 'span', 'div', 'blockquote', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[1].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soup in soups:\n",
    "   unwrap_redundant_tags(soup, ['a', 'span'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[1].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tag_dict(soups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin code to explore matching html data with text data:\n",
    "\n",
    "key idea is to use an html parser and event stream to parse the html tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_working_directory('../books/private_books')\n",
    "text = get_text_from_file('transformation_and_healing_tnh.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = normalize_newlines(text, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_text_to_file('test_th_output.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soups[18].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_html = clean_text(str(soups[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_html = remove_tag_whitespace(cleaned_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_non_breaking_space(text):\n",
    "    \"\"\"\n",
    "    Check if a string contains the non-breaking space character (Unicode \\xa0).\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The string to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if \\xa0 is found, False otherwise.\n",
    "    \"\"\"\n",
    "    return \"\\xa0\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_non_breaking_space(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_non_breaking_space(cleaned_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = text[:307].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLTextMatcher(HTMLParser):\n",
    "    def __init__(self, text_data):\n",
    "        super().__init__()\n",
    "        self.text_iterator = iter(text_data)  # Iterator over the text lines or words\n",
    "        self.current_text_segment = next(self.text_iterator, \"\").strip()\n",
    "        self.mismatches = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        # We may want to log start tags, but they typically don't have matching text\n",
    "        print(f\"Start tag: <{tag}>\")\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        print(f\"End tag: </{tag}>\")\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        html_text = data.strip()\n",
    "        \n",
    "        if html_text:\n",
    "            print(f\"HTML Text: {html_text}\")\n",
    "\n",
    "            # Attempt to match with the current segment of the text document\n",
    "            if self.current_text_segment == html_text:\n",
    "                print(f\"Matched: {html_text}\")\n",
    "                # Move to the next text segment after a match\n",
    "                self.current_text_segment = next(self.text_iterator, \"\").strip()\n",
    "            else:\n",
    "                # Log the mismatch for later review\n",
    "                print(f\"Mismatch: HTML='{html_text}' vs Text='{self.current_text_segment}'\")\n",
    "                self.mismatches.append((html_text, self.current_text_segment))\n",
    "                # Advance to the next segment even on mismatch to keep up with the stream\n",
    "                self.current_text_segment = next(self.text_iterator, \"\").strip()\n",
    "\n",
    "    def get_mismatches(self):\n",
    "        return self.mismatches\n",
    "\n",
    "# # Sample usage\n",
    "# html_data = \"\"\"\n",
    "# <body>\n",
    "#  <p><span class=\"bold\">Table of Contents</span></p>\n",
    "#  <p><span class=\"italic\"><span class=\"underline\">Title Page</span></span></p>\n",
    "#  <p><span class=\"italic\"><span class=\"underline\">A NOTE ON THE TEXT</span></span></p>\n",
    "#  <p><span class=\"italic\"><span class=\"underline\">Introduction</span></span></p>\n",
    "#  <p><span class=\"italic\"><span class=\"underline\">Sutra on the Four Establishments of Mindfulness</span></span></p>\n",
    "# </body>\n",
    "# \"\"\"\n",
    "# text_data = [\n",
    "#     \"Transformation and Healing: Sutra on the Four Establishments of Mindfulness\",\n",
    "#     \"Table of Contents\",\n",
    "#     \"Title Page\",\n",
    "#     \"A NOTE ON THE TEXT\",\n",
    "#     \"Introduction\",\n",
    "#     \"Sutra on the Four Establishments of Mindfulness\",\n",
    "# ]\n",
    "\n",
    "# # Instantiate the matcher with text data\n",
    "# parser = HTMLTextMatcher(text_data)\n",
    "# # Feed the cleaned HTML data\n",
    "# parser.feed(html_data)\n",
    "\n",
    "# # Review mismatches, if any\n",
    "# print(\"Mismatches found:\", parser.get_mismatches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class HTMLPlainTextMatcher(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.plain_text = \"\"         # Accumulated plain text without tags\n",
    "        self.tag_map = []            # Stores tag position data\n",
    "        self.current_index = 0       # Tracks position in the plain text\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        # Convert attributes to a string format, e.g., <tag attr1=\"val1\" attr2=\"val2\">\n",
    "        attr_str = \" \".join(f'{key}=\"{value}\"' for key, value in attrs)\n",
    "        full_tag = f\"<{tag} {attr_str}>\" if attr_str else f\"<{tag}>\"\n",
    "\n",
    "        # Log start of the tag with the current index\n",
    "        self.tag_map.append((self.current_index, None, full_tag))\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        # Find last open tag in tag_map for this tag type and close it with the current index\n",
    "        for i in range(len(self.tag_map) - 1, -1, -1):\n",
    "            if self.tag_map[i][1] is None and self.tag_map[i][2].startswith(f\"<{tag}\"):\n",
    "                self.tag_map[i] = (self.tag_map[i][0], self.current_index, self.tag_map[i][2])  # Update with end_index\n",
    "                break\n",
    "         # Close <p> tags with double newline for paragraph separation\n",
    "        if tag in ['p', 'blockquote']:\n",
    "            self.plain_text += \"\\n\\n\"  # Add double newline after closing <p>\n",
    "            self.current_index += 2  # Update index to account for newlines\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        # Strip the single unit of text and add double newline for readability\n",
    "        # stripped_data = data.strip() # don't strip data; save whitespace to match text.\n",
    "        if data:\n",
    "            self.plain_text += data\n",
    "            self.current_index += len(data)  # Update position after adding text and newlines\n",
    "\n",
    "    def handle_startendtag(self, tag, attrs):\n",
    "        # Capture full tag with attributes, if present, for logging\n",
    "        attr_str = \" \".join(f'{key}=\"{value}\"' for key, value in attrs)\n",
    "        full_tag = f\"<{tag} {attr_str} />\" if attr_str else f\"<{tag} />\"\n",
    "        self.tag_map.append((self.current_index, full_tag))\n",
    "\n",
    "        # For <br> add newlines for readability\n",
    "        if tag == \"br\":\n",
    "            self.plain_text += \"\\n\\n\"  # Single newline for line break\n",
    "            self.current_index += 2  # Update index for newline\n",
    "\n",
    "    def get_plain_text(self):\n",
    "        return self.plain_text\n",
    "\n",
    "    def get_tag_map(self):\n",
    "        return self.tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HTMLPlainTextMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.feed(cleaned_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parser.plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "# Example of using SequenceMatcher for diff alignment\n",
    "html_test_text = parser.plain_text\n",
    "plain_text_test = text\n",
    "\n",
    "html_data = html_test_text #.split()\n",
    "text_data = plain_text_test #.split()\n",
    "\n",
    "# Create a SequenceMatcher object\n",
    "matcher = difflib.SequenceMatcher(None, html_data, text_data)\n",
    "\n",
    "# Get matching blocks\n",
    "matches = matcher.get_matching_blocks()\n",
    "for match in matches:\n",
    "    print(\"Match found:\", match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data[77:77+609]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the start index and length of a matching block\n",
    "for match in matches:\n",
    "    start = match.a  # Starting index in html_data\n",
    "    length = match.size  # Number of matching words\n",
    "\n",
    "    # Retrieve the matching words\n",
    "    matching_words = html_data[start:start + length]\n",
    "    print(\"Matching words:\", matching_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(html_data), len(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
