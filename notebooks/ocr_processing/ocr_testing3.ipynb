{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from xml.sax.saxutils import escape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts metadata of images embedded in each page of a scanned PDF,\n",
    "    including page dimensions in points and inches, and calculates DPI if missing.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_metadata = []\n",
    "    \n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        \n",
    "        # Get page dimensions in points and inches\n",
    "        page_width_pts, page_height_pts = page.rect.width, page.rect.height\n",
    "        page_width_in = page_width_pts / 72  # Convert points to inches\n",
    "        page_height_in = page_height_pts / 72\n",
    "        \n",
    "        # Extract the list of images on this page\n",
    "        images = page.get_images(full=True)  # 'full=True' gets all images on page\n",
    "        \n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]  # Image reference number\n",
    "            \n",
    "            try:\n",
    "                # Attempt to extract the image and retrieve its metadata\n",
    "                base_image = doc.extract_image(xref)\n",
    "                \n",
    "                # Retrieve metadata about the image\n",
    "                width_px, height_px = base_image[\"width\"], base_image[\"height\"]\n",
    "                dpi_x, dpi_y = base_image.get(\"dpi\", (None, None))\n",
    "                image_metadata.append({\n",
    "                            \"index\": img_index,\n",
    "                            \"width\": width_px,\n",
    "                            \"height\": height_px,\n",
    "                            \"dpi_x\": dpi_x,\n",
    "                            \"dpi_y\": dpi_y\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting image from {pdf_path}, page {page_num}, at index {img_index}: {e}\")\n",
    "                continue  # Skip to the next image if extraction fails\n",
    "            \n",
    "            # Calculate DPI if not provided\n",
    "            if dpi_x is None or dpi_y is None:\n",
    "                dpi_x = width_px / page_width_in\n",
    "                dpi_y = height_px / page_height_in\n",
    "            \n",
    "            # Append metadata, including page dimensions and calculated DPI\n",
    "            image_metadata.append({\n",
    "                \"page\": page_num + 1,\n",
    "                \"image_index\": img_index + 1,\n",
    "                \"width_px\": width_px,\n",
    "                \"height_px\": height_px,\n",
    "                \"format\": base_image[\"ext\"],\n",
    "                \"dpi_x\": dpi_x,\n",
    "                \"dpi_y\": dpi_y,\n",
    "                \"page_width_pts\": page_width_pts,\n",
    "                \"page_height_pts\": page_height_pts,\n",
    "                \"page_width_in\": page_width_in,\n",
    "                \"page_height_in\": page_height_in,\n",
    "            })\n",
    "    \n",
    "    doc.close()\n",
    "    return image_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_processed_pdf(directory, filename):\n",
    "    pil_images = []\n",
    "    text_pages = []\n",
    "\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    print(f\"beginning to process: {file_path}\")\n",
    "\n",
    "    # Load PDF and extract image bytes from a given page\n",
    "    doc = fitz.open(file_path)\n",
    "\n",
    "    for page_num in range(doc.page_count):\n",
    "        print(f\"processing page: {page_num}...\")\n",
    "        \n",
    "        page = doc.load_page(page_num)  # Load the first page\n",
    "        images = page.get_images(full=True)\n",
    "        xref = images[0][0]  # Get the first image reference\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]  # Get the raw JPEG byte content\n",
    "\n",
    "        # Convert to PIL Image for further processing if needed\n",
    "        p_image = Image.open(io.BytesIO(image_bytes))\n",
    "        pil_images.append(p_image)\n",
    "\n",
    "        # Annotate with vision\n",
    "        image = vision.Image(content=image_bytes)\n",
    "        response = client.text_detection(image=image)\n",
    "        text_annotations = response.text_annotations\n",
    "\n",
    "        # Build labeled image\n",
    "        font_size = 15  \n",
    "        font_path=\"/System/Library/Fonts/Supplemental/Arial.ttf\"\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "        draw = ImageDraw.Draw(p_image)\n",
    "        for i, text_obj in enumerate(text_annotations):\n",
    "            # Get the bounding box vertices\n",
    "            vertices = [(vertex.x, vertex.y) for vertex in text_obj.bounding_poly.vertices]\n",
    "\n",
    "            # Draw a polygon based on the bounding box\n",
    "            if len(vertices) == 4:\n",
    "                draw.polygon(vertices, outline=\"red\", width=2)\n",
    "                if i > 0: # first bounding box is whole text region\n",
    "                    draw.text(vertices[0], text_obj.description, fill=\"red\", font=font)\n",
    "\n",
    "        full_page_text = text_annotations[0].description  # always the first text_annotation object\n",
    "        text_pages.append(full_page_text)\n",
    "\n",
    "    return text_pages, pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def save_annotated_text_and_image_data(root_dir, data_location, text_data, image_data):\n",
    "    \"\"\"\n",
    "    Creates a directory structure to save images, text data, and an HTML gallery for viewing.\n",
    "    \n",
    "    Parameters:\n",
    "        root_dir (str): The root directory to store data.\n",
    "        data_location (str): Directory location under root_dir for storing files.\n",
    "        text_data (list of str): List of extracted text for each page.\n",
    "        image_data (list of tuples): List of tuples, where each tuple contains the image filename (str) \n",
    "                                     and the image data (as bytes or PIL image).\n",
    "                                     \n",
    "    \"\"\"\n",
    "    # Create directory paths\n",
    "    base_dir = os.path.join(root_dir, data_location)\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    images_dir = os.path.join(base_dir, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    # File paths for JSONL and HTML files\n",
    "    jsonl_file_path = os.path.join(base_dir, \"extracted_text.jsonl\")\n",
    "    html_file_path = os.path.join(base_dir, \"index.html\")\n",
    "    \n",
    "    # Step 1: Save text data to JSONL\n",
    "    with open(jsonl_file_path, \"w\", encoding=\"utf-8\") as jsonl_file:\n",
    "        for i, text in enumerate(text_data):\n",
    "            entry = {\n",
    "                \"image\": f\"images/page{i+1}.jpg\",  # Image filename\n",
    "                \"text\": text\n",
    "            }\n",
    "            jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
    "    \n",
    "    # Step 2: Save images to the images directory\n",
    "    for i, img in enumerate(image_data):\n",
    "        image_path = os.path.join(images_dir, f\"page{i+1}.jpg\")\n",
    "        img.save(image_path, format=\"JPEG\")\n",
    "    \n",
    "    # Step 3: Generate HTML file for viewing\n",
    "    with open(html_file_path, \"w\", encoding=\"utf-8\") as html_file:\n",
    "        html_file.write(\"<html><head><title>Annotated Image Gallery</title></head><body>\\n\")\n",
    "        html_file.write(\"<h1>Annotated Image Gallery</h1>\\n\")\n",
    "        \n",
    "        for i, text in enumerate(text_data):\n",
    "            img_filename = f\"images/page{i+1}.jpg\"\n",
    "            html_file.write(\"<div class='image-entry'>\\n\")\n",
    "            html_file.write(f\"  <img src='{img_filename}' alt='Page {i+1}' style='width:100%; max-width:600px;'>\\n\")\n",
    "            html_file.write(f\"  <textarea readonly style='width:100%; height:150px;'>{text}</textarea>\\n\")\n",
    "            html_file.write(\"</div><br>\\n\")\n",
    "        \n",
    "        html_file.write(\"</body></html>\")\n",
    "\n",
    "    print(f\"Data successfully saved in {base_dir}\")\n",
    "\n",
    "# Example usage:\n",
    "# save_annotated_text_and_image_data(root_dir=\"my_data\", data_location=\"ocr_project\", text_data=[\"text1\", \"text2\"], image_data=[(\"img1.jpg\", img_bytes), (\"img2.jpg\", img_bytes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_xml_text_file(root_dir, title_file, text_data):\n",
    "    \"\"\"\n",
    "    Generates and saves an XML file with a title and pages, where each page contains text data.\n",
    "    \n",
    "    Parameters:\n",
    "        root_dir (str): The root directory where the XML file will be saved.\n",
    "        title_file (str): The title to be used in the XML file and filename.\n",
    "        text_data (list of str): List of extracted text for each page.\n",
    "    \"\"\"\n",
    "    # Define the XML file path\n",
    "    xml_file_path = os.path.join(root_dir, title_file, f\"full_OCR_text_{title_file}.xml\")\n",
    "    os.makedirs(os.path.dirname(xml_file_path), exist_ok=True)\n",
    "    \n",
    "    # Start writing the XML file\n",
    "    with open(xml_file_path, \"w\", encoding=\"utf-8\") as xml_file:\n",
    "        # Write XML declaration and root element with title\n",
    "        xml_file.write(\"<?xml version='1.0' encoding='UTF-8'?>\\n\")\n",
    "        xml_file.write(f\"<document>\\n  <title>{escape(title_file)}</title>\\n\")\n",
    "        \n",
    "        # Add each page with its content, escaping the text for XML safety\n",
    "        for i, text in enumerate(text_data):\n",
    "            # Escape text content to handle special characters\n",
    "            escaped_text = escape(text)\n",
    "            # Write each page as <page page=\"1\">...</page>\n",
    "            xml_file.write(f\"  <page page='{i+1}'>\\n\")\n",
    "            xml_file.write(f\"    {escaped_text}\\n\")\n",
    "            xml_file.write(\"  </page>\\n\")\n",
    "        \n",
    "        # Close the root element\n",
    "        xml_file.write(\"</document>\")\n",
    "\n",
    "    print(f\"XML file successfully saved at {xml_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pdf_process(pdf_dir, pdf_filename, output_dir):\n",
    "    current_title, ext = os.path.splitext(pdf_filename)\n",
    "    assert ext == \".pdf\", f\"Expected .pdf, got {ext}\"\n",
    "    text_pages, marked_images = build_processed_pdf(pdf_dir, pdf_filename)\n",
    "    save_annotated_text_and_image_data(output_dir, current_title, text_pages, marked_images)\n",
    "    save_xml_text_file(output_dir, current_title, text_pages)\n",
    "    return text_pages, marked_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to read pdfs from\n",
    "pdf_dir = \"../PDF/Phat_Giao_journals\"\n",
    "\n",
    "# directory to save output\n",
    "output_dir = \"../processed_journal_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pages, marked_images = full_pdf_process(pdf_dir, \"phat-giao-viet-nam-1956-25-26.pdf\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files =  os.listdir(pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_list = [all_files[2]] + all_files[6:16] + all_files[17:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in px_list:\n",
    "        #print(filename)  # Do something with each file path\n",
    "        full_pdf_process(pdf_dir, filename, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
