{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u26a0\ufe0f **openai_interface deprecated** \u2014 This notebook uses the removed legacy client. Refactor to `tnh_scholar.gen_ai_service` before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "import json\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "\n",
        "from tnh_scholar.text_processing import wrap_lines, unwrap_lines, lines_from_wrapped_text\n",
        "from tnh_scholar.text_processing import get_text_from_file, write_text_to_file\n",
        "from tnh_scholar.utils import iterate_subdir, load_json_into_model, save_model_to_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tnh_scholar.text_processing import process_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tnh_scholar.openai_interface import token_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure main logger using setup_logger\n",
        "import tnh_scholar.logging_config as logging_config\n",
        "from tnh_scholar.logging_config import setup_logging, get_child_logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "setup_logging(log_filepath=\"postprocessing_english.log\")\n",
        "logger = get_child_logger(\"postprocessing_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "video_storage_dir = Path(\"processed_videos/video_transcriptions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Section(BaseModel):\n",
        "    title: str = Field(\n",
        "        ..., \n",
        "        description=\"The title of the section\"\n",
        "    )\n",
        "    summary: str = Field(\n",
        "        ..., \n",
        "        description=\"A summary of the section\"\n",
        "    )\n",
        "    start_line: int = Field(\n",
        "        ..., \n",
        "        description=\"The starting line number of the section.\"\n",
        "    )\n",
        "    end_line: int = Field(\n",
        "        ...,\n",
        "        description=\"The ending line number of the section.\"\n",
        "    )\n",
        "\n",
        "class DharmaTalkSections(BaseModel):\n",
        "    talk_summary: str = Field(\n",
        "        ..., \n",
        "        description=\"A summary of the Dharma talk content.\"\n",
        "    )\n",
        "    sections: List[Section] = Field(\n",
        "        ..., \n",
        "        description=\"An ordered list of sections with their titles and included start and end line numbers.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_sections(output_file: Path, wrapped_transcript: str, section_object: DharmaTalkSections, instructions: str) -> None:\n",
        "    \"\"\"\n",
        "    Processes sections of a document by applying provided instructions\n",
        "    and writing the results to an output file.\n",
        "\n",
        "    Args:\n",
        "        output_file (Path): Path to the file where the processed sections will be written.\n",
        "        wrapped_transcript (str): The transcripted with line number wrapping\n",
        "        section_object: Object containing the sections to process. Each section should have 'start_line', \n",
        "                        'end_line', and 'title' attributes.\n",
        "        instructions (str): Instructions for processing each section.\n",
        "\n",
        "    Example:\n",
        "        process_sections(\n",
        "            output_file=\"output.xml\",\n",
        "            section_object=my_section_object,\n",
        "            instructions=\"Process section titled '{section_title}' carefully.\"\n",
        "        )\n",
        "    \"\"\"\n",
        "    sections = section_object.sections\n",
        "    sections_processed = []\n",
        "    \n",
        "    write_text_to_file(output_file, \"<document>\\n\", overwrite=True)\n",
        "    logger.info(f\"Sections to process: {len(sections)}\")\n",
        "    for i, section in enumerate(sections):\n",
        "        logger.info(f\"Processing section {i+1}: '{section.title}'...\")\n",
        "        original_lines = lines_from_wrapped_text(\n",
        "            wrapped_transcript,  \n",
        "            start=section.start_line,\n",
        "            end=section.end_line,\n",
        "            keep_brackets=False\n",
        "        )\n",
        "        section_instructions = instructions.format(section_title=section.title)\n",
        "        \n",
        "        if i == 0:\n",
        "            logger.info(f\"Processing instructions:\\n{section_instructions}\")\n",
        "        \n",
        "        processed_lines = process_text(original_lines, section_instructions, batch=False)\n",
        "        sections_processed.append(processed_lines)\n",
        "        write_text_to_file(output_file, processed_lines, append=True)\n",
        "    write_text_to_file(output_file, \"</document>\", append=True)\n",
        "    return sections_processed\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "postprocess_format_en_1 = \"\"\"You are the world's leading expert at formatting Dharma talk audio transcriptions into written text for native, and partly fluent English speakers. \n",
        "\n",
        "The current text is from a Dharma Talk offered by a California-based English-speaking monastic.\n",
        "\n",
        "Your goal is to format the text into meaningful paragraphs and sections while correcting errors (logical, transcription, or grammatical). \n",
        "\n",
        "Insert <section> and <title> tags where appropriate in the text to mark natural sections in the talk; give these sections appropriate titles.\n",
        "\n",
        "Make necessary corrections to grammar to create correct English sentence structure and logical flow. \n",
        "\n",
        "You may have to infer the speaker's intent in order to correct transcription or speaking errors and to generate a text that most closely matches the speaker's meaning in clear and eloquent English.\n",
        "\n",
        "Faithfully to convey the speaker\u2019s intended meaning as accurately as possible while maintaining the original tone and style. Use the speaker's original phrasing as much as possible.\n",
        "\n",
        "Do not leave out any content. Do not summarize. \n",
        "\n",
        "Output the final text only.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# postprocess_format_instructions_en_2 = \"\"\"You are the world's leading expert at formatting Dharma talk audio transcriptions into written text for native, and partly fluent English speakers. \n",
        "\n",
        "# The current text is from a Dharma Talk offered by a California-based English-speaking monastic. \n",
        "\n",
        "# Your goal is to process the transcription into meaningful paragraphs and sections while correcting errors (logical, transcription, or grammatical). \n",
        "\n",
        "# Use <p> tags to mark paragraphs. Insert <section> and <title> tags where appropriate in the text to mark natural sections in the talk; give these sections appropriate titles.\n",
        "\n",
        "# You may have to infer the speaker's intent, and also use clues from context, in order to correct transcription or speaking errors and to generate a text that most closely matches the speaker's meaning in clear and eloquent English.\n",
        "\n",
        "# Faithfully convey the speaker's intended meaning as accurately as possible while maintaining the original tone and style. Use the speaker's original phrasing if it is correct.\n",
        "\n",
        "# Do not leave out any content. Do not add any content. Do not summarize. \n",
        "\n",
        "# Output the final text only.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "postprocess_format_instructions_en_2 = \"\"\"You are the world's leading expert at formatting Dharma talk audio transcriptions into written text. The talks are given by native, and mostly-fluent, English speakers. \n",
        "\n",
        "The current text is a section entitled '{section_title}' from a Dharma Talk offered by a California-based English-speaking monastic of the Plum Village tradition established by Thich Nhat Hanh. \n",
        "\n",
        "Your goal is to process the section into meaningful paragraphs while correcting errors (logical, speaking, transcription, or grammatical). \n",
        "\n",
        "Use <p> tags to mark paragraphs. Insert <section> and <title> tags at the beginning of the text and close with a </section> tag. \n",
        "\n",
        "You may have to infer the speaker's intent, and also use clues from context, in order to correct transcription or speaking errors and to generate a text that most closely matches the speaker's meaning in clear and eloquent English.\n",
        "\n",
        "Faithfully convey the speaker's intended meaning as accurately as possible while maintaining the original tone and style. Use the speaker's original phrasing if it works well and is correct.\n",
        "\n",
        "For corrections or language inference, you may refer to the language on the plumvillage.org website.\n",
        "\n",
        "The final section should be polished and publication ready.\n",
        "\n",
        "Do not leave out any content. Do not add any content. Do not summarize. \n",
        "\n",
        "Output the final text only.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "postprocess_format_en_3 = \"\"\"You are the world's leading expert at formatting Dharma talk audio transcriptions into written text for native, and partly fluent English speakers. \n",
        "\n",
        "The current text is from a Dharma Talk offered by a  California-based English-speaking monastic. \n",
        "\n",
        "Your goal is to process the transcription into meaningful concise paragraphs while correcting errors (logical, transcription, or grammatical). \n",
        "\n",
        "You may have to infer the speaker's intent, and also use clues from context, in order to correct transcription or speaking errors and to generate a text that most closely matches the speaker's meaning in clear and eloquent English.\n",
        "\n",
        "Faithfully convey the speaker\u2019s intended meaning as accurately as possible while maintaining the original tone and style. Use the speaker's original phrasing if it is correct and clear.\n",
        "\n",
        "Do not leave out any content. Do not add any content.  Do not summarize.  \n",
        "\n",
        "Output the final text only.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "postprocess_section_instructions_en = \"\"\"You are a highly skilled and meticulous assistant processing an audio transcript of a Dharma Talk given in English.\n",
        "\n",
        "Each line of the transcript is numbered in the format: <NUM:LINE> \n",
        "\n",
        "You goal is to divide the entire transcript into {section_count} logical sections based on content. \n",
        "\n",
        "For each section, give the title, a brief summary, and starting and ending line numbers.\n",
        "\n",
        "Also provide a brief summary of the whole text.\n",
        "\n",
        "IMPORTANT: Every line in the transcript must belong to a section. Don't leave out any lines. Don't include lines in more than one section.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "talk_name = \"Taking Care of Our Fear \uff5c Br. Phap Luu \uff5c 2024-11-06\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "video_dir = video_storage_dir / talk_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcript_path = video_dir / f\"{talk_name}.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(transcript_path)\n",
        "transcript_path.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcript = get_text_from_file(transcript_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(transcript[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wrapped_transcript = wrap_lines(transcript, number=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(wrapped_transcript[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "section_instructions = postprocess_section_instructions_en.format(section_count=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(section_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "section_object = process_text(wrapped_transcript, section_instructions, response_object=DharmaTalkSections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_section_path = video_dir / f\"section_{talk_name}.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model_to_json(json_section_path, section_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# section_object = load_json_into_model(json_section_path, DharmaTalkSections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(section_object.talk_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "section_object.sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_xml_path = video_dir / f\"formatted_{talk_name}.xml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(output_xml_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### for repairing: conditionally adding sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sections = section_object.sections\n",
        "sections_processed = []\n",
        "\n",
        "section_range = range(0, 4)\n",
        "\n",
        "logger.info(f\"Sections to process: {len(sections)}\")\n",
        "for i in section_range:\n",
        "    section = sections[i]\n",
        "    logger.info(f\"Processing section {i+1}: '{section.title}'...\")\n",
        "    original_lines = lines_from_wrapped_text(\n",
        "        wrapped_transcript,  \n",
        "        start=section.start_line,\n",
        "        end=section.end_line,\n",
        "        keep_brackets=False\n",
        "    )\n",
        "    section_instructions = postprocess_format_instructions_en_2.format(section_title=section.title)\n",
        "    \n",
        "    if i == 0:\n",
        "        logger.info(f\"Processing instructions:\\n{section_instructions}\")\n",
        "    \n",
        "    processed_lines = process_text(original_lines, section_instructions, batch=False)\n",
        "    sections_processed.append(processed_lines)\n",
        "    write_text_to_file(output_xml_path, processed_lines, append=True)\n",
        "write_text_to_file(output_xml_path, \"</document>\", append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(output_xml_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "process_sections(output_xml_path, transcript, section_object, postprocess_format_instructions_en_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sections_formatted = []\n",
        "# sections_original = []\n",
        "# sections = section_object.sections\n",
        "# section_range = range(0, 2)\n",
        "# output_file = test_dir / f\"formatted_{talk_name}.xml\"\n",
        "# for i in section_range:\n",
        "#     section = sections[i]\n",
        "#     original_lines = lines_from_wrapped_text(wtest, section.start_line, section.end_line, keep_brackets=False)\n",
        "#     format_instructions = postprocess_format_instructions_en_2.format(section_title=section.title)\n",
        "#     logger.info(f\"Formatting section '{section.title}'...\")\n",
        "\n",
        "#     if i == 0:\n",
        "#         logger.info(f\"Translation instructions:\\n{format_instructions}\")\n",
        "    \n",
        "#     translated_lines = postprocess_text(original_lines, format_instructions, batch=False)\n",
        "#     sections_formatted.append(translated_lines)\n",
        "#     write_text_to_file(output_file, translated_lines, append=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, video_dir in enumerate(iterate_subdir(video_storage_dir)):\n",
        "    try:\n",
        "        talk_name = video_dir.name\n",
        "        \n",
        "        logger.info(f\"Processing talk {i+1}: '{talk_name}'\") \n",
        "        \n",
        "        transcript_file = video_dir / f\"{talk_name}.txt\"\n",
        "\n",
        "        section_output_path = video_dir / f\"section_{talk_name}.json\"\n",
        "\n",
        "        output_xml_path = video_dir / f\"formatted_{talk_name}.xml\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in file setup for {talk_name}: {e}, skipping.\")\n",
        "\n",
        "    if transcript_file.exists():\n",
        "        \n",
        "        logger.info(f\"Transcript found: {transcript_file}\")\n",
        "\n",
        "        if output_xml_path.exists():\n",
        "            logger.info(f\"Formatted xml file found. Skipping {talk_name}.\")\n",
        "            \n",
        "        else: \n",
        "            try:\n",
        "                transcript = get_text_from_file(transcript_file)\n",
        "\n",
        "                wrapped_transcript = wrap_lines(transcript, number=True)\n",
        "\n",
        "                logger.info(f\"Starting sectioning postprocess for {talk_name}...\")\n",
        "\n",
        "                section_object = process_text(wrapped_transcript, postprocess_section_instructions_en, response_object=DharmaTalkSections, max_tokens=5000)\n",
        "\n",
        "                write_text_to_file(section_output_path, section_object.model_dump_json())\n",
        "                logger.info(f\"Sectioning for {talk_name} completed. Dumped section data to {section_output_path}.\")\n",
        "                \n",
        "                logger.info(f\"Starting postprocess for {talk_name}: section formatting sequence.\")            \n",
        "                process_sections(output_xml_path, wrapped_transcript, section_object, postprocess_format_instructions_en_2)\n",
        "                logger.info(f\"Postprocessing completed for {talk_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing {talk_name}: {e}. Partial processing may have been saved. Skipping to next talk file.\")\n",
        "\n",
        "    else:\n",
        "        logger.info(f\"No transcript found in {transcript_file}. Skipping {talk_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "section_object.sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "token_count(str(section_object))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tnh-scholar-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}