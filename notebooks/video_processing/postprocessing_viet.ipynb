{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "from tnh_scholar.utils.file_utils import get_text_from_file, write_text_to_file\n",
    "from tnh_scholar.xml_processing import wrap_lines, unwrap_lines, lines_from_wrapped_text\n",
    "from tnh_scholar.text_processing import process_text\n",
    "from tnh_scholar.utils import iterate_subdir, load_json_into_model, save_model_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnh_scholar.openai_interface import token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure main logger using setup_logger\n",
    "import tnh_scholar.logging_config as logging_config\n",
    "from tnh_scholar.logging_config import setup_logging, get_child_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(log_filepath=\"postprocessing_english.log\")\n",
    "logger = get_child_logger(\"postprocessing_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnh_scholar import PROJECT_ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_storage_dir = PROJECT_ROOT_DIR / \"sandbox/video_transcriptions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    title_vi: str = Field(\n",
    "        ..., \n",
    "        description=\"The title of the section in Vietnamese.\"\n",
    "    )\n",
    "    title_en: str = Field(\n",
    "        ..., \n",
    "        description=\"The translation of the title of the section in English.\"\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        ..., \n",
    "        description=\"A summary of the section in English.\"\n",
    "    )\n",
    "    start_line: int = Field(\n",
    "        ..., \n",
    "        description=\"The starting line number of this section.\"\n",
    "    )\n",
    "    end_line: int = Field(\n",
    "        ...,\n",
    "        description=\"The ending line number of this section.\"\n",
    "    )\n",
    "\n",
    "class DharmaTalkSections(BaseModel):\n",
    "    talk_summary: str = Field(\n",
    "        ..., \n",
    "        description=\"A summary of the Dharma talk in English.\"\n",
    "    )\n",
    "    sections: List[Section] = Field(\n",
    "        ..., \n",
    "        description=\"An ordered list of sections with their titles and included start and end line numbers. The sequence of line ranges for the sections must cover every line from start to finish without any overlaps or gaps.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslatedSection(Section):\n",
    "    content_vi: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The full content of the section in Vietnamese.\"\n",
    "    )\n",
    "    content_en: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The translation of the full content of the section in English.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sections(output_file: Path, wrapped_transcript: str, section_object: DharmaTalkSections, instructions: str) -> None:\n",
    "    \"\"\"\n",
    "    Processes sections of a document by applying provided instructions\n",
    "    and writing the results to an output file.\n",
    "\n",
    "    Args:\n",
    "        output_file (Path): Path to the file where the processed sections will be written.\n",
    "        wrapped_transcript (str): The transcripted with line number wrapping\n",
    "        section_object: Object containing the sections to process. Each section should have 'start_line', \n",
    "                        'end_line', and 'title' attributes.\n",
    "        instructions (str): Instructions for processing each section.\n",
    "\n",
    "    Example:\n",
    "        process_sections(\n",
    "            output_file=\"output.xml\",\n",
    "            section_object=my_section_object,\n",
    "            instructions=\"Process section titled '{section_title}' carefully.\"\n",
    "        )\n",
    "    \"\"\"\n",
    "    sections = section_object.sections\n",
    "    sections_processed = []\n",
    "    \n",
    "    write_text_to_file(output_file, \"<document>\\n\", overwrite=True)\n",
    "    logger.info(f\"Sections to process: {len(sections)}\")\n",
    "    for i, section in enumerate(sections):\n",
    "        logger.info(f\"Processing section {i+1}: '{section.title}'...\")\n",
    "        original_lines = lines_from_wrapped_text(\n",
    "            wrapped_transcript,  \n",
    "            start=section.start_line,\n",
    "            end=section.end_line,\n",
    "            keep_brackets=False\n",
    "        )\n",
    "        section_instructions = instructions.format(section_title=section.title)\n",
    "        \n",
    "        if i == 0:\n",
    "            logger.info(f\"Processing instructions:\\n{section_instructions}\")\n",
    "        \n",
    "        processed_lines = process_text(original_lines, section_instructions, batch=False)\n",
    "        sections_processed.append(processed_lines)\n",
    "        write_text_to_file(output_file, processed_lines, append=True)\n",
    "    write_text_to_file(output_file, \"</document>\", append=True)\n",
    "    return sections_processed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def convert_wrapped_lines_to_xml(wrapped_lines: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a list of wrapped lines into a valid XML structure with <line number=\"x\"> tags.\n",
    "\n",
    "    Args:\n",
    "        lines (List[str]): A list of strings, where each line is in the format \"<n: ...>\".\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing valid XML.\n",
    "\n",
    "    Example:\n",
    "        lines = \"\\n\".join([\n",
    "            \"<1:Today is the 20th of November, 1994.>\",\n",
    "            \"<2:The theme of this winter retreat is>\",\n",
    "        ])\n",
    "        print(convert_wrapped_lines_to_xml(lines))\n",
    "    \"\"\"\n",
    "    xml_lines = []\n",
    "    for line in wrapped_lines.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        # Extract the line number and content using slicing\n",
    "        if line.startswith('<') and line.endswith('>'):\n",
    "            try:\n",
    "                colon_index = line.index(':')  # Find colon separating number and content\n",
    "                number = line[1:colon_index]  # Extract the line number\n",
    "                content = line[colon_index + 1:-1].strip()  # Extract the content\n",
    "                # Wrap the content in a valid <line> tag\n",
    "                xml_lines.append(f'  <line number=\"{number}\">{content}</line>')\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Invalid format: {line}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid line format: {line}\")\n",
    "    return '\\n'.join(xml_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_section_instructions_vi = \"\"\"You are a highly skilled and meticulous assistant processing an audio transcript of a Dharma Talk given by Thich Nhat Hanh in Vietnamese.\n",
    "\n",
    "Each line of the transcript is numbered in the format: <NUM:LINE> \n",
    "\n",
    "You goal is to divide the entire transcript into {section_count} logical sections based on content. \n",
    "\n",
    "For each section, give the title in Vietnamese and English, a summary in English, and the starting and ending line numbers of the section.\n",
    "\n",
    "Also provide a summary of the talk in English.\n",
    "\n",
    "IMPORTANT: Every line in the transcript must belong to a section. Don't leave out any lines. Don't include lines in more than one section.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_instructions_translate_vi = \"\"\"You are the world's leading expert at translating Dharma talks transcribed from spoken Vietnamese.\n",
    "\n",
    "You are translating a section titled '{section_title}' from a Dharma talk offered by Thich Nhat Hanh (Thay) in Plum Village, France.\n",
    "\n",
    "Lines of the transcript are numbered and are given in the format <NUM:LINE>.\n",
    "\n",
    "Your task is to translate each line into correct, clear and typical English. Add correct punctuation to create meaning that matches the speakers style and intent.\n",
    "\n",
    "You may have to infer the Thay's intent in order to correct transcription or speaking errors and to generate a text that most closely matches the speaker's meaning,\n",
    "while still giving clear and eloquent English. Give the best approximation or contextual guess if the transcript is difficult or unclear. Make no comments. \n",
    "\n",
    "Use Plum Village typical English style when making translations.\n",
    "\n",
    "You may consider adjacent lines for corrections and context when generating a line, however each line of translation should be as close as possible a translation of the original line.\n",
    "\n",
    "Some transcriptions may be from sounds such as a bell. These can be marked as [Bell].\n",
    "\n",
    "You must faithfully capture Thay's style and presentation while creating a meaningful flow.\n",
    "\n",
    "Do not leave out any content or summarize. \n",
    "\n",
    "The final output should match the same line structure and line numbering using <> as the original.\n",
    "\n",
    "Your output should be a polished section.\n",
    "\n",
    "Make no other changes; add no content.\n",
    "\n",
    "Output the final text only.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_name = \"Kinh Tư Lượng [TTSĐCTTĐB 01] ｜ TS Thích Nhất Hạnh (20-11-1994, Xóm Thượng, Làng Mai)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = video_storage_dir / talk_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = video_dir / f\"{talk_name}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript_path)\n",
    "transcript_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = get_text_from_file(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_transcript = wrap_lines(transcript, number=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wrapped_transcript[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_instructions = process_section_instructions_vi.format(section_count=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_object = process_text(wrapped_transcript, section_instructions, response_object=DharmaTalkSections, max_tokens=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_section_path = video_dir / f\"section_{talk_name}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_to_json(json_section_path, section_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_object = load_json_into_model(json_section_path, DharmaTalkSections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(section_object.talk_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_object.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(section_object.sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xml_path = video_dir / f\"formatted_{talk_name}.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_xml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for repairing: conditionally adding some sections or all sections as specified by the section_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = section_object.sections\n",
    "sections_processed = []\n",
    "\n",
    "section_range = range(0, 10)\n",
    "\n",
    "logger.info(f\"Sections to process: {list(section_range)}\")\n",
    "for i in section_range:\n",
    "    section = sections[i]\n",
    "    logger.info(f\"Processing section {i+1}: '{section.title_en}'...\")\n",
    "    original_lines = lines_from_wrapped_text(\n",
    "        wrapped_transcript,  \n",
    "        start=section.start_line,\n",
    "        end=section.end_line,\n",
    "        keep_brackets=True\n",
    "    )\n",
    "    section_instructions = section_instructions_translate_vi.format(section_title=section.title_en)\n",
    "    \n",
    "    if i == 0:\n",
    "        logger.info(f\"Processing instructions:\\n{section_instructions}\")\n",
    "    \n",
    "    processed_lines = process_text(original_lines, section_instructions, batch=False)\n",
    "    processed_line = processed_lines\n",
    "    sections_processed.append(f\"<section>\\n<title>{section.title_en}</title>\\n{processed_lines}\\n</section>\")\n",
    "output_str = \"<document>\\n\" + \"\\n\\n\".join(sections_processed) + \"\\n</document>\"\n",
    "write_text_to_file(output_xml_path, output_str, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_sections(output_xml_path, transcript, section_object, postprocess_format_instructions_en_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections_formatted = []\n",
    "# sections_original = []\n",
    "# sections = section_object.sections\n",
    "# section_range = range(0, 2)\n",
    "# output_file = test_dir / f\"formatted_{talk_name}.xml\"\n",
    "# for i in section_range:\n",
    "#     section = sections[i]\n",
    "#     original_lines = lines_from_wrapped_text(wtest, section.start_line, section.end_line, keep_brackets=False)\n",
    "#     format_instructions = postprocess_format_instructions_en_2.format(section_title=section.title)\n",
    "#     logger.info(f\"Formatting section '{section.title}'...\")\n",
    "\n",
    "#     if i == 0:\n",
    "#         logger.info(f\"Translation instructions:\\n{format_instructions}\")\n",
    "    \n",
    "#     translated_lines = postprocess_text(original_lines, format_instructions, batch=False)\n",
    "#     sections_formatted.append(translated_lines)\n",
    "#     write_text_to_file(output_file, translated_lines, append=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, video_dir in enumerate(iterate_subdir(video_storage_dir)):\n",
    "    try:\n",
    "        talk_name = video_dir.name\n",
    "        \n",
    "        logger.info(f\"Processing talk {i+1}: '{talk_name}'\") \n",
    "        \n",
    "        transcript_file = video_dir / f\"{talk_name}.txt\"\n",
    "\n",
    "        section_output_path = video_dir / f\"section_{talk_name}.json\"\n",
    "\n",
    "        output_xml_path = video_dir / f\"formatted_{talk_name}.xml\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in file setup for {talk_name}: {e}, skipping.\")\n",
    "\n",
    "    if transcript_file.exists():\n",
    "        \n",
    "        logger.info(f\"Transcript found: {transcript_file}\")\n",
    "\n",
    "        if output_xml_path.exists():\n",
    "            logger.info(f\"Formatted xml file found. Skipping {talk_name}.\")\n",
    "            \n",
    "        else: \n",
    "            try:\n",
    "                transcript = get_text_from_file(transcript_file)\n",
    "\n",
    "                wrapped_transcript = wrap_lines(transcript, number=True)\n",
    "\n",
    "                logger.info(f\"Starting sectioning postprocess for {talk_name}...\")\n",
    "\n",
    "                section_object = postprocess_text(wrapped_transcript, postprocess_section_instructions_en, response_object=DharmaTalkSections, max_tokens=5000)\n",
    "\n",
    "                write_text_to_file(section_output_path, section_object.model_dump_json())\n",
    "                logger.info(f\"Sectioning for {talk_name} completed. Dumped section data to {section_output_path}.\")\n",
    "                \n",
    "                logger.info(f\"Starting postprocess for {talk_name}: section formatting sequence.\")            \n",
    "                process_sections(output_xml_path, wrapped_transcript, section_object, postprocess_format_instructions_en_2)\n",
    "                logger.info(f\"Postprocessing completed for {talk_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {talk_name}: {e}. Partial processing may have been saved. Skipping to next talk file.\")\n",
    "\n",
    "    else:\n",
    "        logger.info(f\"No transcript found in {transcript_file}. Skipping {talk_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_object.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "token_count(str(section_object))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
