{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_video_processing import get_youtube_urls_from_file, download_audio_yt, detect_boundaries, split_audio_at_boundaries, process_audio_chunks, split_on_silence, postprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.gpt_processing import token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure main logger using setup_logger\n",
    "import logging_config\n",
    "from logging_config import setup_logging\n",
    "from logging_config import get_child_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(log_filename=\"audio_extract_testing.log\", log_level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_child_logger(\"audio_extract_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_storage_dir = Path(\"processed_videos/video_transcriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_working_dir = audio_storage_dir / \"PTTT 04⧸08⧸2024 ｜ Pháp Thoại Hoà Thượng Thích Phước Tịnh ｜ TV Lộc Uyển (Làng Mai tại Mỹ)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = audio_working_dir / \"PTTT 04⧸08⧸2024 ｜ Pháp Thoại Hoà Thượng Thích Phước Tịnh ｜ TV Lộc Uyển (Làng Mai tại Mỹ).mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_working_dir = audio_storage_dir / \"The One-Eyed Goldfish ｜ Thay Phap Dung ｜ 2024-06-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file_path = audio_working_dir / \"The One-Eyed Goldfish ｜ Thay Phap Dung ｜ 2024-06-30.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundaries = detect_boundaries_hf(audio_file_path, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_directory = split_on_silence(audio_file_path, silence_thresh=-40, min_silence_len=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_audio_at_boundaries(audio_file_path, boundaries, test_output_dir, max_duration=1 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transcription_file = Path(\"venerable_test_vi.txt\")\n",
    "output_jsonl_file = Path(\"venerable_test_vi.jsonl\")\n",
    "\n",
    "process_audio_chunks(\n",
    "    directory=chunks_directory,\n",
    "    output_file=output_transcription_file,\n",
    "    jsonl_file=output_jsonl_file,\n",
    "    prompt=\"Tiếng Việt\",\n",
    "    translate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = Path(\"venerable_test_vi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_output_path = Path(\"post_venerable_test_vi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_instructions = \"\"\"You are the world's leading expert at translating Dharma talks transcribed from spoken Vietnamese.\n",
    "\n",
    "The current text is from a Dharma talk offered by Venerable Vietnamese Monastic at Deer Park Monastery in California.\n",
    "\n",
    "Common opening salutations are \"Namo Shakyamuni Buddha,\"  \"Dear Noble Community,\" which may be expressed partly in Sanskrit, and partly in Vietnamese. \n",
    "\n",
    "Some transcriptions may be from sounds such as a bell. These can be marked as [Bell].\n",
    "\n",
    "You may have to be creative to infer the meaning of the text, and correct transcription or speaking errors to create a text that most closely matches the speaker's meaning and intent, while being clear and eloquent English.\n",
    "\n",
    "Your goal is to translate the text and format it into meaningful paragraphs and correct errors (logical, transcription, or grammatical). \n",
    "You must faithfully capture the speaker's style and presentation while creating a meaningful flow and using common, clear, and typical English. \n",
    "Translate faithfully and as carefully as possible. Do not leave out any content.\n",
    "\n",
    "Your output should be a publishable and polished document.\n",
    "\n",
    "Make no other changes; add no content.\n",
    "\n",
    "Output the final text only.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_text(transcript_path, post_output_path, postprocess_instructions, batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_file = Path(\"my_urls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_youtube_urls_from_file(url_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_boundaries_hf(audio_file: Path, model_name: str = 'openai/whisper-tiny', language: str = None) -> List[Dict[str, float]]:\n",
    "#     \"\"\"\n",
    "#     Use Hugging Face's Whisper model to detect sentence boundaries in the audio file.\n",
    "\n",
    "#     Args:\n",
    "#         audio_file (Path): Path to the audio file.\n",
    "#         model_name (str): Name of the Whisper model on Hugging Face (e.g., 'openai/whisper-small').\n",
    "#         language (str): Language code (e.g., 'en' for English, 'vi' for Vietnamese). Defaults to auto-detection.\n",
    "\n",
    "#     Returns:\n",
    "#         List[Dict[str, float]]: List of timestamps with sentence boundaries. Each entry contains:\n",
    "#             - \"start\": Start time of the sentence (in seconds).\n",
    "#             - \"end\": End time of the sentence (in seconds).\n",
    "#             - \"text\": Sentence text.\n",
    "#     \"\"\"\n",
    "#     # Initialize the Whisper pipeline\n",
    "#     logger.info(f\"Loading model '{model_name}' with Hugging Face pipeline...\")\n",
    "\n",
    "#     # Initialize the tokenizer with the desired language and task\n",
    "#     tokenizer = WhisperTokenizer.from_pretrained(model_name, language=language, task=\"transcribe\")\n",
    "\n",
    "#     # Initialize the feature extractor\n",
    "#     feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "#     # Load the model\n",
    "#     model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "#     # Create the ASR pipeline with the specified components\n",
    "#     logger.info(\"Creating Pipeline...\")\n",
    "#     asr_pipeline = pipeline(\n",
    "#         task=\"automatic-speech-recognition\",\n",
    "#         model=model,\n",
    "#         tokenizer=tokenizer,\n",
    "#         feature_extractor=feature_extractor,\n",
    "#         return_timestamps=\"word\",\n",
    "#         device=0\n",
    "#     )\n",
    "\n",
    "#     # Load and transcribe the audio file\n",
    "#     logger.info(f\"Transcribing '{audio_file.name}' with language: {language or 'auto-detected'}...\")\n",
    "#     result = asr_pipeline(str(audio_file))\n",
    "\n",
    "#     # Extract sentence boundaries from word timestamps\n",
    "#     if \"chunks\" not in result:\n",
    "#         logger.warning(\"Word-level timestamps not found; returning entire transcription.\")\n",
    "#         return [{\"start\": 0, \"end\": result[\"duration\"], \"text\": result[\"text\"]}]\n",
    "\n",
    "#     sentence_boundaries = []\n",
    "#     current_sentence = {\"start\": None, \"end\": None, \"text\": \"\"}\n",
    "#     for word in result[\"chunks\"]:\n",
    "#         if current_sentence[\"start\"] is None:\n",
    "#             current_sentence[\"start\"] = word[\"timestamp\"][\"start\"]\n",
    "#         current_sentence[\"end\"] = word[\"timestamp\"][\"end\"]\n",
    "#         current_sentence[\"text\"] += word[\"text\"] + \" \"\n",
    "\n",
    "#         # End a sentence if punctuation is found or the segment length exceeds a threshold\n",
    "#         if word[\"text\"].endswith(('.', '?', '!')) or len(current_sentence[\"text\"].split()) > 10:\n",
    "#             sentence_boundaries.append(current_sentence)\n",
    "#             current_sentence = {\"start\": None, \"end\": None, \"text\": \"\"}\n",
    "\n",
    "#     # Append any remaining sentence\n",
    "#     if current_sentence[\"text\"].strip():\n",
    "#         sentence_boundaries.append(current_sentence)\n",
    "\n",
    "#     logger.info(\"Sentence boundaries successfully detected.\")\n",
    "#     return sentence_boundaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
