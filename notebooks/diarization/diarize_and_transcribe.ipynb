{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the transcription service modules\n",
    "from tnh_scholar.audio_processing.transcription_service import (\n",
    "    DiarizationChunker,\n",
    "    TranscriptionFormatConverter,\n",
    "    TranscriptionServiceFactory,\n",
    ")\n",
    "from tnh_scholar.cli_tools.audio_transcribe.diarize import (\n",
    "    check_job_status,\n",
    "    diarize,\n",
    "    resume_diarization,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path.home() / \"Desktop/transcription_wouter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_base_path = working_dir \\\n",
    "    / \"qa_sr_abbess.mp3\"  \n",
    "if not audio_file_base_path.exists():\n",
    "    raise FileNotFoundError(\"Audio file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_srt(audio_file_obj, provider=\"whisper\", language=None, local_convert=False):\n",
    "    \"\"\"\n",
    "    generate srt\n",
    "    \"\"\"\n",
    "    format_type = \"srt\"\n",
    "    # Create the transcription service\n",
    "    service = TranscriptionServiceFactory.create_service(provider=provider)\n",
    "\n",
    "    # Print some info\n",
    "    print(f\"Running {format_type.upper()} generation with {provider} service...\")\n",
    "    print(f\"Audio file: {audio_file_obj}\")\n",
    "\n",
    "    transcription_options = {\"language\": language} if language else None\n",
    "    \n",
    "    # Generate the formatted transcription\n",
    "    # use the local format converter if specified\n",
    "    if local_convert:\n",
    "        converter = TranscriptionFormatConverter()\n",
    "        transcript = service.transcribe(audio_file_obj, options=transcription_options)\n",
    "        return converter.convert(transcript)\n",
    "        \n",
    "    return service.transcribe_to_format(\n",
    "        audio_file_obj, \n",
    "        format_type=format_type,\n",
    "        transcription_options=transcription_options\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_chunks(\n",
    "    audio_path, chunks, audio_format=None, language=None, local_convert=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Process audio file by chunks and generate SRTs with adjusted timestamps.\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to the audio file\n",
    "        chunks: List of Chunk objects with timing information\n",
    "        \n",
    "    Returns:\n",
    "        Combined SRT string with properly adjusted timestamps\n",
    "    \"\"\"\n",
    "    \n",
    "    if audio_format is None:\n",
    "        audio_format = audio_path.suffix[1:]\n",
    "        print(f\"Using audio format: {audio_format}\")\n",
    "        \n",
    "    # Load the full audio file\n",
    "    print(f\"Loading audio file: {audio_path}\")\n",
    "    full_audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    # Process each chunk\n",
    "    all_srts = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_duration = chunk.end_time - chunk.start_time\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}: {chunk.start_time}ms \"\n",
    "              f\"to {chunk.end_time}ms\")\n",
    "        print(f\"chunk duration: {chunk_duration}\")\n",
    "        \n",
    "        # Get subset of audio\n",
    "        chunk_audio = full_audio[chunk.start_time:chunk.end_time]\n",
    "        \n",
    "        # Convert to file-like object\n",
    "        chunk_file = BytesIO()\n",
    "        chunk_audio.export(chunk_file, format=audio_format)\n",
    "        chunk_file.seek(0)  # Reset file pointer to beginning\n",
    "        \n",
    "        # Add a filename for whisper to recognize\n",
    "        chunk_file.name = f\"chunk_{i}.{audio_format}\"  \n",
    "\n",
    "        # Generate SRT for this chunk\n",
    "        chunk_srt = gen_srt(chunk_file, language=language, local_convert=local_convert)\n",
    "        \n",
    "        # Adjust timestamps in the SRT based on chunk start time\n",
    "        adjusted_srt = adjust_srt_timestamps(chunk_srt, chunk.start_time)\n",
    "        \n",
    "        all_srts.append(adjusted_srt)\n",
    "        \n",
    "    # Combine all SRTs, renumbering entries\n",
    "    combined_srt = combine_srts(all_srts)\n",
    "    \n",
    "    return all_srts, combined_srt\n",
    "\n",
    "def adjust_srt_timestamps(srt_content, offset_ms):\n",
    "    \"\"\"Adjust SRT timestamps by adding the offset (in ms)\"\"\"\n",
    "    \n",
    "    def add_offset_to_timestamp(timestamp_str, offset_ms):\n",
    "        \"\"\"Add millisecond offset to an SRT timestamp string (HH:MM:SS,mmm)\"\"\"\n",
    "        h, m, rest = timestamp_str.split(':')\n",
    "        s, ms = rest.split(',')\n",
    "        \n",
    "        # Convert to total milliseconds\n",
    "        total_ms = int(h) * 3600000 + int(m) * 60000 + int(s) * 1000 + int(ms) + offset_ms\n",
    "        \n",
    "        # Convert back to SRT format\n",
    "        new_h = total_ms // 3600000\n",
    "        total_ms %= 3600000\n",
    "        new_m = total_ms // 60000\n",
    "        total_ms %= 60000\n",
    "        new_s = total_ms // 1000\n",
    "        new_ms = total_ms % 1000\n",
    "        \n",
    "        return f\"{new_h:02d}:{new_m:02d}:{new_s:02d},{new_ms:03d}\"\n",
    "    \n",
    "    # Pattern for SRT timestamp lines\n",
    "    pattern = r'(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})'\n",
    "    \n",
    "    def replace_timestamps(match):\n",
    "        start_time = match.group(1)\n",
    "        end_time = match.group(2)\n",
    "        new_start = add_offset_to_timestamp(start_time, offset_ms)\n",
    "        new_end = add_offset_to_timestamp(end_time, offset_ms)\n",
    "        return f\"{new_start} --> {new_end}\"\n",
    "    \n",
    "    # Replace all timestamp pairs in the SRT\n",
    "    return re.sub(pattern, replace_timestamps, srt_content)\n",
    "\n",
    "def combine_srts(srt_list):\n",
    "    \"\"\"Combine multiple SRT strings, renumbering the entries sequentially\"\"\"\n",
    "    result = []\n",
    "    entry_num = 1\n",
    "    \n",
    "    for srt in srt_list:\n",
    "        # Split into entries (blocks separated by blank lines)\n",
    "        entries = srt.strip().split(\"\\n\\n\")\n",
    "        \n",
    "        for entry in entries:\n",
    "            if not entry.strip():\n",
    "                continue\n",
    "                \n",
    "            # Split the entry into lines\n",
    "            lines = entry.split(\"\\n\")\n",
    "                \n",
    "            # Replace the index number (first line) with sequential number\n",
    "            lines[0] = str(entry_num)\n",
    "            entry_num += 1\n",
    "            \n",
    "            # Add updated entry to result\n",
    "            result.append(\"\\n\".join(lines))\n",
    "    \n",
    "    # Join all entries with blank lines in between\n",
    "    return \"\\n\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = Path(\"/Users/phapman/Desktop/transcription_wouter/qa_sr_abbess_wh_sh.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path.suffix[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = diarize(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resume_diarization(audio_file_path, 'd4d35761-ac95-4ddd-b468-5a7471855219')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = DiarizationChunker(target_duration=60 * 1000, single_speaker=True, min_chunk_duration=60 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = chunker.to_segments(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunker.extract_chunks(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(ch.start_time, ch.end_time, ch.duration_sec, ch.segments[0].speaker) for ch in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[1].segments[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[2].segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_srts, combined = process_audio_chunks(audio_file_path, chunks, language=\"vi\", local_convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_srts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnh_scholar.utils.file_utils import write_str_to_file\n",
    "\n",
    "out_srt = working_dir / \"Dharma Talk Br. Phap Hoi (for transcription) 2-bit.srt\"\n",
    "write_str_to_file(out_srt, combined, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
