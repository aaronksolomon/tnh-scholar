{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Diarization and Transcription Pipeline\n",
    "\n",
    "This notebook provides a simple workflow to:\n",
    "1. Perform speaker diarization using PyAnnote\n",
    "2. Extract speaker-specific audio\n",
    "3. Transcribe speaker audio with audio-transcribe\n",
    "4. Convert JSONL to SRT with timeline mapping\n",
    "\n",
    "Note: Requires tnh-scholar package to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from tnh_scholar.audio_processing.diarization import (\n",
    "    diarize,\n",
    "    resume_diarization,\n",
    ")\n",
    "from tnh_scholar.audio_processing.diarization.audio import AudioHandler\n",
    "from tnh_scholar.audio_processing.diarization.config import (\n",
    "    ChunkConfig,\n",
    "    DiarizationConfig,\n",
    "    LanguageConfig,\n",
    "    SpeakerConfig,\n",
    ")\n",
    "from tnh_scholar.audio_processing.diarization.models import AugDiarizedSegment\n",
    "from tnh_scholar.audio_processing.diarization.pyannote_adapter import PyannoteAdapter\n",
    "from tnh_scholar.audio_processing.diarization.strategies import LanguageProbe, WhisperLanguageDetector\n",
    "from tnh_scholar.audio_processing.diarization.strategies.speaker_blocker import group_speaker_blocks\n",
    "from tnh_scholar.audio_processing.diarization.strategies.time_gap import TimeGapChunker\n",
    "from tnh_scholar.audio_processing.diarization.timeline_mapper import TimelineMapper\n",
    "from tnh_scholar.audio_processing.diarization.viewer import close_segment_viewer, launch_segment_viewer\n",
    "from tnh_scholar.audio_processing.timed_object.timed_text import Granularity, TimedText\n",
    "from tnh_scholar.audio_processing.transcription import patch_whisper_options\n",
    "from tnh_scholar.audio_processing.transcription.srt_processor import (\n",
    "    SRTConfig,\n",
    "    SRTProcessor,\n",
    ")\n",
    "from tnh_scholar.audio_processing.transcription.text_segment_builder import TextSegmentBuilder\n",
    "from tnh_scholar.audio_processing.transcription.transcription_service import (\n",
    "    TranscriptionResult,\n",
    "    TranscriptionServiceFactory,\n",
    ")\n",
    "from tnh_scholar.audio_processing.utils import (\n",
    "    get_audio_from_file,\n",
    "    get_segment_audio,\n",
    "    play_diarization_segment,\n",
    ")\n",
    "from tnh_scholar.utils.file_utils import (\n",
    "    write_str_to_file,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Handle warnings with traceback\n",
    "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "    log = file if hasattr(file, 'write') else sys.stderr\n",
    "    traceback.print_stack(file=log)\n",
    "    log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "\n",
    "warnings.showwarning = warn_with_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger tnh (DEBUG)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from tnh_scholar.logging_config import setup_logging\n",
    "\n",
    "setup_logging(log_level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these values\n",
    "# Path to the directory containing audio files\n",
    "\n",
    "BASE_DIR = Path.home() / \"Desktop/sr_d_transcriptions/audio_transcriptions\"\n",
    "\n",
    "# Audio file to process (run this notebook once per file)\n",
    "AUDIO_FILE_STR = \"sr_d_omega_clean.flac\"\n",
    "\n",
    "DIARIZATION_FILE_STR = AUDIO_FILE_STR\n",
    "\n",
    "SPEAKER_COUNT = 1 # Must be 1, 2 or None. If speakers > 2 use None for best result.\n",
    "\n",
    "GENERATE_NEW_DIARIZATION = False\n",
    "\n",
    "DIARIZE_SINGLE_SPEAKER = True\n",
    "\n",
    "SRT_INCLUDE_SPEAKER = False\n",
    "\n",
    "LANGUAGE = 'en'\n",
    "\n",
    "TARGET_CHUNK_TIME = 2 * 60  # seconds\n",
    "\n",
    "MIN_CHUNK_TIME = 10 # seconds\n",
    "\n",
    "TRANSCRIBER = \"assemblyai\"\n",
    "\n",
    "completed = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarize_config = DiarizationConfig(\n",
    "    chunk = ChunkConfig(\n",
    "        target_duration=TARGET_CHUNK_TIME * 1000,\n",
    "        min_duration= MIN_CHUNK_TIME * 1000, \n",
    "    ),\n",
    "    speaker = SpeakerConfig(\n",
    "        single_speaker=DIARIZE_SINGLE_SPEAKER,\n",
    "    ),\n",
    "    language = LanguageConfig(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "audio_file_path = BASE_DIR / AUDIO_FILE_STR\n",
    "diarize_audio_file_path = BASE_DIR / DIARIZATION_FILE_STR\n",
    "\n",
    "file_ext_str = audio_file_path.suffix\n",
    "\n",
    "if not audio_file_path.exists():\n",
    "    raise FileNotFoundError(f\"No file found: {audio_file_path}\")\n",
    "\n",
    "diarization_results_path = diarize_audio_file_path.parent / \"raw_diarization_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_diarization_result(file_path):\n",
    "    \"\"\"Load diarization result from JSON file or sample data.\"\"\"\n",
    "    if not file_path:\n",
    "        raise ValueError(\"File_path must be provided.\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PyAnnote diarization\n",
    "if GENERATE_NEW_DIARIZATION:\n",
    "    completed = False\n",
    "    print(f\"Starting diarization for {diarize_audio_file_path}...\")\n",
    "    result = diarize(diarize_audio_file_path, num_speakers=SPEAKER_COUNT, output_path=diarization_results_path)\n",
    "\n",
    "    # If the job is still running, you'll get a job ID\n",
    "    if isinstance(result, str):\n",
    "        job_id = result\n",
    "        print(f\"Diarization job started with ID: {job_id}\")\n",
    "        print(\"Wait for completion and then run the next cell with this job ID\")\n",
    "    else:\n",
    "        completed = True\n",
    "        print(\"Diarization process finished on initial run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if you got a job ID in the previous cell\n",
    "# Replace with your actual job ID from the previous step\n",
    "# job_id = \"your-job-id-here\"  # e.g., \"994c79b7-5f32-4715-aa34-33f00e216369\"\n",
    "\n",
    "# Check status\n",
    "\n",
    "if not completed:\n",
    "    status = check_job_status(job_id)\n",
    "    print(f\"Current status: {status.get('status', 'unknown')}\")\n",
    "\n",
    "    # Resume if needed\n",
    "    if status.get('status') != 'succeeded':\n",
    "        print(\"Resuming diarization...\")\n",
    "        result = resume_diarization(audio_file_path, job_id)\n",
    "        print(\"Diarization completed\")\n",
    "    else:\n",
    "        print(\"Diarization already completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_options_aai = {\"language_code\": LANGUAGE, \"language_detection\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 21:37:47,362 - tnh.tnh_scholar.audio_processing.transcription.assemblyai_service - \u001b[1;32mDEBUG\u001b[0m - Initialized AssemblyAI service with SDK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ts_service = TranscriptionServiceFactory.create_service(provider=TRANSCRIBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 21:37:50,726 - tnh.tnh_scholar.audio_processing.transcription.assemblyai_service - \u001b[36mINFO\u001b[0m - Starting synchronous transcription with AssemblyAI SDK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transcript = ts_service.transcribe(audio_file_path, transcription_options_aai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seg = transcript.utterance_timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.raw_result['chapters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert full_seg is not None\n",
    "new_seg = TimedText(segments=full_seg.segments, granularity=Granularity.SEGMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert full_seg is not None\n",
    "full_out = new_seg.export_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A] Dear beloved spiritual family, I know you're here, and I'm very happy and grateful. I'm very aware that it took a lot of efforts and arrangement for you to be here. It took a lot of effort on our part to come here. So every day I cherish it. I haven't been feeling so well the last three, four days. My Lyme disease has been acting up. So I have a lot of physical pain and many other things. But each day I am keenly aware that we have this opportunity to be here together. So I do my best to take care of my health and at the same time, to show up for you. And it gives me such joy and meaning to be with you. When I. After I finished medical school in San Francisco, I went to Lou, my residency right outside of San Francisco. And one day, a doctor whom I was working with, it was at a HIV clinic. And he told me, oh, Dr. Wen, you know, there's a Zen master coming to the States, and he has several retreats. Maybe you would like to go. And he gave me this pamphlet, and I looked at it, and it seemed incredibly straightforward and simple. Just, you know, it listed out the retreats and the location, and I saw that there was one in Santa Barbara. And I had never been to a retreat before. I had been raised as a Buddhist. I used to ride my grandmother on the bicycle to the temple, and I was always afraid of, you know, falling and then causing her to fall. So it was quite an adventure every time I took grandmother to the temple on a bicycle. But I never learned anything about the practice or anything like that. But at the moment I looked at the pamphlet, I felt called to go to the retreat in Santa Barbara. And I actually went to the residency office and asked permission to take five days off. And I'm sure it was unheard of, but miraculously, they gave me permission to go to this retreat for five days. Just the next day, I got the permission. So I did. And at the retreat, that was the first time I met Thay, our beloved teacher, Thich Nhat Hanh, Zen master Thich Hanh, and also the monastic community, and at least 700 other retreatants at the retreat. And I remember crying a lot as I was listening to Thay's teachings. And what really woke me up during that retreat was the four noble truths about suffering. Well, I had never thought of suffering as something noble. It was more like mud that was sticky and stinky. But I learned that suffering can be noble if, first of all, we learn to recognize it. Now, I had suffered a lot in my life as a child, as a teenager, I surely I knew I was suffering, but I never thought of it consciously like that. It was almost like it's something that comes along, it's just there. You don't think much about it. You just bear it and do it. To recognize all the abuses, the losses that I had gone through brought me a lot of tears. And the Second Noble Truth that really shook me, even more so than the First Noble Truth, was that there are causes of suffering. We need to recognize them and identify them. And of course, as children, we experience certain losses, certain injustice, sadness, fear, anger, because of the instability of our family, school, neighborhood, relatives. But what I. What I woke up to, the reality was that not only those were the causes of my suffering. Not only that I was a victim of suffering, but actually I had become a perpetrator of my own suffering. That certain trauma had taken place at. At a certain period of time in my life, whether it was one time or one year or several years, but it had stopped. But I had unknowingly continued to perpetuate my own suffering through my way of unskillful thinking, unskillful speaking, and unskillful behaving. I had continued that suffering as if it's still taking place, but now I am the perpetrator. And that was astounding to me. But it was the first time I learned to take responsibility for my own suffering, to say that I, although I cannot change the past, although I cannot change others, but I can transform the way I think, the way I speak, the way I behave, so that I am not a perpetrator of suffering. I don't impose suffering first and foremost upon myself. And to me it was a grand responsibility, but it was also a way out of suffering for me. It was very liberating to me to just realize that. And of course, on the path we learn about the Third Noble Truth, that there is a way out of suffering. Some scholars misunderstood the teaching of the Buddha and said the Buddha only taught about suffering. It was something very morbid, very negative. They thought about the teaching of the Buddha, but the Buddha was known as the King of Medicine. And the Third Noble Truth is like the prognosis, you know, the First Noble Truth, identifying suffering, that's like chief complaint. You have a chief complaint and then you look for the causes, right? You ask questions, take history, family history, personal history, surgical history, social history, etc. You do lab works and all. But the third one is the diagnosis. And usually, like simple diseases, the prognosis is 100% for cure. But many of the diseases that we have, maybe we can treat them to a certain extent, but not 100%. But the Buddha said that suffering can have a complete cessation. It's very positive, very optimistic prognosis for all kinds of suffering. And of course, the fourth Noble Truth is treatment, treatment plan. And the Buddha taught about the Eightfold Noble Path, which really starts with right mindfulness. That is why in Buddhism we emphasize a lot about mindfulness. We can be aware of all sorts of things. You can be on a computer, on your iPhone for eight hours straight. Oh yes, you are surely very aware. But is it right mindfulness when you are completely oblivious of your body? And this needs to just simply empty the bladder, empty the bowel that has been in that crouched position for so long that there's back pain, headaches, that there's hunger, there's a lack of sleep that we're not aware of. So yes, it's mindfulness, but it can be called as wrong mindfulness because we have forgotten our body, we have forgotten ourselves. So it starts with right mindfulness that we train ourselves in daily life. So let us enjoy oneself the bell and come back to the foundation of our being, which is our breath that we learned yesterday. The first two exercises, breathing in. Aware of the in breath as it is, breathing out. Aware of the out breath as it is. Then as you breathe in, just acknowledge, recognize the characteristics of your in breath as it is. Whether it is short or long, comfortable or uncomfortable. What color is it? Is it red or is it cool? Blue or purple or white or black. Just recognize the characteristics, the quality of your in breath and out breath as they are. Sa. Mindful breathing has become my best friend. It has become my soulmate. This morning when we were doing sitting meditation with guidance. Every time I practice this guided meditation, some new insights arise. This morning I saw myself literally as a five year old child. And my mother was living in this city, doing her best to make money, to help her mother and siblings and me, the first child. And I remember very vividly an image in an evening. And so as my mother was living in the city, I was left in the countryside with my grandmother. And she would come back to the countryside every so often. And that evening she was lying on a hammock in the front porch, on the front porch. And I was standing near, looking at this woman. I was aware she was my mother, but I didn't feel that she was my mother because she was never around. So I really had no connection with her, really she brought back gifts, so that was exciting. But I was also aware that she would be leaving very soon. So that was one of the first images of my life. Memories of my life was that looking at this woman, knowing that she would be leaving very soon. And then when I was six years old, my mother brought me to Saigon to live with her. And again, she was working very, very hard. And I have this other very vivid image. I was standing in front of this house in this crowded neighborhood, just looking out. There was a fence in front of the house, so I was standing in the front yard, very small again, waiting for my mother to come back, not knowing when she was coming back. And another image came to me was when we moved to a bigger house. And by that time, I had my brother. I remember him. And my mother would be coming home so late because she was with this older man who was very kind to us, but he needed care, and he lived in a different place. So sometimes it was already 12 in the evening dark, and we were locked inside. And I just saw shadows on the walls. And I just thought of them as ghosts. And my brother and I would be sitting and then lying down by the doors, waiting for our mother to come back. Those are some very striking memories in my mind of my childhood, just looking out, waiting. And I came to ask myself this morning, how have I been able to become this woman? I am not waiting for anybody to come to me, to come back to me. I'm not waiting for anybody to give me affirmation, affection, acknowledgement. How have I been able to arrive at this place? Surely all my life I was seeking and wanting and desiring for a person to come to me, to come back to me, to be there for me. But I have arrived to a place that there's not that waiting or looking anymore. What has helped me to do that? And my heart is filled with deep gratitude for our beloved teacher, for. For the practice that has become my soulmate, that has become my constant companion, so that I don't have to look for a particular person or a particular situation to validate my existence. This is a Chinese character for soulmate. In Vietnamese, it's D means to remember, to know, to take care of, and to master. Di and ghi means oneself. So most of us, if not all of us, we look for a companion, a soulmate. All our life, we look for this person. Maybe we hoped to find that in our own mother, in our own father, in our own siblings, in our own partner, in our own children, in some friends. But really, I have Come to realize that there's no such person unless we find that soulmate within ourselves, in ourselves. Because as long as we are not our own soul mates, we do not remember ourselves, which include the five skandhas that my brother shared yesterday. If we do not remember our body, our breath, if we do not get to know this body, how it functions, what triggers pain, emotional and physical, what reliefs alleviates that pain. If we don't know how to take care of the discomfort, the suffering, the sadness, the angst, as well as the joy, the happiness. If we don't know how to master unpleasant feelings, strong emotions. If we don't know how to master our mind, if we don't know how to transform our past trauma, we are not our own soulmate. Then, even if somebody so kind comes along and truly loves us, and truly wants to be there for us, we will still walk away from that person. We will still walk all over that person. Which I did. I must say, of all the misunderstood fortune that I experienced in my life, I was very fortunate to have had three partners who loved me dearly, who were faithful, who were caring, who were sensitive, who were strong, strong practitioners in their own way. And yet I walked away from all of them and hurt them too. Because, you know, hurt people, hurt people. So to be a soulmate to ourselves will help us heal that loneliness, that yearning to help us feel invisible. Believe it or not, there was this child, only about 7 years old, in our last retreat. We had a family retreat. And his mother said, my son feels invisible. How can I help him? And I've talked to people of all different ages. We can be so successful and, you know, in society we can have great status. We can be married, we can. Outwardly, we are successful in every way. People, you know, admire us and everything. And yet deep inside, we feel so unseen, unheard. We feel invisible. That wounded child and us continues to manifest in our way of thinking, way of speaking, in our way of behaving. And that child logic of feeling so small, so insignificant, feeling forgotten, feeling unworthy, not enough, continues to operate in this very grown body. And that is why it doesn't matter how successful we are, we still feel invisible. So, riding the waves of life in our practice, it doesn't mean that there are no waves. There will always be waves, waves produced internally and externally. There will always be waves. But are we able to ride the waves? Just like the image of the Bodhisattva Avalokiteshvara, who stands majestically on the wave of birth and death? Can we learn to Stand on the wave. Since I got Lyme disease, I have discovered that swimming helps a lot. It helps a lot to keep my joints flexible, to relax my muscles, to reduce the pain. And now swimming has taught me many, many lessons. And one of the lessons is that everybody swims differently. I tend to swim slowly and quietly. You don't even know I'm swimming next to you. But somebody can be such a big splasher, you know what I mean? Like, literally, when that person passes or just about near you, you feel like a wave coming up and you're like your body literally tilts. Not long ago, just a few weeks ago, there was somebody who was swimming two lanes away and my body was going this way. And usually when I discover there's a big splasher next to me, what I do is that when that person is about to approach me or I'm about to approach that person, I stay still. I either roll over, you know, or just. I don't do a stroke that time. I just stay still, let that person pass. That helps me from drinking water, you know, choking on water, literally. I mean, I choke on water sometimes because of the next person. And so that's why my. That's also a reason my email is Long live aikido. You learn when there's a big splash, you learn to lay low. Otherwise you get to drink a lot of water or you drown yourself and then let that big wave pass and you continue. And I learned to ride the waves of life like that. I recognize sometimes I am a big splasher, you know, with my views, with my speech, with my actions that may cause somebody, you know, to kind of tip over, to be imbalanced. Learn to recognize that it's so important. Most of us identify ourselves as victims who are me, somebody is bullying me, is getting an upper hand. But in the practice, I've also learned to take responsibility that I am not just a victim, I'm also a perpetrator of suffering to myself and to others as well. I can also be a big splasher. And that is humbling. And it is helping me to re examine my own conduct. You know, last night I had three dreams. After I couldn't sleep for at least three, four hours, I had three dreams. And one of the dreams I had was that I was talk. We were talking, this brother and I, we were talking to each other. And then suddenly I stood up and I just did like this, and I just walk away. And then as I walk away, I stopped somewhere out of the corner of his eyes, and I thought to me, what has come to be. We used to count on each other, and now I just walk away from him. And I felt sad. And I recognized even in my dream, that it was unskillful. And in reality, actually that happened to me. I was talking to somebody, sharing about my genuine concerns. I was sharing, and suddenly he said, oh, I need to go get some food. And I was like. Either he didn't recognize that I was sharing something very deep, or he didn't agree with me, or he was just too hungry to pay attention. So in reality, it actually happened to me. But in my dream, I saw myself doing that to somebody else, and that actually let me erase this. You remember the definition of a soulmate, right? There'll be a quiz, so pay close attention. Every time I erase the board, I think of our teacher, how he erased the board so gently and so mindfully. Thay is so alive in us, in our daily life, if we only allow him to be. This is a model of the Yin Yang bean. There's actually these yin Yang beans that I would like to offer to you at the end. So half of the bean is black, and half of the bean is white. And on the black half there's a white dot, and on the white half there's a black dot. It's a Yin Yang bin. In the black, there's the white. In the white, there is the black. I call this an interbean. An interbean which illustrates a very deep teaching of the Buddha on inter being. So in a world that is full of hatred, discrimination, violence, and confusion, we ask ourselves, how do I know what's right? How do I know what's wrong to me? If we keep interbeing as a concentration, if we use inter being as a mirror to reflect upon our thoughts, speech, and behaviors, then we are on the right path. In the black, there is the white. In the white, there is the black. That's interbeing. And so if somebody has done something to hurt me, instead of thinking incessantly about that person, how they have caused me harm, I have learned to see myself in that person's situation. I have also done that to others, unknowingly or intentionally at times, I've also done so. And what kind of pain did that cause me? First and foremost, when I hurt others. And I also understand the working of the mind in those moments when I cause discomfort and pain to others. And I realize it's usually when I am suffering, when I'm unhappy, when I am in physical pain or emotional pain, again, hurt people, hurt people. Then there is that understanding from within. There's that coming home, being a soulmate to suffering, getting to know, to remember, to take care of it and to master it instead of always pointing our finger outward. You see? Now, the Buddha taught that there are four kinds of people, and I'd like to share that with you. The four kinds of people, how they ride the waves of life. The Buddha said the first kind of people are those who do not care about the well being of their own or of others. They don't care about their own well being or the well being of others. That's the first kind. Okay, who are these people? Well, when I was in my medical training, I did volunteer work at San Francisco Youth Guidance Center. These young men were less than 18 years of age and most of them were people of color. And one young man, he said, if I got aids, I'm going to go out there and spread AIDS to everybody. And to me, I was appalled at that moment to hear that. And at the same time, I knew this young man. He was not malicious. He was so sweet and he was very spiritual. Actually, when we ate something and we say, let's, you know, have a prayer, these young men, they would give the deepest, most sincere prayers. It was so moving. It was like poetry in motion. Very heartfelt. And yet he would say that that was my first experience realizing what, wow, these young men, they were so hurt. You know, there were some of them, their parents were in prison or were convicts. They had to learn to pump gas to get, to make money, to feed themselves. This particular young man earned $5 so that he could buy food for himself and for his sister. And one time he was sleeping with his $5 bill, like under his pillow, and his mother actually stole it so that she could buy drugs. Now, that was their circumstance. It made them so angry. Life was so unjust. And so they just wanted to, to hurt others the way they were hurt. Not because they were evil or malicious at all. They all wanted love and care so much. So the first kind of people, we understand that a lot of it, those prisoners, convicts, those people, con artists, et cetera, people, our own partners who hurt us so much is because they have been hurt so in their lives as children, as teenagers, as adults. Hurt people, hurt people. There are also big splashers. Yeah, I'm sure they also suffer a lot from insecurity that even though they are with great power, great fame, and they still can cause a lot of suffering. So even though outwardly they may have, you know, mansions, palaces, they may ride expensive Cars, they might have great titles and positions, but deep inside they don't really have that sense of well being. So to have everything, you know, like material, to have material luxury and power doesn't mean one cares about one's own well being, actually. And if one doesn't know how to care for one's own well being, one cannot care for others well being. So those big splashes. Now. Recently I went on a teaching tour for the Vietnamese youth we call Vic Wake up to help them wake up. And I was on the plane, I was boarding, and because we were the last group, all the aisle seat and window seats were taken. Only the middle seats were open. I mean, literally the whole length of the plane. So I saw the first row and the middle seat, but I saw, you know, there was leg room because it was by the door, the wing, and I wanted to go there. And the woman, she looked up at me, she looked at me from top to bottom and it was such a disgusted look. I just like. And my mind, it was like, I shouldn't sit here. She doesn't like me. Just one look at me. She was disgusted and hostile. But you know what, I figure I will be stuck in the middle anyway and it will be very in a cramped space. At least this had a bigger space. So I actually said, may I please sit here? And she said, she didn't say anything. She just looked down like that and okay, I swallow my pride. I practice humility. And I just quietly sat down, you know, next to her. And then as I settle down, I look over to her and I said, that's such a beautiful collar you have on. And she did. She had a vest, like a jacket, and it was like pink fuchsia, very beautiful, very becoming on her. So I said to her, and she was totally surprised. She's like. And then she said, oh, I like it too. And lo and behold, little by little, we started talking. And she, before you know it, she was telling me how she was abandoned as a child, how she was raised in a foster home and her foster father molested her. And she was crying and I put my hand on her face like this. And it came to my mind just a few minutes ago, we were not at all friendly. And now, you know, she was telling me something very deep from her heart. And I could put my hand on her face. That was such a deep connection. And then as we share more, I told her that my brother is a big Trump supporter. And when I first discovered that, I was just blown away. And I asked my brother, aren't we immigrants? Aren't we refugees? Because we are from Vietnam, you know, and my brother and I were children of the Vietnam War, which means that we were born to an American soldier and to a Vietnamese mother. My brother looks a lot more white than I do, but he's totally anti immigrants, wholly anti prisoners. He's anti everything. And my brother told me, sister, you have become one of those elites who is so. You are so educated, but so out of touch with reality. You are so out of touch with reality and with the people. And I just sat there. I'm like, he's anti everything, and I'm totally out of touch. So over the years, I have learned to not. When it comes to politics, my brother is a big splasher, and he's willing to drown me. He really wants to attack me on this topic. But I have told my brother, you know what? We are blood. Trump comes and Trump goes, but we are blood. We have stuck together all these years. So, anyway, I was sharing this with this woman on the airplane, and she sheepishly said to me, I'm very conservative. She is very conservative. Of course, I know that. But the way she said it, it was the sweetest thing. So I put my hand on her chest like this, and I said, but your heart is wide open. So that's one thing I have learned. When it comes to a big splasher, don't fight back. Either you lay low, huh? Go under, lay low, or just respond with compassion, with kindness. Like I saw that woman. I saw she had such a beautiful color on her, and I saw her as somebody, you know, who's suffering, and I really felt her pain. And so we were able to connect beyond our political views, which I am never a political person until 2016 came along. I know some of you here are Trump supporters, but that's not the point. The point is that in the Democrats, there are the Republicans, and in the Republicans, there are the Democrats. We need to see each other. We need to see each other that at certain time, we can be very conservative. We can be discriminative, we can be biased, we can be full of fear. You know, he's just somebody who is a master at watering seeds of fear, of bias, of discrimination, of hatred. He's just a master at doing that. And we all fall for it, and we all experience such fear, such uncertainty, such deep hatred towards each other. You know, I sat with this for so long, and at times when you don't like somebody, even my own brother or my own sister, sometimes I think not only I think you should just disappear. I have wanted to disappear so many times in my life and I've wished that on others as well. When you disagree something so badly, you just want one or the other one, or disappear to remove that problem, right? But in one sitting, a thought came to me. I love you, Trump. Oh my gosh. It was like, did I just hear that? And then it repeated itself in my mind. I love you, Trump. And then it repeated throughout that day and a few next few days. And now I can say it very naturally. I love you, Trump. And to have him either have a stroke or to have an enlightenment, I would rather him to have an enlightenment, to wake up, to see the state of this country, of this world, to see how people, many people suffer. And if he wakes up like that, it will have such a great impact on every one of us, right? So I'd rather wish him to wake up, to be enlightened than to have a stroke. But that thought, it may not. He may not ever have that kind of enlightenment, but he may still. Right? But at least it has lightened my own heart. It has helped me to preserve my love, my compassion, my faith in humanity. When we face the first kind of people who do not care about their own well being and others, we need to practice first and foremost to preserve our own humanness, our own goodness. Don't destroy that. Because when we destroy that, we just contribute to the despair, the suffering of this world. Let us breathe with the sound of the bell. Maybe you quietly say to yourself, I love you, Trump. Or send love to somebody, whether that person is close to you or public figure that you are not crazy about. You can also send love and understanding to that person. The second kind of people the Buddha talked about are those who care for the well being of others, but not their own. How many of you see yourself in that? Yeah, I think most of us are in this category. We care about the well being of others, but not our own. And I think of those of us who have gone through many difficulties in our lives, which I'm sure most of us have gone through some difficulties or others, some trauma. And we cope, we talk about the coping, different coping mechanism, you know, the first response to the stress we have, either we fight, we fight back. If the assessment from our nervous system for our mind is that we have a chance, we'll fight back. It also depends on our personality and our upbringing as well. We fight or we flight, we run away if there's no chance of winning. Or we freeze, right? We just freeze or have an out of body, experience a dissociative state. Or the fourth way of coping most of us don't think of is fawning. We try to please others. For example, if we have very neglectful parents or abusive parents, we may try to do all the right things. To be very obedient, to do all the housework, like to be a parent, to do very well in school. So that either they pay attention to us, they validate us, or at least they leave us alone and. And they won't hurt us anymore. We please others for our own survival. The thing is that, like I was sharing earlier, certain hardship that we experience and we cope with it, you know, automatically, usually. But what becomes a trauma is that that pattern is continued. It doesn't stop after the traumatic event has stopped. The event has stopped, and yet the pattern of coping continues. So now we have become adults. We have a lot more sovereignty, and yet we continue to fight. We fight within, we fight without, we fight constantly. Or we keep running away from relationships, from ourselves. We give up before we fail. It's like a prophecy, self fulfilling prophecy. I'll fail anyway. So we fail. Or we continue to please others at the cost of our own dignity, our own peace, our own life. So as parents, as health care providers, as teachers, as we offer service to others, we have to ask ourselves, what is this? What is the foundation of my service, of my giving? Do I have so much to share? Or it's because I feel I don't have enough? We operate on the foundation of lacking. I'm not enough. Therefore, I will try to do everything to prove that I'm enough so that people can see me. You see, there's a wonderful Chinese character for enough too. By the way, Nina will like this. It means enough. It has two meanings. It means foot or enough. And this character, it has the mouth or can also stand for the head. That's the body. The vertical line. The horizontal line is the arm and two legs. Enough. Now, when I share the dharma with children and teenagers, I share with them this Chinese character. Because as young as they are, they already feel not enough. I'm not good enough. I'm not tall enough, I'm not thin enough. I'm not built enough. I'm not smart enough. I'm not loved enough. I'm not good enough. They already feel that. And they grow into adults who feel they are not enough and who operate on this foundation of insufficiency. So I share with them. Do you have a head? They say yes. Do you have a head? Answer me. Do you have a body? Yes. Do you have an army? You got two arms still. I say all of you. Do you got two legs? Are you enough? Louder, more convincing. Are you enough? Are you sure? We have to remember that. And not just an arm and two legs. We have our heart that is still in good condition, even if you have to take medication for it. You have two lungs that are still in good condition, right? You can breathe on your own. You got everything, the liver, the kidneys, the spleen, the intestines, you know, like, we have more than enough, my dear. And that's the third and the fourth exercise. Yesterday we learned about the breath. We are still breathing. That's more than enough. And we still have our body. Breathing in, I'm aware of my body breathing out, I'm aware that I have my body still intact. Everything, only one thing is missing. For example, if you lose an eye, your life will completely change. If you lose an arm, your whole body will shift, your life will change, your profession will change. Maybe your partner will actually change too. Yeah, you have a heart attack. You see, everything we have, we take for granted. And yet if one thing goes out, it changes so much our life. So if we remember that everything we have is precious and everything we have is impermanent, is short lived, how do we want to care for ourselves? I ask young people that if you were to know that your life is. Is short and impermanent, how would you live differently? And these are young teenagers from 13 to 15. And most of them would say, I'll spend less time on my electronics, I'll spend more time with my family and friends. I won't turn temporary arguments into something permanent. Actually said that I won't waste so much time, you know, on games and all. These are young people. And then I also ask them, how would you be differently, behave differently, if you were to know that your parents lives are short and impermanent? And again, they touched that very deeply. And I told them this is not a hypothetical question. By the time I was 12, I had lost both of my parents. So we live life as if life is permanent, as if this body is permanent. Therefore we have all the luxury to criticize and to abuse it and to take it for granted. But the truth is that everything is impermanent. The, the waves of life, whether they are small waves or big waves, beautiful waves or ugly waves, they are also impermanent. And so if we remember that, we practice that, then we can ride the waves of life more stably, with more dignity and calm. Let us Enjoy one side of the bell. Breathing in, I'm aware of my body Breathing out I smile to my precious body. Breathing in, I calm my body with my mindful in breath and out breath Breathing out I release the tension in my body with my out breath with a smile with the thought I love you. I'm here for you. Help me to take good care of you. I know you are impermanent and may I take the best care of you as possible. I want to take good care of you the best way I can. Help me. The second kind of people who take care of others but forget ourselves. And then usually we end up feeling very bitter and betrayed. Like when our children leave home and they don't call us, they don't care about us and we think, you know, they're so ungrateful to all of our sacrifices. When I was a doctor, I felt that way towards some patients. I mean, I remember particularly this young man who came with an abscess on his. Was it on his butt? I have so many. One right on his butt and one right on his arm. And you know, they would stay for two months for us to every day to clean the wound, to dress the wound and everything because the infection will go through the muscles to the bones. And then a person would leave. And then a couple of months he comes back with another abscess on his abdomen which was so dangerous because he injected drugs into his abdomen. Must have run out of place to inject drugs. And I thought to myself, I'm wasting my time, I'm wasting my life, I'm wasting my youth taking care of these people who don't take care of themselves. But thankfully I also thought here I was educated, privileged in many ways, and yet I didn't know how to take care of myself. I was depressed every so often. I didn't eat at the right time, my sleep was irregular. You know, my emotions were also going up and down like a yo yo. So then I felt, wow, how can I expect somebody who's not stable, who doesn't have a stable home to take care of themselves? So when we feel angry or resentful towards those we take care of, we can hurt them too. You know, we can be bitter and abusive towards those we serve if we neglect ourselves. So the third kind of people, the Buddha said, are those who care about their own well being, but not others. And the Buddha asserted that the third kind of people are better, more superior than those first two kinds. And you may say that doesn't sound very Buddhist. Shouldn't you Sacrifice yourself, you know, to take care of others. But we already went through those first two kinds, and we see that whatever goodness that we do for others, but if we neglect ourselves in the long run, we cause harm and our work will be short lived. The third kind are those who learn to be their own soulmates. You know, these past three, four days, as my Lyme disease acts up, I was sharing, I got this joint pain, muscle pain. We were at Central Park, Central park in New York, and I was barely walking. I was feeling so dizzy and so sick. But I went, I did walking meditation with almost 100 friends who showed up. And even when we came here, not only physical, I have diarrhea every day, at least five times the last three, four days. Because every time when I have pain, that happens. And then on top of that, sciatica, so. But I have also learned wherever I am, if I sit here or there or I'm alone in my room, I learned to breathe, to breathe with that pain, with the soreness, to say to myself, I love you. I love you. I don't get frustrated with my body when I have pain. Before, I would hit my own body, when I had pain, I would scrub. I still have a scar right here. I used a coin, a Vietnamese coin, the shape of a star, and I scrubbed so hard that I caused it to bleed. And 40 something years later, I still have a scar right here. I would pull my hair until I had a spa, a bald spot when I was a child. But now I learn when I have pain, whether it's physical or emotional, I just hold myself and say, I love you. I'm sorry you have pain. Thank you for carrying the burden of my pain. Whether at that moment my digestive system is carrying that pain and manifesting that pain, or my joints or my head anywhere, I just put my arms on that part and say, thank you. I'm so grateful for you, for being resilient, for enduring this pain. I learn to take care of myself first and foremost. Always, wherever I am, I learn to use loving speech and deep listening to my own body. And it brings relief, it brings comfort. Don't fight your pain. Don't put down your body. I've done that for so many years. And it's like a boxer, you know, but punches you, you fall down, you try get up, you hit again, you hit again. After a while, you can't get up anymore. And that's what we do to ourselves. We keep boxing ourselves, hitting ourselves, until we cannot get up anymore, until the body is so tired, immune System is so low that something comes along and you pick it up like I pick up Lyme disease. Just the first stick bite I ever had. And it became neural Lyme disease that affected my cognitive functions as well as the rest of my body. So I understood the causes and conditions. And I learned not to hate my body for being sick, but to love my body even more so. And as I learned to remember, to know, to take care of that pain, I'm able to be there for others. Maybe I miss an activity here and there, but in those moments I am taking care of myself so that I can be there for others. And it's totally different from the time that I was a doctor. I was always out there taking care of my patients and yet I wasn't taking care of myself. Therefore, many doctors become resentful and bitter and even abusive and arrogant. Let us enjoy a sound bell. The fourth kind of people are those who care about their own well being and the well being of others. And really the third kind of people naturally become the fourth kind of people. So when you care about your well being again, it's not about being a diva, right? Me, me, me, me, me, me, me, me, me. That's actually the first kind. You're not really caring about your well being. Because me, me me is not well being. It's just miserable, egoistical, arrogant and selfish person, right? So this is really a deep understanding and compassion of our own being in light of inter being. I am hurt, I can hurt others. My well being will help the well being of others. Therefore I learn to take care of this foundation again and again. So the fourth kind of people, it's no longer so much of a difference between you and me, between my well being versus your well being. Because we know we affect each other energetically. Our thoughts, speech and actions really affect one another. Those who are near us, those who are on the other side of the planet. I remember one time when I first ordained. I was in deep, deep pain. And I came to taste hermitage where our teacher stayed and a group of us, group of Faust sisters who could come and stay at a building, you know, built next to Thay's hermitage. And we stayed there for a week. And I remember one day I climbed on this magnolia tree right in front of our teacher's office. You know, his room, there's a door, this big magnolia tree, I could climb on it and I saw these parasitic plants and I pulled the plants and threw on the ground and I did that for hours. One plant, I went on to another and Thay must have been in his room and looked out and must have seen me doing that. But I didn't say anything. And that kind of restless energy, that kind of angst in me caused me to do that. I just pulled throw down, you know. And that evening we had a meal with Thay, with our teacher. And everybody was eating peacefully, quietly, and tears were just rolling down. I was making soup with my tears, you know, I. I couldn't eat anything. And Thay also didn't say anything. But after dinner, Thay just said to me, follow me, my child. And we went to the meditation room right next to the kitchen. And Thay was walking, and Thay signaled me to walk with him. And he was doing very slow walking meditation because the room wasn't very big. And we had like this carpet pretty thick and the beige color. So every step we made made an imprint on the carpet. And Thay kept doing that slow walking meditation in circles. And I was right behind Thay. And after a long while, what came to me was that all these footsteps, I couldn't make out which ones were Thay's and which ones were mine. And I couldn't make out which steps were the beginning and which steps were the end. It was just all like that. And we kept walking. And it was such a deep lesson to me. Paid footsteps, mindful steps, beginning and end. It kept going, kept going. And something about that insight really helped me to not see my suffering as my own, but to see that, you know, as a continuation of my family, my ancestors, and not just that of humanity. There's no beginning and no end. And our steps, our beings, we try too hard to assert ourselves as individuals. And yes, we have this one chance to live this life. It is important to strive and do our best, but to do our best to live as beautifully as possible, as harmoniously with ourselves and with each other as possible. That's our one chance not to push each other, not to, you know, kick each other out, but to like to do our best in these endless circles. And I experienced this at Central park too. Let's listen to one sound of the bell. You know how in Central park, people run? They run. And at every point that I exit, I come on the road, I saw people running, and it was so amazing. People of all different ages, of all different skin colors, of all different ways of driving, dressing, different body types, all sorts, but they kept running. Some run faster, some run slower. But, you know, you get out on the street, you see, and then you get on another street, another group of People. But it's like squirreling mass of humanity. There's no beginning, no end, and it keeps going and going again. I relive that experience, experience with walking with thay and to see we are so incredibly insignificant in this mass of humanity, in these waves of life. And yet each one of us is still responsible for living the best way we can. To be the third kind of people, to be the fourth kind of people. By learning to be a soulmate to our suffering, to our trauma, to each other's suffering, to each other's trauma. And if we can just do that, our life is. It's meaningful, it's worthwhile. And if we were to die tonight, we'll be at peace. Because we have made peace with ourselves, with our life, because we have made peace with others who might have hurt us, from whom we might have hurt. We learn to make peace with what was, what is and what will be. And that really starts with every breath that we make. Make peace in your own body, in your own feelings, with your in breath, out breath. One at a time, with your left foot, your right foot, one step at a time, you can make peace. I love you. It's okay. Help me to take good care of you. Help me to choose peace and choose harmony. Help me to be here and not check out, not to try to escape, just simply be here. It My dear ones, this time that we are together is very precious and rare and also impermanent. So let us do our best to support each other with our practice. And when you go to dinner or meals, just see if you can sit at different tables with different people. And whether we're in noble silence or not, just reach out and smile to each other and see ourselves in one another. Feel that connection which can help us in times to come when we feel lonely, we can recall this time. Recall that we are never alone. Really. It sa. Please take a moment to uncross your legs and massage your body and give gratitude to your body. You want to make some announcement?\n",
      "[B] Dear Standard, please allow me to make a few announcements. I know we are quite late for.\n",
      "[A] Lunch.\n",
      "[B] So this afternoon at 2:30 we'll have another chance to practice deep relaxation. And after that is the demo sharing sessions. And on the table over here we have. We have already prepared the application for the five mindfulness training. So if you would like to receive the five mindfulness trainings, please take the application form and fill it up and send it to your monastic facilitator in your daimushing family by tomorrow afternoon after the Dharma sharing or the latest is after dinner tomorrow, so that the monastic can have enough time to prepare the certificate for you. And we will have the five mindfulness training transmission ceremony on the last morning of our retreat on Friday morning.\n",
      "[A] Please also allow me to share that today after deep relaxation, we'll have a special activity because we thought it would be nice if we all interact in a bigger group, get to know each other a little more. That's why we ask you to wear that name tag. So even if we don't talk, we look at the name and we feel, you know, we can acknowledge each other. But today after deep relaxation, you can take a restroom break and then come back here. And at 4 o' clock the monastics will come and have that, you know, some activities as a big group before we break into dharma sharing group. And huh, 3:30, 2:30 to 3:30 is deep relaxation. And then 3:45 we have the big activity. So please stay or come for that activity. And also may I encourage Dharma sharing is very precious. And please do your best to show up to support each other. And if you are sick, of course, please rest. But otherwise, please come because the retreat will be done. We'll finish very soon, so enjoy this rare time that we have together. Thank you. With the sound of the bell, we'll stand up and bow to each other in gratitude and enjoy lunch, dear ones. Oh, one more announcement. Yeah.\n",
      "[B] So tonight after dinner, we also have another sessions of personal consultation, which is the last session, so please check out the list. It's already post to know your monastic, whom you will meet and the location. Thank you.\n",
      "[A] And also afterwards, please give a hand to prepare the meditation hall for deep relaxation. You are already so good at it. Standing up. We are aware that we are standing up, joining our palms with awareness. Thank you, dear ones.\n"
     ]
    }
   ],
   "source": [
    "print(full_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = BASE_DIR / audio_file_path.with_suffix(\".txt\")\n",
    "write_str_to_file(path_out, full_out, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_config = SRTConfig(include_speaker=SRT_INCLUDE_SPEAKER) \n",
    "srt_processor = SRTProcessor(srt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_out = srt_processor.generate(full_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(srt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the diarization results\n",
    "\n",
    "print(f\"Loading diarization results from {diarization_results_path}\")\n",
    "chunker = TimeGapChunker(config=diarize_config)\n",
    "segment_adapter = PyannoteAdapter(config=diarize_config)\n",
    "result = load_diarization_result(file_path=diarization_results_path)\n",
    "data = result['output']\n",
    "segments = segment_adapter.to_segments(data)\n",
    "chunk_list = chunker.extract(segments)\n",
    "\n",
    "for chunk in chunk_list:\n",
    "    print(f\"  chunk: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarize_raw = data['diarization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarize_raw[0]['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list = [seg for seg in segments if seg.duration_sec > 4.0]\n",
    "long_list_info = [\n",
    "    (i, \n",
    "    seg.duration_sec, seg.start.to_seconds(), \n",
    "    seg.end.to_seconds(), seg.speaker\n",
    "    ) \n",
    "    for i, seg in enumerate(long_list) \n",
    "]\n",
    "long_list_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_blocks = group_speaker_blocks(segments, config=diarize_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speaker_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Streamlit viewer with data: /var/folders/rn/6vvb1zdx0z59xqgkpcy8_fx00000gq/T/tmpibtq9pzx.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://10.249.8.237:8501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 08:36:24.409 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    }
   ],
   "source": [
    "pid = launch_segment_viewer(speaker_blocks[:250], audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Streamlit viewer (PID 35020)\n",
      "  Stopping...\n"
     ]
    }
   ],
   "source": [
    "close_segment_viewer(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(block.speaker, block.duration) for block in speaker_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker='SPEAKER_04' start=TimeMs(358.205s) end=TimeMs(359.185s) audio_map_start=TimeMs(169.100s) gap_before=False spacing_time=TimeMs(0.000s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/rn/6vvb1zdx0z59xqgkpcy8_fx00000gq/T/tmpj3bctyj0.wav':\n",
      "  Duration: 00:00:00.98, bitrate: 3072 kb/s\n",
      "  Stream #0:0: Audio: pcm_s32le ([1][0][0][0] / 0x0001), 48000 Hz, 2 channels, s32, 3072 kb/s\n",
      "   0.88 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_idx = 167\n",
    "seg = segments[test_idx]\n",
    "print(seg)\n",
    "play_diarization_segment(seg, base_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = WhisperLanguageDetector()\n",
    "\n",
    "probe = LanguageProbe(\n",
    "    config=diarize_config, \n",
    "    detector=detector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_audio = get_segment_audio(seg, base_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tnh_scholar.utils.tnh_audio_segment.TNHAudioSegment at 0x1413c4a10>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aug_seg = AugDiarizedSegment.from_segment(segments[test_idx], audio=seg_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AugDiarizedSegment(speaker='SPEAKER_02', start=TimeMs(0.565s), end=TimeMs(13.465s), audio_map_start=None, gap_before=False, spacing_time=0, gap_before_new=False, spacing_time_new=TimeMs(0.000s), audio=<tnh_scholar.utils.tnh_audio_segment.TNHAudioSegment object at 0x1413c4a10>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.segment_language(aug_segment=aug_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "from openai import RateLimitError\n",
    "\n",
    "segments_to_probe = long_list\n",
    "\n",
    "def probe_segment_safe(probe, aug_segment):\n",
    "    try:\n",
    "        return probe.segment_language(aug_segment=aug_segment)\n",
    "    except RateLimitError:\n",
    "        print(\"Rate limit hit, sleeping and retrying...\")\n",
    "        time.sleep(10)  # Wait and retry\n",
    "        try:\n",
    "            return probe.segment_language(aug_segment=aug_segment)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed again: {e}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example: probe all segments in long_list (or chunk_list, or your own list)\n",
    "max_workers = 1000  # Adjust based on your rate limit\n",
    "results = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(\n",
    "        probe_segment_safe, \n",
    "        probe, \n",
    "        AugDiarizedSegment.from_segment(seg, audio=get_segment_audio(seg, base_audio))\n",
    "        )\n",
    "        for seg in segments_to_probe]  # Adjust range as needed\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        results.append(future.result())\n",
    "\n",
    "print(\"Language probe results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[chunk.accumulated_time for chunk in chunk_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(chunk.segments) for chunk in chunk_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract speaker audio segments\n",
    "print(\"Extracting speaker audio segments to local ByteIO objects\")\n",
    "audio_handler = AudioHandler()\n",
    "total_chunks = len(chunk_list) \n",
    "\n",
    "for i, chunk in enumerate(chunk_list, start=1):\n",
    "    print(f\"Building chunk {i} of {total_chunks}\")\n",
    "    audio_handler.build_audio_chunk(chunk, audio_file=audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiarizationChunk(start_time=565, end_time=126485, audio=AudioChunk(data=<_io.BytesIO object at 0x142e93ec0>, start_ms=565, end_ms=126485, sample_rate=None, channels=None, format='flac'), segments=[DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(0.565s), end=TimeMs(13.465s), audio_map_start=0, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(12.865s), end=TimeMs(12.885s), audio_map_start=12900, gap_before=False, spacing_time=TimeMs(-0.600s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(14.325s), end=TimeMs(18.705s), audio_map_start=14360, gap_before=False, spacing_time=TimeMs(1.440s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(16.765s), end=TimeMs(16.805s), audio_map_start=18740, gap_before=False, spacing_time=TimeMs(-1.940s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(17.445s), end=TimeMs(22.325s), audio_map_start=19420, gap_before=False, spacing_time=TimeMs(0.640s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(19.245s), end=TimeMs(19.725s), audio_map_start=24300, gap_before=False, spacing_time=TimeMs(-3.080s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(20.145s), end=TimeMs(21.345s), audio_map_start=25200, gap_before=False, spacing_time=TimeMs(0.420s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(21.665s), end=TimeMs(23.485s), audio_map_start=26720, gap_before=False, spacing_time=TimeMs(0.320s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(23.865s), end=TimeMs(26.885s), audio_map_start=28920, gap_before=False, spacing_time=TimeMs(0.380s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(24.225s), end=TimeMs(29.625s), audio_map_start=31940, gap_before=False, spacing_time=TimeMs(-2.660s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(30.025s), end=TimeMs(31.185s), audio_map_start=37740, gap_before=False, spacing_time=TimeMs(0.400s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(30.465s), end=TimeMs(35.965s), audio_map_start=38900, gap_before=False, spacing_time=TimeMs(-0.720s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(31.185s), end=TimeMs(31.525s), audio_map_start=44400, gap_before=False, spacing_time=TimeMs(-4.780s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(31.525s), end=TimeMs(31.545s), audio_map_start=44740, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(31.545s), end=TimeMs(31.585s), audio_map_start=44760, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(31.585s), end=TimeMs(31.705s), audio_map_start=44800, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(31.705s), end=TimeMs(31.765s), audio_map_start=44920, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(33.525s), end=TimeMs(35.665s), audio_map_start=46740, gap_before=False, spacing_time=TimeMs(1.760s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(35.665s), end=TimeMs(35.685s), audio_map_start=48880, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(35.685s), end=TimeMs(35.765s), audio_map_start=48900, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(35.765s), end=TimeMs(35.805s), audio_map_start=48980, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(35.805s), end=TimeMs(35.825s), audio_map_start=49020, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(35.825s), end=TimeMs(41.025s), audio_map_start=49040, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(36.125s), end=TimeMs(36.345s), audio_map_start=54240, gap_before=False, spacing_time=TimeMs(-4.900s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(36.345s), end=TimeMs(36.365s), audio_map_start=54460, gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(37.105s), end=TimeMs(37.165s), audio_map_start=55220, gap_before=False, spacing_time=TimeMs(0.740s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(38.665s), end=TimeMs(38.825s), audio_map_start=56780, gap_before=False, spacing_time=TimeMs(1.500s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(39.685s), end=TimeMs(43.585s), audio_map_start=57800, gap_before=False, spacing_time=TimeMs(0.860s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(43.325s), end=TimeMs(55.165s), audio_map_start=61700, gap_before=False, spacing_time=TimeMs(-0.260s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(45.565s), end=TimeMs(45.865s), audio_map_start=73540, gap_before=False, spacing_time=TimeMs(-9.600s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(53.025s), end=TimeMs(54.405s), audio_map_start=TimeMs(74.840s), gap_before=True, spacing_time=TimeMs(1.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(55.285s), end=TimeMs(56.145s), audio_map_start=TimeMs(77.100s), gap_before=False, spacing_time=TimeMs(0.880s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(56.105s), end=TimeMs(56.885s), audio_map_start=TimeMs(77.960s), gap_before=False, spacing_time=TimeMs(-0.040s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(57.145s), end=TimeMs(57.845s), audio_map_start=TimeMs(79.000s), gap_before=False, spacing_time=TimeMs(0.260s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(58.965s), end=TimeMs(76.505s), audio_map_start=TimeMs(80.820s), gap_before=False, spacing_time=TimeMs(1.120s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(62.105s), end=TimeMs(62.405s), audio_map_start=TimeMs(98.360s), gap_before=False, spacing_time=TimeMs(-14.400s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(64.085s), end=TimeMs(64.505s), audio_map_start=TimeMs(100.340s), gap_before=False, spacing_time=TimeMs(1.680s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(64.525s), end=TimeMs(64.545s), audio_map_start=TimeMs(100.780s), gap_before=False, spacing_time=TimeMs(0.020s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(68.185s), end=TimeMs(69.685s), audio_map_start=TimeMs(104.440s), gap_before=False, spacing_time=TimeMs(3.640s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(70.465s), end=TimeMs(73.865s), audio_map_start=TimeMs(106.720s), gap_before=False, spacing_time=TimeMs(0.780s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(73.865s), end=TimeMs(75.305s), audio_map_start=TimeMs(110.120s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(75.305s), end=TimeMs(86.925s), audio_map_start=TimeMs(111.560s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(87.285s), end=TimeMs(88.045s), audio_map_start=TimeMs(123.540s), gap_before=False, spacing_time=TimeMs(0.360s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(88.505s), end=TimeMs(101.145s), audio_map_start=TimeMs(124.760s), gap_before=False, spacing_time=TimeMs(0.460s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(91.585s), end=TimeMs(91.745s), audio_map_start=TimeMs(137.400s), gap_before=False, spacing_time=TimeMs(-9.560s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(97.805s), end=TimeMs(98.765s), audio_map_start=TimeMs(138.560s), gap_before=True, spacing_time=TimeMs(1.000s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(99.385s), end=TimeMs(99.705s), audio_map_start=TimeMs(140.140s), gap_before=False, spacing_time=TimeMs(0.620s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(101.005s), end=TimeMs(105.145s), audio_map_start=TimeMs(141.760s), gap_before=False, spacing_time=TimeMs(1.300s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(104.265s), end=TimeMs(108.005s), audio_map_start=TimeMs(145.900s), gap_before=False, spacing_time=TimeMs(-0.880s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(105.145s), end=TimeMs(106.565s), audio_map_start=TimeMs(149.640s), gap_before=False, spacing_time=TimeMs(-2.860s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(107.785s), end=TimeMs(109.965s), audio_map_start=TimeMs(152.280s), gap_before=False, spacing_time=TimeMs(1.220s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(109.885s), end=TimeMs(109.945s), audio_map_start=TimeMs(154.460s), gap_before=False, spacing_time=TimeMs(-0.080s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(109.965s), end=TimeMs(111.425s), audio_map_start=TimeMs(154.540s), gap_before=False, spacing_time=TimeMs(0.020s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(110.405s), end=TimeMs(114.485s), audio_map_start=TimeMs(156.000s), gap_before=False, spacing_time=TimeMs(-1.020s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(113.905s), end=TimeMs(113.925s), audio_map_start=TimeMs(160.080s), gap_before=False, spacing_time=TimeMs(-0.580s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(113.925s), end=TimeMs(113.945s), audio_map_start=TimeMs(160.100s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(113.945s), end=TimeMs(114.365s), audio_map_start=TimeMs(160.120s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(114.365s), end=TimeMs(114.405s), audio_map_start=TimeMs(160.540s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(114.405s), end=TimeMs(114.425s), audio_map_start=TimeMs(160.580s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(114.425s), end=TimeMs(114.445s), audio_map_start=TimeMs(160.600s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(115.025s), end=TimeMs(123.625s), audio_map_start=TimeMs(161.200s), gap_before=False, spacing_time=TimeMs(0.580s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(120.805s), end=TimeMs(120.985s), audio_map_start=TimeMs(169.800s), gap_before=False, spacing_time=TimeMs(-2.820s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(121.085s), end=TimeMs(121.125s), audio_map_start=TimeMs(170.080s), gap_before=False, spacing_time=TimeMs(0.100s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(121.125s), end=TimeMs(122.125s), audio_map_start=TimeMs(170.120s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_02', start=TimeMs(122.125s), end=TimeMs(126.145s), audio_map_start=TimeMs(171.120s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(124.225s), end=TimeMs(124.605s), audio_map_start=TimeMs(175.140s), gap_before=False, spacing_time=TimeMs(-1.920s)), DiarizedSegment(speaker='SPEAKER_06', start=TimeMs(124.605s), end=TimeMs(126.625s), audio_map_start=TimeMs(175.520s), gap_before=False, spacing_time=TimeMs(0.000s)), DiarizedSegment(speaker='SPEAKER_04', start=TimeMs(126.425s), end=TimeMs(126.485s), audio_map_start=TimeMs(177.540s), gap_before=False, spacing_time=TimeMs(-0.200s))], accumulated_time=114700)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.92"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list[0].total_duration_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list = [chunk.audio for chunk in chunk_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_chunk = audio_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioChunk(data=<_io.BytesIO object at 0x142e93ec0>, start_ms=565, end_ms=126485, sample_rate=None, channels=None, format='flac')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio_mp4(aud_chunk.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 21:30:14,547 - tnh.tnh_scholar.audio_processing.transcription.assemblyai_service - \u001b[1;32mDEBUG\u001b[0m - Created logger with name: tnh.tnh_scholar.audio_processing.transcription.assemblyai_service\u001b[0m\n",
      "2025-07-24 21:30:14,549 - tnh.tnh_scholar.audio_processing.transcription.whisper_service - \u001b[1;32mDEBUG\u001b[0m - API key updated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ts_service = TranscriptionServiceFactory.create_service(provider=TRANSCRIBER)\n",
    "\n",
    "transcription_options_whisper = {\n",
    "    \"language\": LANGUAGE, \"timestamp_granularities\": [\"word\"], \"prompt\": metadata\n",
    "    }\n",
    "transcription_options_whisper = patch_whisper_options(\n",
    "    transcription_options_whisper, file_extension=file_ext_str\n",
    "    )\n",
    "transcription_options_aai = {\"language_code\": LANGUAGE, \"language_detection\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_options = transcription_options_whisper \\\n",
    "    if TRANSCRIBER == 'whisper' \\\n",
    "        else transcription_options_aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_to_process = chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts: List[TranscriptionResult]= []\n",
    "for i, chunk in enumerate(chunks_to_process, start=1):\n",
    "    print(f\"processing chunk: {i}\")\n",
    "    audio = chunk.audio\n",
    "    if not audio:\n",
    "        raise ValueError(\"No audio data for chunk.\")\n",
    "    audio_obj = audio.data\n",
    "    print(f\"Running transcript generation with {TRANSCRIBER} service...\")\n",
    "    print(f\"Audio file: {audio_obj}\")\n",
    "    transcript = ts_service.transcribe(audio_obj, transcription_options)\n",
    "    print(transcript)\n",
    "    transcripts.append(transcript)\n",
    "    \n",
    "print(\"Transcription loop complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 21:45:57,423 - tnh.tnh_scholar.audio_processing.diarization.timeline_mapper - \u001b[1;32mDEBUG\u001b[0m - Created logger with name: tnh.tnh_scholar.audio_processing.diarization.timeline_mapper\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mapper = TimelineMapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = []\n",
    "for chunk, transcript in zip(chunk_list, transcripts):\n",
    "    tt = transcript.word_timing\n",
    "    if tt is not None:\n",
    "        new_timing = mapper.remap(tt, chunk)\n",
    "        timings.append(new_timing)\n",
    "    else:\n",
    "        raise ValueError(\"No timed text for words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_timing = TimedText.merge(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_builder = TextSegmentBuilder(max_duration_ms=4*1000, target_characters=42, ignore_speaker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seg = segment_builder.create_segments(complete_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_config = SRTConfig(include_speaker=SRT_INCLUDE_SPEAKER) \n",
    "srt_processor = SRTProcessor(srt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_out = srt_processor.generate(full_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(srt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio_mp4(aud_chunk.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(str(audio_file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"srt_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ext = \".srt\"\n",
    "new_stem = f\"{audio_file_path.stem}_{test_str}\"\n",
    "srt_path = audio_file_path.with_name(new_stem + new_ext)\n",
    "\n",
    "\n",
    "write_str_to_file(srt_path, srt_out, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PROCESS PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Translating SRT files to English =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BASE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Translating SRT files to English =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Find all _final.srt files in each speaker directory\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m srt_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mBASE_DIR\u001b[49m\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.srt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrt_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     en_srt_file \u001b[38;5;241m=\u001b[39m srt_file\u001b[38;5;241m.\u001b[39mwith_name(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrt_file\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_en.srt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BASE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Post-processing: Translate all final SRT files to English\n",
    "print(\"\\n===== Translating SRT files to English =====\")\n",
    "\n",
    "        \n",
    "# Find all _final.srt files in each speaker directory\n",
    "for srt_file in BASE_DIR.glob(\"*.srt\"):\n",
    "    print(f\"file: {srt_file}\")\n",
    "          \n",
    "    en_srt_file = srt_file.with_name(f\"{srt_file.stem}_en.srt\")\n",
    "    \n",
    "    # Skip if English version already exists\n",
    "    if en_srt_file.exists():\n",
    "        print(f\"English SRT already exists: {en_srt_file}\")\n",
    "        continue\n",
    "        \n",
    "    # Run srt-translate\n",
    "    cmd = f\"srt-translate '{srt_file}' -o '{en_srt_file}' -t en\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "        print(f\"Successfully translated: {srt_file} -> {en_srt_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error translating {srt_file}: {e}\")\n",
    "\n",
    "print(\"===== Translation complete =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and renaming completed.\n"
     ]
    }
   ],
   "source": [
    "# --- Settings ---\n",
    "srt_folder = BASE_DIR  # <-- Change this to your actual folder\n",
    "srt_processor = SRTProcessor()\n",
    "\n",
    "# --- Processing Loop ---\n",
    "for srt_file in srt_folder.glob(\"*.srt\"):\n",
    "    # Read original SRT content\n",
    "    srt_content = srt_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # Parse to TimedText\n",
    "    timed_text = srt_processor.parse(srt_content)\n",
    "\n",
    "    # Re-generate SRT without speaker labels\n",
    "    cleaned_srt = srt_processor.generate(timed_text, include_speaker=False)\n",
    "\n",
    "    # Rename original file to *_sp.srt\n",
    "    speaker_file = srt_file.with_stem(f\"{srt_file.stem}_sp\")\n",
    "    srt_file.rename(speaker_file)\n",
    "\n",
    "    # Save cleaned SRT under original filename\n",
    "    srt_file.write_text(cleaned_srt, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Cleaning and renaming completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process each speaker's audio\n",
    "# for speaker, blocks in mapped_blocks.items():\n",
    "#     speaker_audio_path = export_dir / f\"{speaker}.mp3\"\n",
    "#     speaker_output_dir = export_dir / \"audio_transcriptions\" / speaker\n",
    "#     audio_transcribe_output_dir = export_dir / \"audio_transcriptions\"\n",
    "#     ensure_directory_exists(speaker_output_dir)\n",
    "    \n",
    "#     print(f\"\\nProcessing {speaker}...\")\n",
    "    \n",
    "#     # Run audio-transcribe on the speaker's audio file\n",
    "#     cmd = f\"audio-transcribe -f {speaker_audio_path} --output_dir {audio_transcribe_output_dir} --split --transcribe\"\n",
    "#     print(f\"Running: {cmd}\")\n",
    "#     subprocess.run(cmd, shell=True, check=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
