{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "%aimport json\n",
    "from pathlib import Path\n",
    "%aimport re\n",
    "from typing import List, Dict\n",
    "%aimport os\n",
    "from xml.sax.saxutils import escape\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.text_processing import get_text_from_file, set_working_directory, get_working_directory\n",
    "from data_processing.text_processing import normalize_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.text_processing import write_text_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.gpt_processing import token_count, set_api_client, get_api_client, get_active_batches\n",
    "from data_processing.gpt_processing import generate_messages, run_immediate_chat_process, create_jsonl_file_for_batch, start_batch\n",
    "from data_processing.gpt_processing import get_completed_batches, get_batch_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.xml_processing import split_xml_pages, save_pages_to_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(\"/Users/phapman/Desktop/tnh-scholar/\")\n",
    "data_dir = project_dir / \"data_processing\"\n",
    "journal_dir = data_dir / \"processed_journal_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_string_clean = \"\"\"{text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_wrap_function_clean(text_block):\n",
    "    return user_message_string_clean.format(text=text_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_clean = \"\"\"\n",
    "You are a meticulous and consistent world expert at cleaning OCR-generated Vietnamese text. \n",
    "You are cleaning text from a 1950's Buddhist Journal. \n",
    "The text will be given in XML, and the output text should be in matching XML. \n",
    "Your goal is to minimally modify the text to generate a cleaned version.\n",
    "Do not remove any text from the main body of the text. \n",
    "Formatting markers (such as footers) at the end of the text can be adjusted or removed as needed for clarity. \n",
    "You can use patterns in the text blocks (given by page) to infer patterns in the text.\n",
    "You can use the semantic meaning of the text to infer correctionsâ€”but make no semantic changes. \n",
    "You can also add diacritical marks if they are missing or clearly inaccurate. \n",
    "Do not change any proper names, except to add missing diacritical marks if the context is clear.  \n",
    "This particular text has a title marker: \"Phat Giao Viet Nam,\" and also a publishing mark near the end of each page of text. \n",
    "The publishing mark is something like \"TU VIEN HUE QUANG\"  and is very difficult for the OCR to process. \n",
    "Text corresponding to these marks (or part thereof) and page numbers can be omitted.\n",
    "Output the corrected text only with no comments (including ``` xml).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = \"phat-giao-viet-nam-1956-01\"\n",
    "ocr_file_to_process = journal_dir / basename / f\"full_OCR_{basename}.xml\"\n",
    "ocr_file_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_message_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_single_oa_batch_from_pages(\n",
    "    input_xml_file: str,\n",
    "    output_file: str,\n",
    "    system_message: str,\n",
    "    user_wrap_function,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a batch file for the OpenAI (OA) API using a single input XML file.\n",
    "\n",
    "    Parameters:\n",
    "        batch_file (str): Full path to the input XML file to process.\n",
    "        output_file (str): Full path to the output batch JSONL file.\n",
    "        system_message (str): System message template for batch processing.\n",
    "        user_wrap_function (callable): Function to wrap user input for processing pages.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the created batch file.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If an error occurs during file processing.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Read the OCR text from the batch file\n",
    "        text = get_text_from_file(input_xml_file)\n",
    "        logger.info(f\"Processing file: {input_xml_file}\")\n",
    "\n",
    "        # Split the text into pages for processing\n",
    "        pages = split_xml_pages(text)\n",
    "        if not pages:\n",
    "            raise ValueError(f\"No pages found in XML file: {input_xml_file}\")\n",
    "        logger.info(f\"Found {len(pages)} pages in {input_xml_file}.\")\n",
    "\n",
    "        # Generate messages for the pages\n",
    "        batch_message_seq = generate_messages(system_message, user_wrap_function, pages)\n",
    "\n",
    "        # Save the batch file\n",
    "        create_jsonl_file_for_batch(batch_message_seq, output_file)\n",
    "        logger.info(f\"Batch file created successfully: {output_file}\")\n",
    "\n",
    "        return output_file\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {input_xml_file}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Value error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error while processing {input_xml_file}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def generate_all_batches(\n",
    "    processed_document_dir: str,\n",
    "    system_message: str,\n",
    "    user_wrap_function,\n",
    "    file_regex: str = r\".*\\.xml\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate cleaning batches for all journals in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        processed_journals_dir (str): Path to the directory containing processed journal data.\n",
    "        system_message (str): System message template for batch processing.\n",
    "        user_wrap_function (callable): Function to wrap user input for processing pages.\n",
    "        file_regex (str): Regex pattern to identify target files (default: \".*\\\\.xml\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    document_dir = Path(processed_document_dir)\n",
    "    regex = re.compile(file_regex)\n",
    "\n",
    "    for journal_file in document_dir.iterdir():\n",
    "        if journal_file.is_file() and regex.search(journal_file.name):\n",
    "            try:\n",
    "                # Derive output file path\n",
    "                output_file = journal_file.with_suffix(\".jsonl\")\n",
    "                logger.info(f\"Generating batch for {journal_file}...\")\n",
    "\n",
    "                # Call single batch function\n",
    "                generate_single_oa_batch_from_pages(\n",
    "                    input_xml_file=str(journal_file),\n",
    "                    output_file=str(output_file),\n",
    "                    system_message=system_message,\n",
    "                    user_wrap_function=user_wrap_function,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to process {journal_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "    logger.info(\"Batch generation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_client = set_api_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job_dir = data_dir / \"gpt_processing\" / \"gpt_batch_files\"\n",
    "batch_file_path = batch_job_dir / \"journal_cleaning_batches\" / f\"clean_batch_{basename}.jsonl\"\n",
    "batch_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_single_oa_batch_from_pages(ocr_file_to_process, batch_file_path, system_message_clean, user_wrap_function_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## completed batches:\n",
    "10, 25-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = start_batch(batch_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_active_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = get_completed_batches()\n",
    "completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = get_batch_response(completed[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_pages(data):\n",
    "    result = [\"<document>\"]\n",
    "    result = result + data\n",
    "    result.append(\"</document>\")\n",
    "    return \"\\n\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned_text = join_pages(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned_path = journal_dir / basename / f\"full_cleaned_{basename}.xml\"\n",
    "full_cleaned_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_text_to_file(full_cleaned_path, full_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cleaned_current = get_text_from_file(full_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_cleaned_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count(full_cleaned_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages = split_xml_pages(full_cleaned_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_page_tags(text):\n",
    "    \"\"\"\n",
    "    Removes <page ...> and </page> tags from a text string.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text containing <page> tags.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with <page> tags removed.\n",
    "    \"\"\"\n",
    "    # Remove opening <page ...> tags\n",
    "    text = re.sub(r\"<page[^>]*>\", \"\", text)\n",
    "    # Remove closing </page> tags\n",
    "    text = re.sub(r\"</page>\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages = [remove_page_tags(page) for page in cleaned_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pages[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_sections = split_xml_pages(full_cleaned_text, page_groups=[(1, 6), (7, 17),(18, 25), (26, 30), (31, 36), (37, 37), (38, 44), (45, 51)])\n",
    "# print(clean_xml_keep_pages(cleaned_sections[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cleaned_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_translate = \"\"\"\n",
    "You are Thich Nhat Hanh translating from Vietnamese to English for your experienced students. \n",
    "The text is based on an OCR scan of a journal you edited from 1956-1958. Use the title: \"Journal of Vietnamese Buddhism\" \n",
    "You want your students to understand the material and its historical and cultural contextâ€”in particular, as it relates to your life and teachings.\n",
    "You will be translating a single section of the journal and with the title\n",
    "Translate for the most meaningful, typical, and eloquent English interpretation.\n",
    "Keep pages together: each translated page must match its original page source as pages will be studied side by side with the original Vietnamese.\n",
    "Infer paragraphs and text structure from the text layout.\n",
    "Add XML tags for clarity. Use only the following: \n",
    "\n",
    "   <p> for paragraphs.\n",
    "   <section> for major sections.\n",
    "   <subsection> for subsections.\n",
    "   <title> for main titles of sections and subsections. \n",
    "   <subtitle> for subtitles of sections and subsections. \n",
    "   <heading> for headings that do not mark titles or subtitles\n",
    "   <contents> for tables of contents\n",
    "   <author> for authors of sections or subsections\n",
    "   <ol> <ul> <li> for lists\n",
    "   <i> for italics. \n",
    "   <b> for bold.\n",
    "   <footnote> <footnote-section> for footnotes (see below).\n",
    "\n",
    "All titles, XML sections, text, and terms should be translated--do not leave any terms or expressions in Vietnamese, except names of Vietnamese people.\n",
    "\n",
    "Add footnotes as follows:\n",
    "\n",
    "1. Structure\n",
    "   - Inline Reference: Use `<footnote number=\"X\">[X]</footnote>` directly after the reference in the text.\n",
    "   - Footnote Section: Include all footnote explanations in `<footnote-section>` at the end of the document. Example:\n",
    "     A sentence with a footnote.<footnote number=\"1\">[1]</footnote>\n",
    "     <footnote-section>\n",
    "         <footnote number=\"1\">Explanation for footnote 1.</footnote>\n",
    "     </footnote-section>\n",
    "\n",
    "2. Numbering\n",
    "   - Start numbering at 1 for each new section.\n",
    "   - Increment sequentially for each new reference.\n",
    "\n",
    "4. Placement\n",
    "   - Inline `<footnote>` tags immediately follow the referenced text.\n",
    "   - `<footnote-section>` appears at the end of each section.\n",
    "\n",
    "5. Formatting\n",
    "   - Inline footnote references use square brackets: `[X]`.\n",
    "   - Explanations appear only in `<footnote-section>`.\n",
    "   - Highlight complex terms (Sanskrit, Sino-Vietnamese, French) with `<i>` tags and explain in footnotes. \n",
    "   - Each footnote should always include the original text or term before translation.\n",
    "\n",
    "6. Content \n",
    "   - Use footnotes liberally to explain:\n",
    "     * Elements of Vietnamese Buddhism or Buddhism in general.\n",
    "     * Vietnamese culture and history.\n",
    "     * Life, teachings, and practices of Thich Nhat Hanh.\n",
    "   - For footnoted terms, include the original Vietnamese, Sino-Vietnamese, Sanskrit, or French in the explanation.\n",
    "\n",
    "7. Examples:\n",
    "   Inline: Thich Nhat Hanh emphasized <i>mindfulness</i> <footnote number=\"1\">[1]</footnote>.\n",
    "   Section: \n",
    "   <footnote-section>\n",
    "       <footnote number=\"1\"><i>Mindfulness</i>: Original term is \"ChÃ¡nh niá»‡m\" (Vietnamese).</footnote>\n",
    "   </footnote-section>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_base_tranlate = \"\"\"\n",
    "You are Thich Nhat Hanh translating pages from an OCR scanned journal you edited in the 1950's. If words or text are garbled you may correct.\n",
    "Give a precise English translation of the page in xml format. Strive for phrase-level accuracy. \n",
    "Add <section> <p> and <title> tags to any parts of the text which indicate sections paragraphs or titles.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_tagging = \"\"\"\n",
    "This page is from a Vietnamese Buddhist Journal published in the 1950's. Add XML tags where appropriate:\n",
    "<section> for major sections.\n",
    "<subsection> for subsections.\n",
    "<p> for paragraphs.\n",
    "<title> for titles of sections or subsections\n",
    "<subtitle> for subtitles\n",
    "<author> for authors\n",
    "<heading> for any other headings in the text\n",
    "<ol> <ul> <li> for lists\n",
    "<contents> for tables of contents\n",
    "<note> for notes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5 turbo test system message:\n",
    "\n",
    "```\n",
    "Give a precise English translation of this initially cleaned OCR text in the style of Thich Nhat Hanh. \n",
    "Strive for phrase-level accuracy.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_string_translate = \"\"\"{text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_wrap_function_translate(text_block):\n",
    "    return user_message_string_translate.format(text=text_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_message_seq = generate_messages(system_message_tagging, user_wrap_function_translate, cleaned_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_file_path = batch_job_dir / \"journal_translate_batches\" / f\"translate_base_batch_{basename}.jsonl\" \n",
    "batch_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jsonl_file_for_batch(translation_message_seq, batch_file_path, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_batch = start_batch(batch_file_path)\n",
    "tx_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_api_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_active_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = get_completed_batches()\n",
    "completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = get_batch_response(completed[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_data[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_translated_text = join_pages(translated_data)\n",
    "token_count(full_translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_output_xml_path = journal_dir / basename / \"full_rough_tx_test_phat-giao-viet-nam-1956-01.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pages_to_xml(tx_output_xml_path, translated_data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
