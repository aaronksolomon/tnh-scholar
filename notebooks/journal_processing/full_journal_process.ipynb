{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Journal Processing Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Incudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from math import floor\n",
    "\n",
    "# OCR processing\n",
    "from google.cloud import vision\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path\n",
    "import fitz  # for pdf work: PyMuPDF\n",
    "from xml.sax.saxutils import escape\n",
    "\n",
    "\n",
    "# XML\n",
    "from xml.sax.saxutils import escape\n",
    "\n",
    "# Local modules\n",
    "from data_processing.ocr_processing import (\n",
    "    make_image_preprocess_mask,\n",
    "    build_processed_pdf, \n",
    "    save_processed_pdf_data, \n",
    "    load_processed_PDF_data\n",
    ")\n",
    "\n",
    "from data_processing.gpt_processing import (\n",
    "    start_batch_with_retries, \n",
    "    set_model_settings,\n",
    "    delete_api_files\n",
    ")\n",
    "\n",
    "from data_processing.xml_processing import split_xml_pages, split_xml_on_pagebreaks, save_pages_to_xml\n",
    "\n",
    "from data_processing.text_processing import get_text_from_file\n",
    "\n",
    "from data_processing.gpt_processing.pdf_journal_process import (\n",
    "    setup_logger,\n",
    "    generate_clean_batch, batch_section, batch_translate, \n",
    "    save_sectioning_data, save_translation_data, save_cleaned_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "project_dir = Path(\"/Users/phapman/Desktop/tnh-scholar/\")\n",
    "data_dir = project_dir / \"data_processing\"\n",
    "pdf_dir = data_dir / \"PDF\" / \"Phat_Giao_journals\" # directory to read pdfs from\n",
    "journal_dir = data_dir / \"processed_journal_data\"\n",
    "journal_name = \"phat-giao-viet-nam-1956-11\"\n",
    "pdf_to_process = pdf_dir / f\"{journal_name}.pdf\"\n",
    "working_dir = journal_dir / journal_name\n",
    "ocr_data_dir = journal_dir / \"ocr_data\"\n",
    "cleaned_xml_path = working_dir / f\"full_cleaned_{journal_name}.xml\"\n",
    "batch_job_dir = working_dir / \"processing_batch_files\"\n",
    "clean_batch_jsonl = batch_job_dir / f\"clean_batch_{journal_name}.jsonl\"\n",
    "ocr_file = journal_dir / journal_name / f\"full_OCR_{journal_name}.xml\"\n",
    "translation_xml_path = working_dir / f\"translation_{journal_name}.xml\"\n",
    "section_batch_jsonl = batch_job_dir / \"section_batch.jsonl\"\n",
    "translate_batch_jsonl = batch_job_dir / \"translation_batch.jsonl\"\n",
    "section_metadata_path = working_dir / \"section_metadata.json\"\n",
    "raw_json_metadata_path = working_dir / \"raw_metadata_response.txt\"\n",
    "logfile = data_dir / \"gpt_processing\" / \"pdf_journal_process\" / \"processing_info.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for cleaning OCR generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for OCR cleaning\n",
    "def user_wrap_function_clean(text_block):   # Function to wrap user message sent to model. Currently no wrapping.\n",
    "    return text_block  \n",
    "\n",
    "model_settings_clean = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 1000, # default value\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "}\n",
    "system_message_clean = \"\"\"You are a meticulous and consistent world expert at cleaning OCR-generated Vietnamese text. \n",
    "You are cleaning pages from a 1950's Buddhist Journal. \n",
    "Each line of scanned data will be enclosed in <> brackets. Leave <> brackets in place.\n",
    "Your goal is to minimally modify the text to generate a cleaned version.\n",
    "Do not remove any content from the main body of the text. \n",
    "Do not change the line formatting. \n",
    "\n",
    "You can use the semantic meaning of the text to infer correctionsâ€”but make no semantic changes. \n",
    "You can also add diacritical marks if they are missing or clearly inaccurate. \n",
    "Do not change any proper names, except to add missing diacritical marks or to fix orthographic errors if the context is clear.  \n",
    "\n",
    "This particular text has a title marker in the footer, \"Phat Giao Viet Nam,\" and also a publishing mark diagonally across the text.  \n",
    "The publishing watermark is \"TU VIEN HUE QUANG\"  and is faint so only parts of it may appear in some locations in the text. Remove all text corresponding to the watermark.\n",
    "Text corresponding to the footer, the publishing watermak (or part thereof), and page numbers can be omitted.\n",
    "\n",
    "IMPORTANT: If the page is blank return: blank page \n",
    "IMPORTANT: Output the corrected text only with no comments (including ``` xml)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for sectioning a journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding journal sections\n",
    "model_settings_section = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,\n",
    "        \"temperature\": 0.25\n",
    "    }\n",
    "}\n",
    "\n",
    "system_message_section = \"\"\"You are a highly skilled assistant processing a Vietnamese Buddhist journal scanned from OCR. \n",
    "Use the title: \"Journal of Vietnamese Buddhism.\"\n",
    "You will be determining the journal sections by page number. You will also generate metadata for the full text and each section. \n",
    "You will return this metadata in JSON format.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the text and divide it into sections based on logical breaks, such as headings, topic changes, or clear shifts in content.\n",
    "2. Ensure every page is part of a section. The first title page should always be its own section. Blank pages should be titled \"blank page\".\n",
    "3. For each section, provide:\n",
    "   - The original title in Vietnamese (`section_title_vi`).\n",
    "   - The translated title in English (`section_title_en`).\n",
    "   - The author's name if it is available (`section_author`). \n",
    "   - A one-paragraph summary of the section in English (`section_summary`).\n",
    "   - A list of keywords for the section that are related to its content, these can be proper names, specific concepts, or contextual information.\n",
    "   - The section's start and end page numbers (`start_page` and `end_page`).\n",
    "   - Use \"null\" for any data that is not available (such as author name) for the section.\n",
    "\n",
    "4. Return the output as a JSON object with the following schema:\n",
    "{\n",
    "    \"journal_summary\": \"A one-page summary of the whole journal in English.\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"title_vi\": \"Original title in Vietnamese\",\n",
    "            \"title_en\": \"Translated title in English\",\n",
    "            \"author\": \"Name of the author of the section\",\n",
    "            \"summary\": \"One-paragraph summary of the section in English\",\n",
    "            \"keywords\": \"A list of keywords for the section\",\n",
    "            \"start_page\":  X,\n",
    "            \"end_page\":  Y\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "5.  Ensure the JSON is well-formed and adheres strictly to the provided schema.\n",
    "6.  IMPORTANT: ensure every page is part of a section and sections appear in order of pagination.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation settings\n",
    "model_settings_translate = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,  # a default value, updated per batch\n",
    "        \"temperature\": 0.75\n",
    "    }\n",
    "}\n",
    "\n",
    "system_message_translate = \"\"\"You are the world's foremost translator of Zen Master Thich Nhat Hanh's Vietnamese writing into English, following the language style of the plumvillage.org website.\n",
    "The text is based on an OCR scan of a journal you edited from 1956-1958. Use the title: \"Journal of Vietnamese Buddhism\" for the journal when it is referenced.\n",
    "You will be translating a single section of the journal and will be provided with the section title in English. \n",
    "Translate for the most meaningful, typical, and eloquent English interpretation that is simple, yet poetic. \n",
    "Translate precisely; do not add change the text or add commentary.  \n",
    "Notes on the text can be added in the <notes>.\n",
    "Make corrections in the text only where necessary (for example if words are missing) to create logical flow. Note all corrections in the <translation-notes>. \n",
    "Do not change <pagebreak> tag postioning. Each translated page must match its original page source as pages will be studied side by side with the original Vietnamese.\n",
    "Infer paragraphs and text structure from the text layout.\n",
    "Add XML tags for clarity, using only the following tags: \n",
    "\n",
    "   <section> for major sections.\n",
    "   <subsection> for subsections.\n",
    "   <title> for main titles of sections and subsections. \n",
    "   <subtitle> for subtitles of sections and subsections. \n",
    "   <heading> for headings that do not mark titles or subtitles\n",
    "   <p> for paragraphs.\n",
    "   <br/> for linebreaks that add meaning such as in poems or other structures.\n",
    "   <TOC> for tables of contents\n",
    "   <author> for named authors of sections (only)\n",
    "   <i> for italics. \n",
    "   <b> for bold.\n",
    "   <notes>\n",
    "   <translation-notes>\n",
    "\n",
    "You may use <notes> at the end of the section for notes on historical, cultural, spiritual, or other interesting elements of the text.\n",
    "You want advanced students of Thay to understand the text in its larger historical context, in the context of Vietnamese Buddhism, and in the context of his life.\n",
    "You may add <translation-notes> at the end of the section as a commentary to summarize your translation choices. \n",
    "For <translation-notes>, you may include information on Sino-Vietnamese, complex, unusual, poetic, or other interesting terms, and significant corrections to the text. \n",
    "In the <translation-notes> include the original Vietnamese terms for reference.\n",
    "\n",
    "IMPORTANT: All titles, XML sections, text, poetry, quotations, and terms MUST BE TRANSLATED TO ENGLISH. Do not however, translate names of people; leave names in Vietnamese with diacritics.\n",
    "IMPORTANT: Return pure XML with no formatting marks such as xml or ```.\n",
    "IMPORTANT: The returned XML should begin and end with <section> tags.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process execution pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process pdf with OCR through google vision\n",
    "client = vision.ImageAnnotatorClient()\n",
    "pre_mask1 = make_image_preprocess_mask(0.1)  #this masks the bottom 10% of the image where the publishing mark is located\n",
    "text_pages, word_locations_list, annotated_images, unannotated_images = build_processed_pdf(pdf_to_process, client, pre_mask1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed info\n",
    "save_processed_pdf_data(ocr_data_dir, journal_name, text_pages, word_locations_list, annotated_images, unannotated_images)\n",
    "save_pages_to_xml(working_dir / f\"full_OCR_{journal_name}.xml\", text_pages, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_clean_batch(ocr_file, clean_batch_jsonl, system_message_clean, user_wrap_function_clean)\n",
    "job_description = f\"cleaning for {journal_name} on {ocr_file}\"\n",
    "cleaned_data = start_batch_with_retries(clean_batch_jsonl, job_description) # run the clean process\n",
    "save_cleaned_data(cleaned_xml_path, cleaned_data, journal_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_model_settings(model_settings_section)\n",
    "metadata_serial_json = batch_section(cleaned_xml_path, section_batch_jsonl, system_message_section, journal_name) # run the section process\n",
    "save_sectioning_data(section_metadata_path, raw_json_metadata_path, metadata_serial_json, journal_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_model_settings(model_settings_translate)\n",
    "translation_data = batch_translate(cleaned_xml_path, translate_batch_jsonl, section_metadata_path, system_message_translate, journal_name)\n",
    "save_translation_data(translation_xml_path, translation_data, journal_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation = input(\"Are you sure you want to delete API files? 'y' to confirm: \").strip().lower()\n",
    "if confirmation == 'y':\n",
    "    delete_api_files(datetime.now())\n",
    "    print(\"Files deleted successfully.\")\n",
    "else:\n",
    "    print(\"Deletion canceled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
