{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from data_processing.gpt_processing import (\n",
    "    generate_messages, \n",
    "    set_model_settings,\n",
    "    run_immediate_chat_process,\n",
    "    get_last_batch_response,\n",
    ")\n",
    "\n",
    "from data_processing.gpt_processing.pdf_journal_process import (\n",
    "    batch_section, batch_translate, validate_and_save_metadata, save_sectioning_data, save_translation_data\n",
    ")\n",
    "\n",
    "%aimport time\n",
    "%aimport json\n",
    "%aimport datetime\n",
    "%aimport logging\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from math import floor\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "project_dir = Path(\"/Users/phapman/Desktop/tnh-scholar/\")\n",
    "data_dir = project_dir / \"data_processing\"\n",
    "journal_dir = data_dir / \"processed_journal_data\"\n",
    "journal_name = \"phat-giao-viet-nam-1956-02\"\n",
    "working_dir = journal_dir / journal_name\n",
    "input_xml = working_dir / f\"TEST_full_cleaned_{journal_name}.xml\"\n",
    "translation_xml_path = working_dir / f\"translation_{journal_name}.xml\"\n",
    "section_batch_jsonl = working_dir / \"processing_batch_files\" /\"section_batch.jsonl\"\n",
    "translate_batch_jsonl = working_dir / \"processing_batch_files\" / \"translation_batch.jsonl\"\n",
    "section_metadata_out = working_dir / \"section_metadata.json\"\n",
    "raw_json_metadata_path = working_dir / \"raw_metadata_response.txt\"\n",
    "logfile = data_dir / \"gpt_processing\" / \"processing_info.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MAX_TOKEN_LIMIT = 20000\n",
    "MAX_BATCH_RETRIES = 20  # Number of retries\n",
    "BATCH_RETRY_DELAY = 5  # seconds to wait before retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the logger\n",
    "def setup_logger(log_file_path):\n",
    "    \"\"\"\n",
    "    Configures the logger to write to a log file and the console.\n",
    "    \"\"\"\n",
    "    # Remove existing handlers\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",  # Include logger name\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()  # Optional: to log to the console as well\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Suppress DEBUG/INFO logs for specific noisy modules\n",
    "    modules_to_suppress = [\"httpx\", \"httpcore\", \"urllib3\", \"openai\"]\n",
    "    for module in modules_to_suppress:\n",
    "        logger = logging.getLogger(module)\n",
    "        logger.setLevel(logging.WARNING)  # Suppress DEBUG and INFO logs\n",
    "\n",
    "    \n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings_section = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,\n",
    "        \"temperature\": 0.25\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_section = \"\"\"You are a highly skilled assistant processing a Vietnamese Buddhist journal scanned from OCR. \n",
    "Use the title: \"Journal of Vietnamese Buddhism.\"\n",
    "You will be determining the journal sections by page number. You will also generate metadata for the full text and each section. \n",
    "You will return this metadata in JSON format.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the text and divide it into sections based on logical breaks, such as headings, topic changes, or clear shifts in content.\n",
    "2. Ensure every page is part of  a section, even if that section is titled \"blank page\" or \"title page,\" for example.\n",
    "3. For each section, provide:\n",
    "   - The original title in Vietnamese (`section_title_vi`).\n",
    "   - The translated title in English (`section_title_en`).\n",
    "   - The author's name if it is available (`section_author`). \n",
    "   - A one-paragraph summary of the section in English (`section_summary`).\n",
    "   - A list of keywords for the section that are related to its content, these can be proper names, specific concepts, or contextual information.\n",
    "   - The section's start and end page numbers (`start_page` and `end_page`).\n",
    "   - Use \"null\" for any data that is not available (such as author name) for the section.\n",
    "\n",
    "4. Return the output as a JSON object with the following schema:\n",
    "{\n",
    "    \"journal_summary\": \"A one-page summary of the whole journal in English.\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"title_vi\": \"Original title in Vietnamese\",\n",
    "            \"title_en\": \"Translated title in English\",\n",
    "            \"author\": \"Name of the author of the section\",\n",
    "            \"summary\": \"One-paragraph summary of the section in English\",\n",
    "            \"keywords\": \"A list of keywords for the section\",\n",
    "            \"start_page\":  X,\n",
    "            \"end_page\":  Y\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "5.  Ensure the JSON is well-formed and adheres strictly to the provided schema.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings_translate = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 5000,  # a default value, updated per batch\n",
    "        \"temperature\": 0.75\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_translate = \"\"\"You are the world's foremost translator of Zen Master Thich Nhat Hanh's Vietnamese writing into English, following the language style of the plumvillage.org website.\n",
    "The text is based on an OCR scan of a journal you edited from 1956-1958. Use the title: \"Journal of Vietnamese Buddhism\" for the journal when it is referenced.\n",
    "You will be translating a single section of the journal and will be provided with the section title in English. \n",
    "You want advanced students of Thay to understand the text in its larger historical context, in the context of Vietnamese Buddhism, and in the context of your own life.\n",
    "Translate for the most meaningful, typical, and eloquent English interpretation that is simple, yet poetic. Translate literally, don't add any content. \n",
    "Notes on the text can be added in the <notes>.\n",
    "Make corrections in the text only where necessary (for example if words are missing) to create logical flow. Note all corrections in the <translation-notes>. \n",
    "Do not change <pagebreak> tag postioning. Each translated page must match its original page source as pages will be studied side by side with the original Vietnamese.\n",
    "Infer paragraphs and text structure from the text layout.\n",
    "Add XML tags for clarity, using only the following tags: \n",
    "\n",
    "   <section> for major sections.\n",
    "   <subsection> for subsections.\n",
    "   <title> for main titles of sections and subsections. \n",
    "   <subtitle> for subtitles of sections and subsections. \n",
    "   <heading> for headings that do not mark titles or subtitles\n",
    "   <p> for paragraphs.\n",
    "   <br/> for linebreaks that add meaning such as in poems or other structures.\n",
    "   <TOC> for tables of contents\n",
    "   <author> for authors of sections or subsections\n",
    "   <ol> <ul> <li> for lists\n",
    "   <i> for italics. \n",
    "   <b> for bold.\n",
    "   <notes>\n",
    "   <translation-notes>\n",
    "\n",
    "You may use <notes> at the end of the section for notes on historical, cultural, spiritual, or other interesting elements of the text.\n",
    "You may add <translation-notes> at the end of the section as a commentary to summarize your translation choices. \n",
    "For <translation-notes>, you may include information on Sino-Vietnamese, complex, unusual, poetic, or other interesting terms, and significant corrections to the text. \n",
    "In the <translation-notes> include the original Vietnamese terms for reference.\n",
    "\n",
    "IMPORTANT: All titles, XML sections, text, and terms should be translated. Do not however, translate names of people; leave names in Vietnamese with diacritics.\n",
    "IMPORTANT: Return pure XML with no formatting marks such as xml or ```.\n",
    "IMPORTANT: The returned XML should begin and end with <section> tags.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_xml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sectioning\n",
    "set_model_settings(model_settings_section)\n",
    "metadata_serial_json = batch_section(input_xml, section_batch_jsonl, system_message_section, journal_name)\n",
    "metadata_path = save_sectioning_data(section_metadata_out, raw_json_metadata_path, metadata_serial_json, journal_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Translating\n",
    "set_model_settings(model_settings_translate)\n",
    "if metadata_path:\n",
    "    translation_data = batch_translate(input_xml, translate_batch_jsonl, metadata_path, system_message_translate, journal_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_translation_data(Path(\"test.xml\"), translation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_last_batch_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_and_save_metadata(section_metadata_out, result[0], journal_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_sectioning(input_xml_path, output_json_path, raw_output_path, journal_name, max_retries=MAX_BATCH_RETRIES, retry_delay=BATCH_RETRY_DELAY):\n",
    "#     \"\"\"\n",
    "#     Splits the journal content into sections using GPT, with retries for both starting and completing the batch.\n",
    "#     \"\"\"\n",
    "#     journal_pages = get_text_from_file(input_xml_path)\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"{text}\"\n",
    "#     messages = generate_messages(system_message_section, user_message_wrapper, [journal_pages])\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, section_batch_jsonl, json_mode=True)\n",
    "\n",
    "#     for attempt in range(max_retries):\n",
    "#         try:\n",
    "#             # Try to start the batch\n",
    "#             batch = start_batch(jsonl_file, description=f\"Batch for sectioning journal: {journal_name} | input file: {input_xml_path}\")\n",
    "#             batch_id = batch.id\n",
    "#             if not batch_id:\n",
    "#                 raise RuntimeError(\"Batch started but no ID was returned.\")\n",
    "\n",
    "#             print(f\"Batch for sectioning started successfully on attempt {attempt + 1}. ID: {batch_id}\")\n",
    "\n",
    "#             # Poll for batch completion\n",
    "#             json_results = poll_batch_for_response(batch_id)\n",
    "#             if json_results:\n",
    "#                 break # exit retry loop\n",
    "#             else:\n",
    "#                 raise RuntimeError(\"Unknown error in polling for batch response.\", exc_info=True)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Attempt {attempt + 1} failed: {e}. Retrying batch process in {retry_delay} seconds...\")\n",
    "#             time.sleep(retry_delay)\n",
    "#     else:\n",
    "#         logger.error(\"Failed to complete batch sectioning after maximum retries.\")\n",
    "#         raise RuntimeError(\"Error: Failed to complete batch sectioning after maximum retries.\")\n",
    "\n",
    "#     # save raw result\n",
    "#     try:\n",
    "#         write_text_to_file(raw_output_path, json_results, force=True)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"failed to write raw response file: {raw_output_path}\")\n",
    "#         raise\n",
    "\n",
    "#     # If successful, try to validate and save metadata and exit loop\n",
    "#     try:\n",
    "#         valid = validate_and_save_metadata(output_json_path, json_results, journal_schema)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error occurred while validating and saving metadata for journal {journal_name}: '{output_json_path}' (batch ID: {batch_id}).\", exc_info=True)\n",
    "#         raise\n",
    "    \n",
    "#     if valid:\n",
    "#         logger.info(f\"Successfully processed {journal_name}: {input_xml_path} with batch: {batch_id} and saved metadata to {output_json_path} \")\n",
    "#         return output_json_path\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Sectioning\n",
    "# def batch_sectioning(input_xml_path, output_xml_path):\n",
    "#     \"\"\"\n",
    "#     Splits the journal content into sections using the GPT model.\n",
    "#     Saves the sectioned content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the input XML\n",
    "#     journal_pages = load_xml(input_xml_path)\n",
    "#     pages_content = [page.text for page in journal_pages]\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"Divide this content into sections:\\n{text}\"\n",
    "#     messages = generate_messages(system_message_section, user_message_wrapper, pages_content)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, section_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for sectioning journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for sectioning.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for sectioning started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_status(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve sectioning batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save sectioned content back to XML\n",
    "#     for i, section_content in enumerate(results):\n",
    "#         journal_pages[i].text = section_content  # Replace original content with sectioned content\n",
    "\n",
    "#     save_xml(journal_pages, output_xml_path)\n",
    "#     print(f\"Sectioned journal saved to {output_xml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from gpt_processing.gpt_interface import (\n",
    "#     set_api_client, \n",
    "#     generate_messages, \n",
    "#     create_jsonl_file_for_batch, \n",
    "#     start_batch, \n",
    "#     get_batch_response\n",
    "# )\n",
    "# from data_processing.xml_processing import (\n",
    "#     load_xml, \n",
    "#     save_xml, \n",
    "#     extract_sections_from_xml\n",
    "# )\n",
    "\n",
    "# # Initialize OpenAI client\n",
    "# set_api_client()\n",
    "\n",
    "# # File paths\n",
    "# INPUT_XML = \"input_journal.xml\"\n",
    "# SECTIONED_XML = \"sectioned_journal.xml\"\n",
    "# TRANSLATED_XML = \"translated_journal.xml\"\n",
    "# BATCH_SECTION_JSONL = \"section_batch.jsonl\"\n",
    "# BATCH_TRANSLATE_JSONL = \"translate_batch.jsonl\"\n",
    "\n",
    "# # System messages\n",
    "# SYSTEM_MESSAGE_SECTION = \"\"\"\n",
    "# You are a helpful assistant. Divide the text into meaningful sections and add XML tags:\n",
    "# <section> for major sections, <subsection> for subsections, <title> for titles, and <p> for paragraphs.\n",
    "# \"\"\"\n",
    "# SYSTEM_MESSAGE_TRANSLATE = \"\"\"\n",
    "# You are Thich Nhat Hanh translating from Vietnamese to English. Provide meaningful translations with appropriate XML tags:\n",
    "# <section>, <subsection>, <title>, <p>.\n",
    "# \"\"\"\n",
    "\n",
    "# # Step 1: Sectioning\n",
    "# def batch_sectioning(input_xml, output_xml):\n",
    "#     # Load the input XML and extract pages or chunks\n",
    "#     journal_pages = load_xml(input_xml)\n",
    "#     pages_content = [page.text for page in journal_pages]  # Assuming .text contains the text of each page\n",
    "\n",
    "#     # Create GPT messages for sectioning\n",
    "#     user_message_wrapper = lambda text: f\"Divide this content into sections:\\n{text}\"\n",
    "#     messages = generate_messages(SYSTEM_MESSAGE_SECTION, user_message_wrapper, pages_content)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, BATCH_SECTION_JSONL)\n",
    "\n",
    "#     # Start batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for sectioning journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for sectioning.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for sectioning started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion and retrieve results\n",
    "#     results = get_batch_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve sectioning batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save the sectioned content back to XML\n",
    "#     for i, section_content in enumerate(results):\n",
    "#         journal_pages[i].text = section_content  # Replace original content with sectioned content\n",
    "\n",
    "#     save_xml(journal_pages, output_xml)\n",
    "#     print(f\"Sectioned journal saved to {output_xml}\")\n",
    "\n",
    "# # Step 2: Translation\n",
    "# def batch_translation(input_xml, output_xml):\n",
    "#     # Load the sectioned XML and extract sections or chunks for translation\n",
    "#     sections = extract_sections_from_xml(input_xml)\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(SYSTEM_MESSAGE_TRANSLATE, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, BATCH_TRANSLATE_JSONL)\n",
    "\n",
    "#     # Start batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion and retrieve results\n",
    "#     results = get_batch_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save the translated content back to XML\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         sections[i].text = translated_content  # Replace original content with translated content\n",
    "\n",
    "#     save_xml(sections, output_xml)\n",
    "#     print(f\"Translated journal saved to {output_xml}\")\n",
    "\n",
    "# # Main process\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Step 1: Sectioning\n",
    "#     print(\"Starting batch sectioning...\")\n",
    "#     batch_sectioning(INPUT_XML, SECTIONED_XML)\n",
    "\n",
    "#     # Step 2: Translation\n",
    "#     print(\"Starting batch translation...\")\n",
    "#     batch_translation(SECTIONED_XML, TRANSLATED_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function schema for function calling\n",
    "# function_schemas = [\n",
    "#     {\n",
    "#         \"name\": \"save_processed_metadata\",\n",
    "#         \"description\": \"Save metadata for a processed vietnamese journal, including sections and summaries, that will later be translated\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"journal_summary\": {\"type\": \"string\", \"description\": \"A one-page summary of the journal in English.\"},\n",
    "#                 \"sections\": {\n",
    "#                     \"type\": \"array\",\n",
    "#                     \"items\": {\n",
    "#                         \"type\": \"object\",\n",
    "#                         \"properties\": {\n",
    "#                             \"section_title_vi\": {\"type\": \"string\", \"description\": \"The original title of the section in Vietnamese.\"},\n",
    "#                             \"section_title_en\": {\"type\": \"string\", \"description\": \"The translated title of the section in English.\"},\n",
    "#                             \"section_summary\": {\"type\": \"string\", \"description\": \"A one paragraph summary of the section in English.\"},\n",
    "#                             \"page_range\": {\n",
    "#                                 \"type\": \"array\",\n",
    "#                                 \"items\": {\"type\": \"integer\"},\n",
    "#                                 \"minItems\": 2,\n",
    "#                                 \"maxItems\": 2,\n",
    "#                                 \"description\": \"The start and end page numbers of the section.\"\n",
    "#                             }\n",
    "#                         },\n",
    "#                         \"required\": [\"section_title_en\", \"section_title_vi\", \"section_summary\", \"page_range\"]\n",
    "#                     }\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"journal_summary\", \"sections\"]\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Translation\n",
    "# def batch_translate(input_xml_path, metadata_path):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the sectioned XML\n",
    "#     section_metadata = #load json data from metadata_path and deserialize\n",
    "\n",
    "#     # use the function split_xml_to_pages to get sections for translation:\n",
    "#     sections = split_xml_pages(...)\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # convert the blocks below to a series of nested try blocks with multiple attempts as in batch_section():\n",
    "#     # add appropriate logging to match batch_section():\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_for_response(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save translated content back to XML\n",
    "#     translated_sections = []\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         translated_sections.append(translated_content)  # Replace original content with translated content\n",
    "\n",
    "#     save_pages_to_xml(translated_sections, translated_xml)\n",
    "#     print(f\"Translated journal saved to {translated_xml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old system message\n",
    "\n",
    "# system_message_section = \"\"\"\n",
    "# You are a highly skilled assistant processing a Vietnamese journal scanned from OCR. \n",
    "# You will be determining the journal sections by page number. You will also generate summaries for the full text and each section. \n",
    "# You will return this metadata in JSON format.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Analyze the text and divide it into sections based on logical breaks, such as headings, topic changes, or clear shifts in content.\n",
    "# 2. Ensure every page is part of  a section, even if that section is titled \"blank page\" or \"title page,\" for example.\n",
    "# 3. For each section, provide:\n",
    "#    - The original title in Vietnamese (`section_title_vi`).\n",
    "#    - The translated title in English (`section_title_en`).\n",
    "#    - The author's name if it is available (`section_author`). \n",
    "#    - A one-paragraph summary of the section in English (`section_summary`).\n",
    "#    - A list of keywords for the section that are related to its content, these can be proper names, specific concepts, or contextual information.\n",
    "#    - The section's start and end page numbers (`start_page` and `end_page`).\n",
    "#    - Use \"null\" for any data that is not available (such as author name) for the section.\n",
    "\n",
    "# 4. Return the output as a JSON object with the following schema:\n",
    "# {\n",
    "#     \"journal_summary\": \"A one-page summary of the whole journal in English.\",\n",
    "#     \"sections\": [\n",
    "#         {\n",
    "#             \"section_title_vi\": \"Original title in Vietnamese\",\n",
    "#             \"section_title_en\": \"Translated title in English\",\n",
    "#             \"section_author\": \"Name of the author of the section\",\n",
    "#             \"section_summary\": \"One-paragraph summary of the section in English\",\n",
    "#             \"section_keywords\": \"A list of keywords for the section\",\n",
    "#             \"start_page\":  X,\n",
    "#             \"end_page\":  Y\n",
    "#         },\n",
    "#         ...\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# 5.  Ensure the JSON is well-formed and adheres strictly to the provided schema.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Translation\n",
    "# def batch_translate(input_xml_path, output_xml_path):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "#     \"\"\"\n",
    "#     # Load the sectioned XML\n",
    "#     section_metadata = \n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "\n",
    "#     # Start the batch\n",
    "#     batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#     batch_id = batch.get(\"id\")\n",
    "#     if not batch_id:\n",
    "#         print(\"Error: Failed to start batch for translation.\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"Batch for translation started with ID: {batch_id}\")\n",
    "\n",
    "#     # Poll for batch completion\n",
    "#     results = poll_batch_status(batch_id)\n",
    "#     if not results:\n",
    "#         print(\"Error: Failed to retrieve translation batch results.\")\n",
    "#         return None\n",
    "\n",
    "#     # Save translated content back to XML\n",
    "#     for i, translated_content in enumerate(results):\n",
    "#         sections[i].text = translated_content  # Replace original content with translated content\n",
    "\n",
    "#     save_pages_to_xml(sections, output_xml_path)\n",
    "#     print(f\"Translated journal saved to {output_xml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Translation\n",
    "# def batch_translate(input_xml_path, metadata_path, journal_name, xml_output_path, max_retries=MAX_BATCH_RETRIES, retry_delay=BATCH_RETRY_DELAY):\n",
    "#     \"\"\"\n",
    "#     Translates the journal sections using the GPT model.\n",
    "#     Saves the translated content back to XML.\n",
    "\n",
    "#     Args:\n",
    "#         input_xml_path (str): Path to the input XML file.\n",
    "#         metadata_path (str): Path to the metadata JSON file.\n",
    "#         max_retries (int): Maximum number of retries for batch operations.\n",
    "#         retry_delay (int): Delay in seconds between retries.\n",
    "\n",
    "#     Returns:\n",
    "#         bool: True if the process succeeds, False otherwise.\n",
    "#     \"\"\"\n",
    "#     logger.info(\n",
    "#         f\"starting translation batch {journal_name}...\",\n",
    "#         extra={\n",
    "#             \"input_xml\": input_xml_path,\n",
    "#             \"metadata_path\": metadata_path,\n",
    "#             \"journal_name\": journal_name\n",
    "#         }\n",
    "#     )\n",
    "#     try: # data initialization:\n",
    "#         # get metadata\n",
    "#         section_metadata = deserialize_json(metadata_path)\n",
    "#         section_title = section_metadata.section_title_en\n",
    "\n",
    "#         # Extract page groups and split XML content\n",
    "#         page_groups = extract_page_groups_from_metadata(section_metadata)\n",
    "#         xml_content = get_text_from_file(input_xml_path)\n",
    "#         sections = split_xml_pages(xml_content, page_groups)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         # Log the error with full traceback\n",
    "#         logger.error(\n",
    "#             \"Could not initialize data for translation batching {journal_name}\", exc_info=True)\n",
    "#         raise  # Re-raise the exception to escalate\n",
    "\n",
    "#     # Create GPT messages for translation\n",
    "\n",
    "#     user_message_wrapper = lambda section: f\"Translate this section with title {section_title}:\\n{section}\"\n",
    "#     messages = generate_messages(system_message_translate, user_message_wrapper, sections)\n",
    "\n",
    "#     # Create JSONL file for batch processing\n",
    "    \n",
    "#     jsonl_file = create_jsonl_file_for_batch(messages, translate_batch_jsonl)\n",
    "#     if not jsonl_file:\n",
    "#         logger.error(\n",
    "#             \"Failed to create JSONL file for translation batch.\",\n",
    "#             exc_info=True  # Logs the exception traceback if one exists\n",
    "#         )\n",
    "#         raise RuntimeError(\"Failed to create JSONL file for translation batch.\")\n",
    "    \n",
    "#     for attempt in range(max_retries): # batching logic requires multiple retries due to issues with API:\n",
    "#         try:\n",
    "#             # Start the batch\n",
    "#             batch = start_batch(jsonl_file, description=\"Batch for translating journal\")\n",
    "#             batch_id = batch.get(\"id\")\n",
    "#             if not batch_id:\n",
    "#                 raise RuntimeError(\"Batch started but no ID was returned.\")\n",
    "            \n",
    "#             print(f\"Batch for translation started successfully on attempt {attempt + 1}. ID: {batch_id}\")\n",
    "\n",
    "#             # Poll for batch completion\n",
    "#             print(\"Polling for batch completion...\")\n",
    "#             results = poll_batch_for_response(batch_id)\n",
    "\n",
    "#             if results:\n",
    "#                 break # exit the retry loop\n",
    "#             else:\n",
    "#                 raise RuntimeError(\"Unknown error. No results from batch polling.\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(\n",
    "#                 f\"Attempt {attempt + 1} failed during translation for journal '{input_xml_path}'. Retrying in {retry_delay} seconds...\",\n",
    "#                 exc_info=True\n",
    "#             )\n",
    "#             time.sleep(retry_delay)\n",
    "#     else:\n",
    "#         logger.error(f\"Failed to complete translation after {max_retries} retries for journal '{input_xml_path}'.\")\n",
    "#         raise RuntimeError(\"Unable to run translate batch.\")\n",
    "        \n",
    "#     # Save translated content back to XML\n",
    "#     try: \n",
    "#         print(\"Saving translated content back to XML...\")\n",
    "#         translated_sections = []\n",
    "#         for i, translated_content in enumerate(results):\n",
    "#             translated_sections.append(translated_content)\n",
    "\n",
    "#         save_pages_to_xml(translated_sections, xml_output_path, overwrite=True)\n",
    "#         print(f\"Translated journal saved to {xml_output_path}\")\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(\"Failed to save translation data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "set_api_client()\n",
    "msgs = generate_messages(\"you are assisting a software engineering/researcher looking to develop new AI platforms and processes.\", lambda x: x, [\"why is AI suddenly successful?\", \"What is the (immediate) future of AI?\"])\n",
    "run_immediate_chat_process(msgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model_settings = {\n",
    "    \"gpt-4o\": {\n",
    "        \"max_tokens\": 3000,\n",
    "        \"context_limit\": 20000,  # Total context limit for the model\n",
    "        \"temperature\": 1.3\n",
    "    }}\n",
    "\n",
    "set_model_settings(model_settings)\n",
    "batch_id = run_single_oa_batch([\"what is the square root of 2?\", \"why is the sky blue?\"], \"you are are explaining complex ideas to a 9 year old child.\")\n",
    "\n",
    "poll_batch_for_response(batch_id, 10)\n",
    "\n",
    "msgs = generate_messages(\"you are assisting a software engineering/researcher looking to develop new AI platforms and processes.\", lambda x: x, [\"why is AI suddenly successful?\", \"What is the (immediate) future of AI?\"])\n",
    "run_immediate_chat_process(msgs[1])\n",
    "\n",
    "get_last_batch_response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnh-scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
